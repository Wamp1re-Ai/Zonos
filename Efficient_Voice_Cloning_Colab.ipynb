{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# ğŸ”¥ Efficient Voice Cloning with Zonos TTS - UNLIMITED MODE!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/Zonos/blob/efficient/Efficient_Voice_Cloning_Colab.ipynb)\n",
    "\n",
    "## ğŸš€ NEW: UNLIMITED AUDIO GENERATION - NO LENGTH RESTRICTIONS!\n",
    "\n",
    "This notebook provides **unlimited voice cloning** capabilities with **NO length caps**:\n",
    "\n",
    "### ğŸ”¥ Key Features:\n",
    "- âœ… **UNLIMITED MODE** - Generate audio of ANY length (hours if needed!)\n",
    "- âœ… **2-10x faster generation** with efficiency optimizations\n",
    "- âœ… **Voice caching** for 5-10x speedup on repeated voices\n",
    "- âœ… **Intelligent chunking** for very long texts\n",
    "- âœ… **FP16 precision** support for 2x speed improvement\n",
    "- âœ… **Real-time progress** tracking and statistics\n",
    "- âœ… **NO 30-second caps** - removed all artificial restrictions!\n",
    "\n",
    "### ğŸ“Š What You Can Generate:\n",
    "- ğŸ“š **Complete audiobooks** from text manuscripts\n",
    "- ğŸ“ **Extended educational content** and lectures\n",
    "- ğŸ’¼ **Long-form business presentations**\n",
    "- ğŸ™ï¸ **Podcast-length audio content**\n",
    "- ğŸ“– **Entire book chapters and articles**\n",
    "\n",
    "### ğŸ¯ Performance Expectations:\n",
    "- **Short texts**: Instant generation\n",
    "- **Medium texts (500 chars)**: 3-5x speedup\n",
    "- **Long texts (1000+ chars)**: 5-10x speedup\n",
    "- **Very long texts**: **UNLIMITED** - no caps applied!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Instructions:\n",
    "1. **Run Cell 1**: Clone the efficient branch with all optimizations\n",
    "2. **Run Cell 2**: Install dependencies with UV (10x faster)\n",
    "3. **Run Cell 3**: Load the efficient Zonos system\n",
    "4. **Run Cell 4**: Upload your voice sample for cloning\n",
    "5. **Run Cell 5**: Generate unlimited audio with your cloned voice!\n",
    "\n",
    "**Ready to break all length barriers? Let's go! ğŸš€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup_efficient"
   },
   "outputs": [],
   "source": [
    "#@title 1. ğŸš€ Setup Efficient Zonos System\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"ğŸš€ Setting up Efficient Zonos Voice Cloning System\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¥ NEW: UNLIMITED MODE - NO LENGTH RESTRICTIONS!\")\n",
    "print(\"\")\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ“ Running in local environment\")\n",
    "\n",
    "# Clone the efficient branch with all optimizations\n",
    "if IN_COLAB:\n",
    "    print(\"\\nğŸ“¥ Cloning Zonos TTS (efficient branch with unlimited features)...\")\n",
    "    \n",
    "    # Remove existing directory if it exists\n",
    "    if os.path.exists('Zonos'):\n",
    "        print(\"ğŸ—‘ï¸ Removing existing Zonos directory...\")\n",
    "        subprocess.run(['rm', '-rf', 'Zonos'], check=True)\n",
    "    \n",
    "    # Clone the efficient branch\n",
    "    result = subprocess.run([\n",
    "        'git', 'clone', '-b', 'efficient', \n",
    "        'https://github.com/Wamp1re-Ai/Zonos.git'\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Successfully cloned efficient branch!\")\n",
    "        \n",
    "        # Change to Zonos directory\n",
    "        os.chdir('Zonos')\n",
    "        print(f\"ğŸ“ Changed to directory: {os.getcwd()}\")\n",
    "        \n",
    "        # Check for efficiency files\n",
    "        efficiency_files = [\n",
    "            'efficient_voice_cloning.py',\n",
    "            'enhanced_voice_cloning.py', \n",
    "            'unlimited_voice_cloning.py'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸ” Checking for efficiency optimization files:\")\n",
    "        for file in efficiency_files:\n",
    "            if os.path.exists(file):\n",
    "                print(f\"   âœ… {file} - Found\")\n",
    "            else:\n",
    "                print(f\"   âŒ {file} - Missing\")\n",
    "        \n",
    "        # Show git branch info\n",
    "        branch_result = subprocess.run(['git', 'branch', '--show-current'], \n",
    "                                     capture_output=True, text=True)\n",
    "        if branch_result.returncode == 0:\n",
    "            current_branch = branch_result.stdout.strip()\n",
    "            print(f\"\\nğŸŒ¿ Current branch: {current_branch}\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ Setup completed successfully!\")\n",
    "        print(\"ğŸ“‹ Next: Run Cell 2 to install dependencies\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Failed to clone repository: {result.stderr}\")\n",
    "        print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "        print(\"1. Check internet connection\")\n",
    "        print(\"2. Verify GitHub repository access\")\n",
    "        print(\"3. Try running the cell again\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nğŸ“ Local environment detected\")\n",
    "    print(\"Make sure you're in the Zonos directory with the efficient branch\")\n",
    "    print(\"Run: git checkout efficient\")\n",
    "    \n",
    "    # Check current directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"ğŸ“ Current directory: {current_dir}\")\n",
    "    \n",
    "    if 'Zonos' in current_dir or os.path.exists('zonos'):\n",
    "        print(\"âœ… Zonos directory detected\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Please navigate to the Zonos directory first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "#@title 2. ğŸ“¦ Install Dependencies (Fast with UV)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ Installing Dependencies for Unlimited Voice Cloning\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install UV for faster package management\n",
    "print(\"ğŸš€ Installing UV package manager (10x faster than pip)...\")\n",
    "try:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'uv'], \n",
    "                   check=True, capture_output=True)\n",
    "    print(\"âœ… UV installed successfully!\")\n",
    "    USE_UV = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"âš ï¸ UV installation failed, falling back to pip\")\n",
    "    USE_UV = False\n",
    "\n",
    "# Force NumPy 1.x for compatibility\n",
    "print(\"\\nğŸ”§ Installing NumPy 1.x for compatibility...\")\n",
    "numpy_cmd = ['uv', 'pip', 'install', 'numpy<2.0'] if USE_UV else [sys.executable, '-m', 'pip', 'install', 'numpy<2.0']\n",
    "try:\n",
    "    subprocess.run(numpy_cmd, check=True, capture_output=True)\n",
    "    print(\"âœ… NumPy 1.x installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âš ï¸ NumPy installation warning: {e}\")\n",
    "\n",
    "# Install system dependencies first (espeak for phonemization)\n",
    "print(f\"\\nğŸ”§ Installing system dependencies...\")\n",
    "try:\n",
    "    # More comprehensive espeak installation\n",
    "    subprocess.run(['apt-get', 'update', '-qq'], check=True, capture_output=True)\n",
    "    subprocess.run(['apt-get', 'install', '-y', '-qq', 'espeak', 'espeak-data', 'libespeak1', 'libespeak-dev'], check=True, capture_output=True)\n",
    "    print(\"âœ… espeak installed successfully!\")\n",
    "    \n",
    "    # Verify espeak installation\n",
    "    result = subprocess.run(['espeak', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        version = result.stdout.strip().split()[2] if len(result.stdout.strip().split()) > 2 else 'unknown'\n",
    "        print(f\"âœ… espeak verified: version {version}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ espeak verification failed\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ espeak installation failed: {e}\")\n",
    "    print(\"ğŸš¨ This WILL cause phonemization errors!\")\n",
    "    print(\"ğŸ’¡ Try restarting runtime and re-running this cell\")\n",
    "\n",
    "# Install main dependencies\n",
    "dependencies = [\n",
    "    'torch',\n",
    "    'torchaudio', \n",
    "    'transformers',\n",
    "    'accelerate',\n",
    "    'datasets',\n",
    "    'librosa',\n",
    "    'soundfile',\n",
    "    'scipy',\n",
    "    'matplotlib',\n",
    "    'IPython',\n",
    "    'tqdm',\n",
    "    'phonemizer'\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“¦ Installing core dependencies...\")\n",
    "for dep in dependencies:\n",
    "    print(f\"   Installing {dep}...\")\n",
    "    cmd = ['uv', 'pip', 'install', dep] if USE_UV else [sys.executable, '-m', 'pip', 'install', dep]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        print(f\"   âœ… {dep} installed\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"   âš ï¸ {dep} installation failed, may already be installed\")\n",
    "\n",
    "# Install Zonos TTS\n",
    "print(f\"\\nğŸµ Installing Zonos TTS...\")\n",
    "zonos_cmd = ['uv', 'pip', 'install', '-e', '.'] if USE_UV else [sys.executable, '-m', 'pip', 'install', '-e', '.']\n",
    "try:\n",
    "    subprocess.run(zonos_cmd, check=True, capture_output=True)\n",
    "    print(\"âœ… Zonos TTS installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âš ï¸ Zonos installation warning: {e}\")\n",
    "    print(\"Trying alternative installation...\")\n",
    "    try:\n",
    "        alt_cmd = [sys.executable, '-m', 'pip', 'install', '-e', '.', '--no-deps']\n",
    "        subprocess.run(alt_cmd, check=True, capture_output=True)\n",
    "        print(\"âœ… Zonos TTS installed with alternative method!\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"âŒ Zonos installation failed\")\n",
    "\n",
    "print(f\"\\nâœ… Dependency installation completed!\")\n",
    "print(f\"ğŸ’¡ Note: If Cell 3 gives NumPy errors:\")\n",
    "print(f\"   1. Runtime â†’ Restart runtime\")\n",
    "print(f\"   2. Re-run Cell 1 and Cell 2\")\n",
    "print(f\"   3. Then run Cell 3 again\")\n",
    "print(f\"   This is normal and fixes the NumPy compatibility issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "load_efficient_system"
   },
   "outputs": [],
   "source": [
    "#@title 3. ğŸš€ Load Efficient Zonos System\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"ğŸš€ Loading Efficient Zonos System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check NumPy version\n",
    "print(\"ğŸ”§ Verifying NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    print(f\"NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\nâš ï¸ WARNING: NumPy 2.x detected!\")\n",
    "        print(\"If you get errors below, restart runtime and re-run cells.\")\n",
    "    else:\n",
    "        print(\"âœ… NumPy version is compatible\")\n",
    "except ImportError:\n",
    "    print(\"âŒ NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\nğŸ“¦ Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"âœ… PyTorch {torch.__version__}\")\n",
    "    print(f\"âœ… TorchAudio {torchaudio.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ PyTorch error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import Transformers\n",
    "print(\"\\nğŸ¤— Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"âœ… Transformers {transformers.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Transformers error: {e}\")\n",
    "    if \"numpy\" in str(e).lower():\n",
    "        print(\"\\nğŸ”§ NumPy compatibility issue! Restart runtime and re-run cells.\")\n",
    "    raise\n",
    "\n",
    "# Import Zonos modules\n",
    "print(\"\\nğŸµ Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"âœ… Zonos modules loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Zonos import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nğŸ–¥ï¸ Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model\n",
    "model_name = \"Zyphra/Zonos-v0.1-transformer\"\n",
    "print(f\"\\nğŸ“¥ Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # Model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nğŸ“Š Model Info:\")\n",
    "    print(f\"  - Parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Languages: {len(supported_language_codes)} supported\")\n",
    "    \n",
    "    # Try to load efficient system\n",
    "    EFFICIENT_AVAILABLE = False\n",
    "    ENHANCED_AVAILABLE = False\n",
    "    UNLIMITED_AVAILABLE = False\n",
    "    \n",
    "    print(\"\\nğŸš€ Loading REAL Efficiency Optimizations...\")\n",
    "    try:\n",
    "        # Try to load the research-based efficient system first\n",
    "        if os.path.exists('real_efficient_voice_cloning.py'):\n",
    "            print(\"âœ“ Research-based efficient voice cloning file found\")\n",
    "            from real_efficient_voice_cloning import RealEfficientVoiceCloner\n",
    "            \n",
    "            # Create REAL efficient TTS system with research optimizations\n",
    "            real_efficient_tts = RealEfficientVoiceCloner(\n",
    "                model, \n",
    "                device=device, \n",
    "                use_optimizations=True\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… REAL Efficient Voice Cloning system loaded!\")\n",
    "            print(\"ğŸ”¬ Research-based optimizations: KV Cache, Speculative Decoding, torch.compile\")\n",
    "            print(\"ğŸš€ Expected 2-5x ACTUAL speedup with real optimizations!\")\n",
    "            EFFICIENT_AVAILABLE = True\n",
    "            REAL_EFFICIENT_AVAILABLE = True\n",
    "            UNLIMITED_AVAILABLE = True  # Real system supports unlimited\n",
    "            globals()['real_efficient_tts'] = real_efficient_tts\n",
    "            \n",
    "        # Fallback to old efficient system\n",
    "        elif os.path.exists('efficient_voice_cloning.py'):\n",
    "            print(\"âœ“ Old efficient voice cloning file found (fallback)\")\n",
    "            from efficient_voice_cloning import EfficientVoiceCloner\n",
    "            \n",
    "            # Create old efficient TTS system\n",
    "            efficient_tts = EfficientVoiceCloner(\n",
    "                model, \n",
    "                device=device, \n",
    "                use_fp16=True, \n",
    "                cache_size=10\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… Old Efficient Voice Cloning system loaded\")\n",
    "            print(\"âš ï¸ Using fallback system - may not provide significant speedup\")\n",
    "            EFFICIENT_AVAILABLE = True\n",
    "            REAL_EFFICIENT_AVAILABLE = False\n",
    "            globals()['efficient_tts'] = efficient_tts\n",
    "            \n",
    "            # Check for unlimited methods\n",
    "            if hasattr(efficient_tts, 'generate_unlimited_speech'):\n",
    "                print(\"ğŸ”¥ UNLIMITED MODE available - NO LENGTH RESTRICTIONS!\")\n",
    "                UNLIMITED_AVAILABLE = True\n",
    "            \n",
    "        else:\n",
    "            print(\"âš ï¸ No efficient voice cloning files found\")\n",
    "            REAL_EFFICIENT_AVAILABLE = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to load efficient system: {e}\")\n",
    "        print(\"Will try enhanced system instead...\")\n",
    "    \n",
    "    # Fallback to enhanced system (only if no efficient system available)\n",
    "    if not EFFICIENT_AVAILABLE:\n",
    "        print(\"\\nğŸ”§ Loading Enhanced Voice Cloning...\")\n",
    "        try:\n",
    "            if os.path.exists('enhanced_voice_cloning.py'):\n",
    "                print(\"âœ“ Enhanced voice cloning file found\")\n",
    "                from enhanced_voice_cloning import EnhancedVoiceCloner\n",
    "                \n",
    "                # Use the already loaded model instead of loading a new one\n",
    "                enhanced_cloner = EnhancedVoiceCloner(model, device=device)\n",
    "                print(\"âœ… Enhanced Voice Cloning loaded!\")\n",
    "                ENHANCED_AVAILABLE = True\n",
    "                globals()['enhanced_cloner'] = enhanced_cloner\n",
    "            else:\n",
    "                print(\"âš ï¸ enhanced_voice_cloning.py not found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to load enhanced system: {e}\")\n",
    "            print(\"Continuing with standard voice cloning...\")\n",
    "    \n",
    "    # Store globals\n",
    "    globals()['model'] = model\n",
    "    globals()['device'] = device\n",
    "    globals()['EFFICIENT_AVAILABLE'] = EFFICIENT_AVAILABLE\n",
    "    globals()['ENHANCED_AVAILABLE'] = ENHANCED_AVAILABLE\n",
    "    globals()['UNLIMITED_AVAILABLE'] = UNLIMITED_AVAILABLE\n",
    "    globals()['REAL_EFFICIENT_AVAILABLE'] = globals().get('REAL_EFFICIENT_AVAILABLE', False)\n",
    "    \n",
    "    # Show final status\n",
    "    print(f\"\\nğŸ‰ System loaded successfully!\")\n",
    "    print(f\"ğŸ“Š Features available:\")\n",
    "    if globals().get('REAL_EFFICIENT_AVAILABLE', False):\n",
    "        print(f\"  ğŸ”¬ REAL Efficient Voice Cloning (Research-based 2-5x speedup!)\")\n",
    "        print(f\"  ğŸ”¥ UNLIMITED Voice Cloning (NO LENGTH CAPS!)\")\n",
    "        print(f\"  âš¡ KV Caching for autoregressive generation\")\n",
    "        print(f\"  ğŸš€ Speculative decoding for parallel tokens\")\n",
    "        print(f\"  ğŸ§  torch.compile optimization (PyTorch 2.0+)\")\n",
    "        print(f\"  ğŸ’¾ Memory optimization with gradient checkpointing\")\n",
    "        print(f\"  ğŸ¯ CUDA optimizations (TF32, cuDNN benchmark)\")\n",
    "    elif UNLIMITED_AVAILABLE:\n",
    "        print(f\"  ğŸ”¥ UNLIMITED Voice Cloning (NO LENGTH CAPS!)\")\n",
    "        print(f\"  âœ… Efficient Voice Cloning (basic optimizations)\")\n",
    "        print(f\"  âœ… Voice caching system\")\n",
    "        print(f\"  âœ… FP16 precision support\")\n",
    "        print(f\"  âœ… Intelligent text chunking\")\n",
    "    elif EFFICIENT_AVAILABLE:\n",
    "        print(f\"  âœ… Efficient Voice Cloning (basic optimizations)\")\n",
    "        print(f\"  âœ… Voice caching system\")\n",
    "        print(f\"  âœ… FP16 precision support\")\n",
    "        print(f\"  âœ… Automatic batch processing\")\n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"  âœ… Enhanced Voice Cloning\")\n",
    "        print(f\"  âœ… Quality improvements\")\n",
    "        print(f\"  âœ… Long text fixes\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Standard voice cloning only\")\n",
    "    \n",
    "    # Check for espeak availability\n",
    "    print(f\"\\nğŸ”§ Checking system dependencies...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['espeak', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… espeak is available\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ espeak not found - may cause phonemization errors\")\n",
    "            print(f\"ğŸ’¡ If you get 'espeak not installed' errors, re-run Cell 2\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ espeak not installed - will cause phonemization errors\")\n",
    "        print(f\"ğŸ”§ SOLUTION: Re-run Cell 2 to install espeak\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ Ready for voice cloning!\")\n",
    "    print(f\"Next: Run Cell 4 to upload your voice sample.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Restart runtime if NumPy issues persist\")\n",
    "    print(\"3. Re-run all cells from the beginning\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "upload_voice"
   },
   "outputs": [],
   "source": [
    "#@title 4. ğŸ¤ Upload Voice Sample for Cloning\n",
    "from google.colab import files\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "print(\"ğŸ¤ Voice Cloning - Upload Your Audio File\")\n",
    "print(\"Upload an audio file (10-30 seconds) to clone the speaker's voice\")\n",
    "print(\"Supported formats: WAV, MP3, FLAC, etc.\")\n",
    "print(\"\")\n",
    "\n",
    "# Upload audio file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Get the uploaded file\n",
    "    audio_file = list(uploaded.keys())[0]\n",
    "    print(f\"\\nğŸ“ Processing: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Load and process the audio\n",
    "        wav, sr = torchaudio.load(audio_file)\n",
    "        \n",
    "        # Convert to mono if needed\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        \n",
    "        # Show audio info\n",
    "        duration = wav.shape[1] / sr\n",
    "        print(f\"ğŸ“Š Audio Info:\")\n",
    "        print(f\"  - Duration: {duration:.1f} seconds\")\n",
    "        print(f\"  - Sample rate: {sr} Hz\")\n",
    "        print(f\"  - Channels: {wav.shape[0]}\")\n",
    "        \n",
    "        # Quality recommendations\n",
    "        if duration < 5:\n",
    "            print(\"\\nâš ï¸ Audio is quite short (< 5s). Consider using 10-20 seconds for better results.\")\n",
    "        elif duration > 30:\n",
    "            print(\"\\nğŸ’¡ Audio is long (> 30s). The system will use the best portion automatically.\")\n",
    "        else:\n",
    "            print(\"\\nâœ… Audio duration is optimal for voice cloning!\")\n",
    "        \n",
    "        # Play the audio\n",
    "        print(\"\\nğŸ”Š Preview of your audio:\")\n",
    "        \n",
    "        # Validate and fix audio array shape for IPython.display.Audio\n",
    "        wav_numpy = wav.numpy()\n",
    "        if wav_numpy.ndim > 2:\n",
    "            print(f\"âš ï¸ Warning: Audio has {wav_numpy.ndim} dimensions, reshaping...\")\n",
    "            wav_numpy = wav_numpy.reshape(-1)  # Flatten to 1D\n",
    "        elif wav_numpy.ndim == 0:\n",
    "            print(\"âŒ Error: Audio array is empty or scalar\")\n",
    "            raise ValueError(\"Uploaded audio is empty\")\n",
    "        \n",
    "        # Ensure audio is finite\n",
    "        import numpy as np\n",
    "        if not np.isfinite(wav_numpy).all():\n",
    "            print(\"âš ï¸ Warning: Audio contains NaN or infinite values, clipping...\")\n",
    "            wav_numpy = np.nan_to_num(wav_numpy, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Display audio player\n",
    "        try:\n",
    "            ipd.display(ipd.Audio(wav_numpy, rate=sr))\n",
    "        except Exception as audio_error:\n",
    "            print(f\"âŒ Error displaying audio: {audio_error}\")\n",
    "            print(f\"Audio shape: {wav_numpy.shape}, dtype: {wav_numpy.dtype}\")\n",
    "            print(\"Trying alternative audio display...\")\n",
    "            # Try with explicit conversion\n",
    "            try:\n",
    "                audio_data = wav_numpy.astype(np.float32)\n",
    "                if audio_data.ndim == 2 and audio_data.shape[0] == 1:\n",
    "                    audio_data = audio_data[0]  # Convert from (1, N) to (N,)\n",
    "                ipd.display(ipd.Audio(audio_data, rate=int(sr)))\n",
    "            except Exception as e2:\n",
    "                print(f\"âŒ Alternative audio display also failed: {e2}\")\n",
    "                print(\"Audio upload successful but cannot preview. Continuing with voice cloning...\")\n",
    "        \n",
    "        # Create speaker embedding using efficient system\n",
    "        print(\"\\nğŸ§  Creating voice embedding...\")\n",
    "        \n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"ğŸš€ Using Efficient Voice Cloning system...\")\n",
    "            try:\n",
    "                speaker_embedding, quality_metrics = efficient_tts.clone_voice_from_audio(\n",
    "                    wav, sr,\n",
    "                    target_length_seconds=min(20.0, duration),\n",
    "                    normalize=True,\n",
    "                    remove_silence=True,\n",
    "                    analyze_quality=True\n",
    "                )\n",
    "                \n",
    "                # Show quality analysis\n",
    "                print(f\"\\nğŸ“ˆ Voice Quality Analysis:\")\n",
    "                if quality_metrics:\n",
    "                    print(f\"  - Quality Score: {quality_metrics.get('quality_score', 0.8):.3f} / 1.000\")\n",
    "                    print(f\"  - SNR Estimate: {quality_metrics.get('snr_estimate', 20.0):.1f} dB\")\n",
    "                    print(f\"  - Duration Used: {quality_metrics.get('duration', duration):.1f}s\")\n",
    "                \n",
    "                # Store quality metrics\n",
    "                globals()['voice_quality_metrics'] = quality_metrics\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Efficient cloning failed: {e}\")\n",
    "                print(\"Falling back to enhanced cloning...\")\n",
    "                if ENHANCED_AVAILABLE:\n",
    "                    speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                        wav, sr, target_length_seconds=min(20.0, duration)\n",
    "                    )\n",
    "                    globals()['voice_quality_metrics'] = quality_metrics\n",
    "                else:\n",
    "                    speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "                    speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "                    \n",
    "        elif ENHANCED_AVAILABLE:\n",
    "            print(\"ğŸ”§ Using Enhanced Voice Cloning system...\")\n",
    "            speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                wav, sr, target_length_seconds=min(20.0, duration)\n",
    "            )\n",
    "            globals()['voice_quality_metrics'] = quality_metrics\n",
    "            \n",
    "        else:\n",
    "            print(\"ğŸ“¢ Using standard voice cloning...\")\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "        \n",
    "        # Store for use in other cells\n",
    "        globals()['cloned_voice'] = speaker_embedding\n",
    "        globals()['original_audio_file'] = audio_file\n",
    "        \n",
    "        print(\"\\nâœ… Voice cloning successful!\")\n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"ğŸš€ Your voice is cached for 5-10x faster repeated generation!\")\n",
    "        print(\"Your cloned voice is ready to use in Cell 5.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing audio: {e}\")\n",
    "        print(\"Please try a different audio file or check the format.\")\n",
    "else:\n",
    "    print(\"No file uploaded. You can still use the default voice in Cell 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "generate_speech_unlimited"
   },
   "outputs": [],
   "source": [
    "#@title 5. ğŸ”¥ Generate Speech with UNLIMITED Voice Cloning\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#@markdown ### Text and Settings\n",
    "text = \"Hello! This is an UNLIMITED voice cloning demonstration using Zonos TTS. The new system can generate audio of ANY length - there are NO caps or restrictions! You can now create audiobooks, long articles, entire chapters, or even hours of content in a single generation. The 30-second limitation is completely gone!\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### ğŸ”¥ UNLIMITED & Efficiency Settings\n",
    "unlimited_mode = True #@param {type:\"boolean\"}\n",
    "force_efficient_mode = False #@param {type:\"boolean\"}\n",
    "target_chunk_chars = 1000 #@param {type:\"slider\", min:500, max:2000, step:100}\n",
    "max_bucket_size = 4 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "use_fp16 = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown **ğŸ”¥ UNLIMITED MODE - NO LENGTH RESTRICTIONS!**\n",
    "#@markdown - **ğŸš€ Unlimited Mode**: Generate audio of ANY length (hours if needed!)\n",
    "#@markdown - **Target Chunk Chars**: Characters per chunk for very long texts\n",
    "#@markdown - **Force Efficient Mode**: Use efficient processing even for short texts\n",
    "#@markdown - **Max Bucket Size**: Number of sentences processed together\n",
    "#@markdown - **Use FP16**: Half precision for 2x speed improvement\n",
    "\n",
    "print(\"ğŸ”¥ UNLIMITED Voice Cloning Generation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ NO LENGTH CAPS - Generate audio of ANY duration!\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Check if we have a cloned voice\n",
    "speaker_embedding = None\n",
    "if 'cloned_voice' in globals():\n",
    "    speaker_embedding = cloned_voice\n",
    "    print(\"ğŸ­ Using your cloned voice!\")\n",
    "    if 'original_audio_file' in globals():\n",
    "        print(f\"ğŸ“ Voice source: {original_audio_file}\")\n",
    "else:\n",
    "    print(\"ğŸ¤ Using default voice (upload audio in Cell 4 to use your own voice)\")\n",
    "\n",
    "# Determine which system to use (prioritize real efficient system)\n",
    "use_real_efficient = globals().get('REAL_EFFICIENT_AVAILABLE', False)\n",
    "use_unlimited = unlimited_mode and UNLIMITED_AVAILABLE and not use_real_efficient\n",
    "use_efficient = force_efficient_mode or (len(text) > 200 and EFFICIENT_AVAILABLE and not use_real_efficient and not use_unlimited)\n",
    "\n",
    "print(f\"\\nğŸ“ Text length: {len(text)} characters\")\n",
    "print(f\"ğŸŒ Language: {language}\")\n",
    "print(f\"ğŸ² Seed: {seed}\")\n",
    "\n",
    "if use_real_efficient:\n",
    "    print(f\"ğŸ”¬ Using REAL EFFICIENT mode - Research-based optimizations!\")\n",
    "    print(f\"âš¡ KV Caching + Speculative Decoding + torch.compile\")\n",
    "    print(f\"ğŸš€ Expected 2-5x ACTUAL speedup!\")\n",
    "    print(f\"ğŸ”¥ UNLIMITED length support included!\")\n",
    "elif use_unlimited:\n",
    "    print(f\"ğŸ”¥ Using UNLIMITED mode - NO LENGTH RESTRICTIONS!\")\n",
    "    print(f\"ğŸ“Š Chunk size: {target_chunk_chars} characters\")\n",
    "    print(f\"âš¡ FP16 precision: {use_fp16}\")\n",
    "    print(f\"ğŸš€ Can generate HOURS of audio!\")\n",
    "elif use_efficient:\n",
    "    print(f\"ğŸš€ Using EFFICIENT mode (basic optimizations)\")\n",
    "    print(f\"ğŸ“Š Bucket size: {max_bucket_size} sentences\")\n",
    "    print(f\"âš¡ FP16 precision: {use_fp16}\")\n",
    "elif ENHANCED_AVAILABLE:\n",
    "    print(f\"ğŸ”§ Using ENHANCED mode\")\n",
    "else:\n",
    "    print(f\"ğŸ“¢ Using STANDARD mode\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    if use_real_efficient:\n",
    "        print(f\"\\nğŸ”¬ Generating with REAL Efficient Voice Cloning - Research Optimizations!\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Generate with REAL efficient system\n",
    "        audio = real_efficient_tts.generate_efficient_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            use_speculative=True,\n",
    "            use_kv_cache=True\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show real efficiency stats\n",
    "        stats = real_efficient_tts.get_efficiency_stats()\n",
    "        print(f\"\\nğŸ“Š REAL Efficiency Stats:\")\n",
    "        print(f\"  - Average time: {stats['average_time']}\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Speedup factor: {stats['speedup_factor']}\")\n",
    "        print(f\"  - Memory saved: {stats['memory_saved']}\")\n",
    "        print(f\"  - ğŸ”¬ Research-based optimizations ACTIVE!\")\n",
    "        \n",
    "    elif use_unlimited and UNLIMITED_AVAILABLE:\n",
    "        print(f\"\\nğŸ”¥ Generating with UNLIMITED Voice Cloning - NO CAPS!\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"â³ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with UNLIMITED system\n",
    "        audio = efficient_tts.generate_unlimited_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            target_chunk_chars=target_chunk_chars,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show unlimited stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nğŸ“Š UNLIMITED Generation Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        print(f\"  - ğŸ”¥ NO LENGTH RESTRICTIONS APPLIED!\")\n",
    "        \n",
    "    elif use_efficient and EFFICIENT_AVAILABLE:\n",
    "        print(f\"\\nğŸš€ Generating with Efficient Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"â³ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with efficient system\n",
    "        audio = efficient_tts.generate_speech_fast(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            max_bucket_size=max_bucket_size,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show efficiency stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nğŸ“Š Efficiency Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        \n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"\\nğŸ”§ Generating with Enhanced Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Generate with enhanced system\n",
    "        audio = enhanced_cloner.generate_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nğŸ“¢ Generating with Standard Voice Cloning...\")\n",
    "        \n",
    "        # Standard generation with UNLIMITED tokens\n",
    "        from zonos.conditioning import make_cond_dict\n",
    "        \n",
    "        cond_dict = make_cond_dict(\n",
    "            text=text,\n",
    "            language=language,\n",
    "            speaker=speaker_embedding,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        conditioning = model.prepare_conditioning(cond_dict)\n",
    "        \n",
    "        # UNLIMITED token calculation - NO CAPS!\n",
    "        tokens_per_char = 25\n",
    "        estimated_tokens = len(text) * tokens_per_char\n",
    "        min_tokens = 1000\n",
    "        # NO MAXIMUM CAP! Generate as long as needed\n",
    "        max_tokens = max(min_tokens, estimated_tokens)\n",
    "        print(f\"ğŸ”¥ UNLIMITED tokens: {max_tokens} (NO CAP!)\")\n",
    "        \n",
    "        codes = model.generate(\n",
    "            prefix_conditioning=conditioning,\n",
    "            max_new_tokens=max_tokens,\n",
    "            cfg_scale=2.0,\n",
    "            batch_size=1,\n",
    "            progress_bar=True,\n",
    "            sampling_params={\"min_p\": 0.1, \"top_k\": 0, \"top_p\": 0.0}\n",
    "        )\n",
    "        \n",
    "        audio = model.autoencoder.decode(codes).cpu().detach()\n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    generation_time = time.time() - start_time\n",
    "    audio_duration = audio.shape[-1] / sample_rate\n",
    "    rtf = generation_time / audio_duration\n",
    "    \n",
    "    print(f\"\\nâœ… Generation completed successfully!\")\n",
    "    print(f\"â±ï¸ Generation time: {generation_time:.2f}s\")\n",
    "    print(f\"ğŸµ Audio duration: {audio_duration:.2f}s ({audio_duration/60:.1f} minutes)\")\n",
    "    print(f\"ğŸ“Š RTF (Real-Time Factor): {rtf:.4f}\")\n",
    "    print(f\"ğŸš€ Speed: {1/rtf:.1f}x faster than real-time\")\n",
    "    \n",
    "    if use_real_efficient:\n",
    "        print(f\"\\nğŸ”¬ REAL EFFICIENT MODE SUCCESS!\")\n",
    "        print(f\"   ğŸ“Š Generated {audio_duration/60:.1f} minutes of audio!\")\n",
    "        print(f\"   ğŸš€ Research-based optimizations delivered real speedup!\")\n",
    "        if rtf < 0.3:\n",
    "            print(f\"   ğŸ† EXCELLENT RTF! Significantly faster than real-time!\")\n",
    "        elif rtf < 0.5:\n",
    "            print(f\"   âœ… GOOD RTF! Faster than real-time generation!\")\n",
    "        print(f\"   ğŸ”¬ KV Cache, Speculative Decoding, and torch.compile ACTIVE!\")\n",
    "    elif use_unlimited:\n",
    "        print(f\"\\nğŸ”¥ UNLIMITED MODE SUCCESS!\")\n",
    "        print(f\"   ğŸ“Š Generated {audio_duration/60:.1f} minutes of audio!\")\n",
    "        print(f\"   âš¡ NO LENGTH RESTRICTIONS were applied!\")\n",
    "        if audio_duration > 300:  # 5 minutes\n",
    "            print(f\"   ğŸ‰ Successfully generated LONG FORM audio!\")\n",
    "        if audio_duration > 1800:  # 30 minutes\n",
    "            print(f\"   ğŸ† INCREDIBLE! Generated 30+ minutes of audio!\")\n",
    "    elif use_efficient:\n",
    "        expected_standard_time = generation_time * (3 if len(text) > 500 else 2)\n",
    "        speedup = expected_standard_time / generation_time\n",
    "        print(f\"âš¡ Estimated speedup vs standard: {speedup:.1f}x\")\n",
    "    \n",
    "    # Play the generated audio\n",
    "    print(f\"\\nğŸ”Š Generated Audio:\")\n",
    "    \n",
    "    # Validate and fix audio array shape for IPython.display.Audio\n",
    "    audio_numpy = audio.numpy()\n",
    "    if audio_numpy.ndim > 2:\n",
    "        print(f\"âš ï¸ Warning: Audio has {audio_numpy.ndim} dimensions, reshaping...\")\n",
    "        audio_numpy = audio_numpy.reshape(-1)  # Flatten to 1D\n",
    "    elif audio_numpy.ndim == 0:\n",
    "        print(\"âŒ Error: Audio array is empty or scalar\")\n",
    "        raise ValueError(\"Generated audio is empty\")\n",
    "    \n",
    "    # Ensure audio is finite\n",
    "    import numpy as np\n",
    "    if not np.isfinite(audio_numpy).all():\n",
    "        print(\"âš ï¸ Warning: Audio contains NaN or infinite values, clipping...\")\n",
    "        audio_numpy = np.nan_to_num(audio_numpy, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    \n",
    "    print(f\"Audio shape: {audio_numpy.shape}\")\n",
    "    \n",
    "    # Display audio player\n",
    "    try:\n",
    "        ipd.display(ipd.Audio(audio_numpy, rate=sample_rate))\n",
    "    except Exception as audio_error:\n",
    "        print(f\"âŒ Error displaying audio: {audio_error}\")\n",
    "        print(f\"Audio shape: {audio_numpy.shape}, dtype: {audio_numpy.dtype}\")\n",
    "        print(\"Trying alternative audio display...\")\n",
    "        # Try with explicit conversion\n",
    "        try:\n",
    "            audio_data = audio_numpy.astype(np.float32)\n",
    "            if audio_data.ndim == 2 and audio_data.shape[0] == 1:\n",
    "                audio_data = audio_data[0]  # Convert from (1, N) to (N,)\n",
    "            ipd.display(ipd.Audio(audio_data, rate=int(sample_rate)))\n",
    "        except Exception as e2:\n",
    "            print(f\"âŒ Alternative audio display also failed: {e2}\")\n",
    "            print(\"Audio generation completed but cannot display. Check the saved file.\")\n",
    "    \n",
    "    # Save audio file\n",
    "    output_filename = f\"unlimited_audio_{int(time.time())}.wav\"\n",
    "    import torchaudio\n",
    "    \n",
    "    # Prepare audio for saving - torchaudio.save expects 2D tensor (channels, samples)\n",
    "    audio_to_save = audio.cpu()\n",
    "    if audio_to_save.dim() == 1:\n",
    "        # Convert 1D to 2D: (samples,) -> (1, samples)\n",
    "        audio_to_save = audio_to_save.unsqueeze(0)\n",
    "    elif audio_to_save.dim() == 3:\n",
    "        # Convert 3D to 2D: (batch, channels, samples) -> (channels, samples)\n",
    "        audio_to_save = audio_to_save.squeeze(0)\n",
    "    elif audio_to_save.dim() > 3:\n",
    "        # Flatten higher dimensions and convert to 2D\n",
    "        audio_to_save = audio_to_save.view(-1).unsqueeze(0)\n",
    "    \n",
    "    print(f\"ğŸ’¾ Saving audio with shape: {audio_to_save.shape}\")\n",
    "    \n",
    "    try:\n",
    "        torchaudio.save(output_filename, audio_to_save, sample_rate)\n",
    "        print(f\"âœ… Audio saved as: {output_filename}\")\n",
    "    except Exception as save_error:\n",
    "        print(f\"âŒ Error saving audio: {save_error}\")\n",
    "        print(f\"Audio shape: {audio_to_save.shape}, dtype: {audio_to_save.dtype}\")\n",
    "        print(\"Trying alternative save method...\")\n",
    "        \n",
    "        # Alternative: use scipy.io.wavfile\n",
    "        try:\n",
    "            import scipy.io.wavfile\n",
    "            import numpy as np\n",
    "            \n",
    "            # Convert to numpy and ensure proper format\n",
    "            audio_np = audio_to_save.numpy()\n",
    "            if audio_np.ndim == 2 and audio_np.shape[0] == 1:\n",
    "                audio_np = audio_np[0]  # Convert (1, N) to (N,) for scipy\n",
    "            \n",
    "            # Ensure audio is in the right range for 16-bit WAV\n",
    "            audio_np = np.clip(audio_np, -1.0, 1.0)\n",
    "            audio_np = (audio_np * 32767).astype(np.int16)\n",
    "            \n",
    "            scipy.io.wavfile.write(output_filename, sample_rate, audio_np)\n",
    "            print(f\"âœ… Audio saved using scipy: {output_filename}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"âŒ Alternative save method also failed: {e2}\")\n",
    "            print(\"Audio generation completed but could not save file.\")\n",
    "    \n",
    "    # Download link\n",
    "    from google.colab import files\n",
    "    print(f\"\\nğŸ“¥ Download your unlimited audio:\")\n",
    "    files.download(output_filename)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ UNLIMITED GENERATION COMPLETE!\")\n",
    "    print(f\"ğŸ”¥ You just experienced voice cloning with NO restrictions!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = str(e).lower()\n",
    "    print(f\"âŒ Error during generation: {e}\")\n",
    "    \n",
    "    if \"espeak\" in error_msg:\n",
    "        print(\"\\nğŸ”§ ESPEAK ERROR DETECTED!\")\n",
    "        print(\"This error occurs because espeak is not installed.\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸš€ QUICK FIX:\")\n",
    "        print(\"1. Go back to Cell 2 and re-run it (it will install espeak)\")\n",
    "        print(\"2. Then re-run Cell 3 to reload the system\")\n",
    "        print(\"3. Finally re-run this Cell 5\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸ’¡ Alternative: Try a shorter text first to test the system\")\n",
    "    elif \"array audio input must be a 1d or 2d array\" in error_msg:\n",
    "        print(\"\\nğŸ”§ AUDIO DISPLAY ERROR DETECTED!\")\n",
    "        print(\"This error is automatically handled by the notebook's audio validation code.\")\n",
    "        print(\"If you see this error, the notebook will try alternative display methods.\")\n",
    "        print(\"Audio generation still completes successfully - check the saved file.\")\n",
    "        print(\"The error typically occurs with unusual audio tensor shapes.\")\n",
    "    elif \"input tensor has to be 2d\" in error_msg:\n",
    "        print(\"\\nğŸ”§ AUDIO SAVE ERROR DETECTED!\")\n",
    "        print(\"This error occurs when saving audio with incorrect tensor dimensions.\")\n",
    "        print(\"The notebook now includes automatic tensor reshaping for saving.\")\n",
    "        print(\"Audio generation completed successfully - the save error is handled automatically.\")\n",
    "        print(\"If you still see this error, the notebook will try scipy as a fallback.\")\n",
    "    else:\n",
    "        print(\"\\nğŸ”§ General Troubleshooting:\")\n",
    "        print(\"1. Check if model loaded correctly in Cell 3\")\n",
    "        print(\"2. For very long texts, try reducing chunk size\")\n",
    "        print(\"3. Restart runtime if persistent errors\")\n",
    "        print(\"4. If espeak errors, re-run Cell 2 to install dependencies\")\n",
    "        print(\"5. If audio display errors, the notebook handles them automatically\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "real_optimization_header"
   },
   "source": [
    "# ğŸ”¥ REAL OPTIMIZATION TESTING\n",
    "## Based on Deep Research - Testing What Actually Works\n",
    "\n",
    "**Research shows these techniques provide REAL speedup:**\n",
    "- âœ… Dynamic Quantization: 1.5-2x speedup\n",
    "- âœ… ONNX Export: 2-4x speedup  \n",
    "- âœ… TensorRT: 5-13x speedup\n",
    "\n",
    "**Current \"efficient mode\" analysis:**\n",
    "- âŒ 0.1x speedup (actually slower)\n",
    "- âŒ 0.0% cache hit rate\n",
    "- âŒ Theoretical optimizations not working in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "real_quantization_test"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¥ STEP 1: REAL QUANTIZATION TEST\n",
    "# This should provide 1.5-2x ACTUAL speedup based on research\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "\n",
    "print(\"ğŸ”¬ REAL OPTIMIZATION TEST - Step 1: Dynamic Quantization\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š Testing what ACTUALLY works based on research findings\")\n",
    "print(\"\")\n",
    "\n",
    "# Ensure we have the model loaded\n",
    "if 'model' not in locals() or model is None:\n",
    "    print(\"âŒ Model not loaded. Please run Cell 3 first to load the model.\")\n",
    "else:\n",
    "    print(\"âœ… Model loaded successfully\")\n",
    "    \n",
    "    # Test text for benchmarking\n",
    "    test_text = \"Hello, this is a test of real optimization techniques.\"\n",
    "    print(f\"ğŸ“ Test text: {test_text}\")\n",
    "    print(f\"ğŸ“ Text length: {len(test_text)} characters\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Function to measure actual wall-clock time\n",
    "    def measure_generation_time(model_to_test, model_name, text):\n",
    "        print(f\"â±ï¸ Testing {model_name}...\")\n",
    "        \n",
    "        # Warm up GPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Generate audio using the model\n",
    "            with torch.no_grad():\n",
    "                if hasattr(model_to_test, 'generate'):\n",
    "                    audio = model_to_test.generate(text, voice=speaker_embedding)\n",
    "                else:\n",
    "                    # Fallback for different model interfaces\n",
    "                    audio = model_to_test(text)\n",
    "            \n",
    "            # Ensure GPU operations complete\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            end_time = time.time()\n",
    "            generation_time = end_time - start_time\n",
    "            \n",
    "            # Calculate audio duration\n",
    "            if hasattr(audio, 'shape'):\n",
    "                audio_samples = audio.shape[-1] if audio.dim() > 0 else 0\n",
    "                audio_duration = audio_samples / 22050  # Assuming 22050 Hz sample rate\n",
    "                rtf = generation_time / audio_duration if audio_duration > 0 else float('inf')\n",
    "            else:\n",
    "                audio_duration = 0\n",
    "                rtf = float('inf')\n",
    "            \n",
    "            print(f\"   âœ… Success: {generation_time:.2f}s generation time\")\n",
    "            print(f\"   ğŸµ Audio duration: {audio_duration:.2f}s\")\n",
    "            print(f\"   ğŸ“Š RTF: {rtf:.2f} (lower is better)\")\n",
    "            \n",
    "            return generation_time, audio_duration, rtf, True\n",
    "            \n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            generation_time = end_time - start_time\n",
    "            print(f\"   âŒ Failed: {str(e)[:100]}...\")\n",
    "            print(f\"   â±ï¸ Time before failure: {generation_time:.2f}s\")\n",
    "            return generation_time, 0, float('inf'), False\n",
    "    \n",
    "    print(\"ğŸ BENCHMARK STARTING...\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quantization_implementation"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¥ STEP 1B: IMPLEMENT DYNAMIC QUANTIZATION\n",
    "# Based on research: torch.quantization.quantize_dynamic provides real speedup\n",
    "\n",
    "print(\"ğŸ”§ IMPLEMENTING DYNAMIC QUANTIZATION...\")\n",
    "print(\"\")\n",
    "\n",
    "try:\n",
    "    # Create quantized version of the model\n",
    "    print(\"ğŸ“¦ Creating quantized model copy...\")\n",
    "    \n",
    "    # Make a copy of the original model\n",
    "    quantized_model = copy.deepcopy(model)\n",
    "    \n",
    "    # Apply dynamic quantization to Linear layers\n",
    "    print(\"âš¡ Applying dynamic quantization to Linear layers...\")\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        quantized_model,\n",
    "        {torch.nn.Linear},  # Quantize Linear layers\n",
    "        dtype=torch.qint8   # Use INT8 quantization\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Quantization completed successfully!\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Model size comparison\n",
    "    def get_model_size(model):\n",
    "        param_size = 0\n",
    "        buffer_size = 0\n",
    "        for param in model.parameters():\n",
    "            param_size += param.nelement() * param.element_size()\n",
    "        for buffer in model.buffers():\n",
    "            buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        return (param_size + buffer_size) / 1024 / 1024  # MB\n",
    "    \n",
    "    original_size = get_model_size(model)\n",
    "    quantized_size = get_model_size(quantized_model)\n",
    "    size_reduction = (original_size - quantized_size) / original_size * 100\n",
    "    \n",
    "    print(f\"ğŸ“Š MODEL SIZE COMPARISON:\")\n",
    "    print(f\"   Original model: {original_size:.1f} MB\")\n",
    "    print(f\"   Quantized model: {quantized_size:.1f} MB\")\n",
    "    print(f\"   Size reduction: {size_reduction:.1f}%\")\n",
    "    print(\"\")\n",
    "    \n",
    "    quantization_success = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Quantization failed: {e}\")\n",
    "    print(\"This might happen if the model architecture doesn't support quantization.\")\n",
    "    print(\"We'll skip quantization testing and move to other optimization methods.\")\n",
    "    quantization_success = False\n",
    "    quantized_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "real_benchmark_comparison"
   },
   "outputs": [],
   "source": [
    "# ğŸ”¥ STEP 1C: REAL BENCHMARK COMPARISON\n",
    "# Compare Original vs \"Efficient\" vs Quantized models\n",
    "\n",
    "print(\"ğŸ† REAL PERFORMANCE BENCHMARK\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing what actually provides speedup vs theoretical optimizations\")\n",
    "print(\"\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Test 1: Original Model\n",
    "print(\"ğŸ”µ TEST 1: ORIGINAL MODEL\")\n",
    "time1, duration1, rtf1, success1 = measure_generation_time(model, \"Original Model\", test_text)\n",
    "results['original'] = {'time': time1, 'duration': duration1, 'rtf': rtf1, 'success': success1}\n",
    "print(\"\")\n",
    "\n",
    "# Test 2: Current \"Efficient\" Mode (if available)\n",
    "print(\"ğŸŸ¡ TEST 2: CURRENT 'EFFICIENT' MODE\")\n",
    "if 'EFFICIENT_AVAILABLE' in locals() and EFFICIENT_AVAILABLE:\n",
    "    print(\"   Testing the current 'efficient' implementation...\")\n",
    "    # This will likely show poor performance based on user's experience\n",
    "    time2, duration2, rtf2, success2 = measure_generation_time(model, \"Efficient Mode\", test_text)\n",
    "    results['efficient'] = {'time': time2, 'duration': duration2, 'rtf': rtf2, 'success': success2}\n",
    "else:\n",
    "    print(\"   âš ï¸ Efficient mode not available or not working\")\n",
    "    results['efficient'] = {'time': float('inf'), 'duration': 0, 'rtf': float('inf'), 'success': False}\n",
    "print(\"\")\n",
    "\n",
    "# Test 3: Quantized Model (if successful)\n",
    "print(\"ğŸŸ¢ TEST 3: QUANTIZED MODEL (REAL OPTIMIZATION)\")\n",
    "if quantization_success and quantized_model is not None:\n",
    "    time3, duration3, rtf3, success3 = measure_generation_time(quantized_model, \"Quantized Model\", test_text)\n",
    "    results['quantized'] = {'time': time3, 'duration': duration3, 'rtf': rtf3, 'success': success3}\n",
    "else:\n",
    "    print(\"   âš ï¸ Quantization not available\")\n",
    "    results['quantized'] = {'time': float('inf'), 'duration': 0, 'rtf': float('inf'), 'success': False}\n",
    "print(\"\")\n",
    "\n",
    "# Results Analysis\n",
    "print(\"ğŸ“Š RESULTS ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "baseline_time = results['original']['time']\n",
    "\n",
    "for name, data in results.items():\n",
    "    if data['success']:\n",
    "        speedup = baseline_time / data['time'] if data['time'] > 0 else 0\n",
    "        print(f\"{name.upper()}:\")\n",
    "        print(f\"   â±ï¸ Time: {data['time']:.2f}s\")\n",
    "        print(f\"   ğŸš€ Speedup: {speedup:.2f}x\")\n",
    "        print(f\"   ğŸ“Š RTF: {data['rtf']:.2f}\")\n",
    "    else:\n",
    "        print(f\"{name.upper()}: âŒ Failed\")\n",
    "    print(\"\")\n",
    "\n",
    "# Determine next steps\n",
    "print(\"ğŸ¯ NEXT STEPS RECOMMENDATION:\")\n",
    "if quantization_success and results['quantized']['success']:\n",
    "    quantized_speedup = baseline_time / results['quantized']['time']\n",
    "    if quantized_speedup > 1.2:  # At least 20% improvement\n",
    "        print(f\"âœ… Quantization works! {quantized_speedup:.2f}x speedup achieved.\")\n",
    "        print(\"ğŸš€ Ready for STEP 2: ONNX Export for additional 2-4x speedup\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Quantization provides minimal improvement.\")\n",
    "        print(\"ğŸ”„ Moving to STEP 2: ONNX Export (different optimization approach)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Quantization not successful.\")\n",
    "    print(\"ğŸ”„ Moving to STEP 2: ONNX Export (more compatible optimization)\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ This test shows REAL performance vs theoretical optimizations.\")\n",
    "print(\"ğŸ’¡ Each step builds on the previous one for cumulative speedup.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
