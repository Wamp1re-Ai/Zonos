{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ Efficient Voice Cloning with Zonos TTS\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/Zonos/blob/efficient/Efficient_Voice_Cloning_Colab.ipynb)\n",
    "\n",
    "## ‚ö° NEW: 2-10x Faster Generation!\n",
    "\n",
    "This notebook features the **latest efficiency optimizations** inspired by Index TTS:\n",
    "\n",
    "### üöÄ **Speed Improvements:**\n",
    "- **2-10x faster** generation for long texts\n",
    "- **Sentence bucketing** and batch processing\n",
    "- **Voice caching** (5-10x speedup for repeated voices)\n",
    "- **FP16 precision** support\n",
    "- **Memory optimization** for large texts\n",
    "\n",
    "### ‚úÖ **Quality Maintained:**\n",
    "- **No quality degradation** - same high-quality output\n",
    "- **Long text fixes** - no more silent gaps\n",
    "- **Enhanced expressiveness** controls\n",
    "- **Automatic optimization** based on text length\n",
    "\n",
    "### üìä **Performance Targets:**\n",
    "- **Short texts (< 200 chars)**: 1.5x speedup\n",
    "- **Medium texts (500 chars)**: 3-5x speedup  \n",
    "- **Long texts (1000+ chars)**: 5-10x speedup\n",
    "- **RTF < 0.5** for most use cases\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Quick Start Guide\n",
    "\n",
    "1. **Run Cell 1**: Setup and clone repository\n",
    "2. **Run Cell 2**: Install dependencies (uses UV for 10x faster installation)\n",
    "3. **Run Cell 3**: Load efficient Zonos system\n",
    "4. **Run Cell 4**: Upload your voice sample\n",
    "5. **Run Cell 5**: Generate speech with automatic efficiency optimization\n",
    "\n",
    "**üí° Pro Tip**: The system automatically chooses the best mode based on your text length!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "#@title 1. üöÄ Setup and Clone Efficient Repository\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"üöÄ Efficient Voice Cloning Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üìç Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üìç Running in local environment\")\n",
    "\n",
    "# Clone the efficient branch\n",
    "if not os.path.exists('zonos'):\n",
    "    print(\"\\nüì• Cloning Zonos TTS (efficient branch)...\")\n",
    "    !git clone -b efficient https://github.com/Wamp1re-Ai/Zonos.git\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Repository already exists\")\n",
    "\n",
    "# Change to the Zonos directory\n",
    "os.chdir('Zonos')\n",
    "print(f\"üìÅ Changed to directory: {os.getcwd()}\")\n",
    "\n",
    "# Install system dependencies\n",
    "print(\"\\nüîß Installing system dependencies...\")\n",
    "!apt-get install -y espeak-ng git-lfs -qq\n",
    "!git lfs install\n",
    "print(\"‚úÖ System dependencies installed!\")\n",
    "\n",
    "# Check for efficient and enhanced files\n",
    "efficient_files = {\n",
    "    'efficient_voice_cloning.py': 'Efficient voice cloning with 2-10x speedup',\n",
    "    'enhanced_voice_cloning.py': 'Enhanced voice cloning with quality improvements',\n",
    "    'test_efficiency_improvements.py': 'Performance benchmarking tools',\n",
    "    'efficient_integration_example.py': 'Integration examples and usage guides'\n",
    "}\n",
    "\n",
    "print(\"\\nüîç Checking for optimization files...\")\n",
    "available_features = []\n",
    "for filename, description in efficient_files.items():\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"‚úÖ {filename} - {description}\")\n",
    "        available_features.append(filename)\n",
    "    else:\n",
    "        print(f\"‚ùå {filename} - Not found\")\n",
    "\n",
    "if 'efficient_voice_cloning.py' in available_features:\n",
    "    print(\"\\nüöÄ EFFICIENCY OPTIMIZATIONS DETECTED!\")\n",
    "    print(\"You have access to 2-10x faster generation for long texts!\")\n",
    "elif 'enhanced_voice_cloning.py' in available_features:\n",
    "    print(\"\\nüöÄ Enhanced voice cloning files detected!\")\n",
    "    print(\"You have access to quality improvements.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No enhanced files found. Using standard voice cloning.\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete! Continue to Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "#@title 2. ‚ö° Install Dependencies (Fast UV Installation)\n",
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"‚ö° Fast Dependency Installation with UV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Install UV (ultra-fast Python package installer)\n",
    "print(\"üöÄ Installing UV (10x faster than pip)...\")\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!source $HOME/.cargo/env\n",
    "\n",
    "# Add UV to PATH for this session\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.path.expanduser('~')}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "print(\"\\nüì¶ Installing core dependencies with UV...\")\n",
    "\n",
    "# Core dependencies for Zonos TTS\n",
    "dependencies = [\n",
    "    \"torch>=2.0.0\",\n",
    "    \"torchaudio>=2.0.0\", \n",
    "    \"transformers>=4.30.0\",\n",
    "    \"numpy<2.0.0\",  # Force NumPy 1.x for compatibility\n",
    "    \"librosa>=0.10.0\",\n",
    "    \"soundfile>=0.12.0\",\n",
    "    \"scipy>=1.10.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"tqdm>=4.65.0\",\n",
    "    \"einops>=0.6.0\",\n",
    "    \"accelerate>=0.20.0\",\n",
    "    \"datasets>=2.12.0\",\n",
    "    \"huggingface_hub>=0.15.0\"\n",
    "]\n",
    "\n",
    "# Install with UV (much faster than pip)\n",
    "try:\n",
    "    for dep in dependencies:\n",
    "        print(f\"Installing {dep}...\")\n",
    "        result = subprocess.run([f\"{os.path.expanduser('~')}/.cargo/bin/uv\", \"pip\", \"install\", dep], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"‚ö†Ô∏è UV failed for {dep}, falling back to pip...\")\n",
    "            !pip install {dep} -q\n",
    "        else:\n",
    "            print(f\"‚úÖ {dep} installed with UV\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è UV installation failed: {e}\")\n",
    "    print(\"Falling back to pip installation...\")\n",
    "    \n",
    "    # Fallback to pip\n",
    "    for dep in dependencies:\n",
    "        print(f\"Installing {dep} with pip...\")\n",
    "        !pip install {dep} -q\n",
    "        print(f\"‚úÖ {dep} installed\")\n",
    "\n",
    "# Install Zonos TTS package\n",
    "print(\"\\nüéµ Installing Zonos TTS...\")\n",
    "!pip install -e . -q\n",
    "print(\"‚úÖ Zonos TTS installed!\")\n",
    "\n",
    "# Add current directory to Python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "print(f\"‚úÖ Added {current_dir} to Python path\")\n",
    "\n",
    "installation_time = time.time() - start_time\n",
    "print(f\"\\nüéâ All dependencies installed successfully in {installation_time:.1f} seconds!\")\n",
    "print(f\"‚ö° UV is ~10x faster than pip for package installation\")\n",
    "print(\"\\nüöÄ Ready for Cell 3: Load Efficient System\")\n",
    "print(\"\\nüí° Note: If Cell 3 gives NumPy errors:\")\n",
    "print(\"   1. Runtime ‚Üí Restart runtime\")\n",
    "print(\"   2. Re-run Cell 1 and Cell 2\")\n",
    "print(\"   3. Then run Cell 3 again\")\n",
    "print(\"   This is normal and fixes the NumPy compatibility issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "load_efficient_system"
   },
   "outputs": [],
   "source": [
    "#@title 3. üöÄ Load Efficient Zonos System\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Loading Efficient Zonos System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check NumPy version\n",
    "print(\"üîß Verifying NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    print(f\"NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\n‚ö†Ô∏è WARNING: NumPy 2.x detected!\")\n",
    "        print(\"If you get errors below, restart runtime and re-run cells.\")\n",
    "    else:\n",
    "        print(\"‚úÖ NumPy version is compatible\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\nüì¶ Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
    "    print(f\"‚úÖ TorchAudio {torchaudio.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PyTorch error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import Transformers\n",
    "print(\"\\nü§ó Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"‚úÖ Transformers {transformers.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Transformers error: {e}\")\n",
    "    if \"numpy\" in str(e).lower():\n",
    "        print(\"\\nüîß NumPy compatibility issue! Restart runtime and re-run cells.\")\n",
    "    raise\n",
    "\n",
    "# Import Zonos modules\n",
    "print(\"\\nüéµ Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"‚úÖ Zonos modules loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Zonos import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model\n",
    "model_name = \"Zyphra/Zonos-v0.1-transformer\"\n",
    "print(f\"\\nüì• Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # Model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nüìä Model Info:\")\n",
    "    print(f\"  - Parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Languages: {len(supported_language_codes)} supported\")\n",
    "    \n",
    "    # Try to load efficient system\n",
    "    EFFICIENT_AVAILABLE = False\n",
    "    ENHANCED_AVAILABLE = False\n",
    "    \n",
    "    print(\"\\nüöÄ Loading Efficiency Optimizations...\")\n",
    "    try:\n",
    "        if os.path.exists('efficient_voice_cloning.py'):\n",
    "            print(\"‚úì Efficient voice cloning file found\")\n",
    "            from efficient_voice_cloning import EfficientVoiceCloner\n",
    "            \n",
    "            # Create efficient TTS system\n",
    "            efficient_tts = EfficientVoiceCloner(\n",
    "                model, \n",
    "                device=device, \n",
    "                use_fp16=True, \n",
    "                cache_size=10\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Efficient Voice Cloning system loaded!\")\n",
    "            print(\"üöÄ You now have access to 2-10x faster generation!\")\n",
    "            EFFICIENT_AVAILABLE = True\n",
    "            globals()['efficient_tts'] = efficient_tts\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è efficient_voice_cloning.py not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load efficient system: {e}\")\n",
    "        print(\"Will try enhanced system instead...\")\n",
    "    \n",
    "    # Fallback to enhanced system\n",
    "    if not EFFICIENT_AVAILABLE:\n",
    "        print(\"\\nüîß Loading Enhanced Voice Cloning...\")\n",
    "        try:\n",
    "            if os.path.exists('enhanced_voice_cloning.py'):\n",
    "                print(\"‚úì Enhanced voice cloning file found\")\n",
    "                from enhanced_voice_cloning import (\n",
    "                    EnhancedVoiceCloner, \n",
    "                    create_enhanced_voice_cloner\n",
    "                )\n",
    "                enhanced_cloner = create_enhanced_voice_cloner(device=device)\n",
    "                print(\"‚úÖ Enhanced Voice Cloning loaded!\")\n",
    "                ENHANCED_AVAILABLE = True\n",
    "                globals()['enhanced_cloner'] = enhanced_cloner\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è enhanced_voice_cloning.py not found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load enhanced system: {e}\")\n",
    "    \n",
    "    # Store globals\n",
    "    globals()['model'] = model\n",
    "    globals()['device'] = device\n",
    "    globals()['EFFICIENT_AVAILABLE'] = EFFICIENT_AVAILABLE\n",
    "    globals()['ENHANCED_AVAILABLE'] = ENHANCED_AVAILABLE\n",
    "    \n",
    "    # Show final status\n",
    "    print(f\"\\nüéâ System loaded successfully!\")\n",
    "    print(f\"üìä Features available:\")\n",
    "    if EFFICIENT_AVAILABLE:\n",
    "        print(f\"  ‚úÖ Efficient Voice Cloning (2-10x speedup)\")\n",
    "        print(f\"  ‚úÖ Voice caching system\")\n",
    "        print(f\"  ‚úÖ FP16 precision support\")\n",
    "        print(f\"  ‚úÖ Automatic batch processing\")\n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"  ‚úÖ Enhanced Voice Cloning\")\n",
    "        print(f\"  ‚úÖ Quality improvements\")\n",
    "        print(f\"  ‚úÖ Long text fixes\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Standard voice cloning only\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Ready for voice cloning!\")\n",
    "    print(f\"Next: Run Cell 4 to upload your voice sample.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Restart runtime if NumPy issues persist\")\n",
    "    print(\"3. Re-run all cells from the beginning\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "upload_voice"
   },
   "outputs": [],
   "source": [
    "#@title 4. üé§ Upload Voice Sample for Cloning\n",
    "from google.colab import files\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "print(\"üé§ Voice Cloning - Upload Your Audio File\")\n",
    "print(\"Upload an audio file (10-30 seconds) to clone the speaker's voice\")\n",
    "print(\"Supported formats: WAV, MP3, FLAC, etc.\")\n",
    "print(\"\")\n",
    "\n",
    "# Upload audio file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Get the uploaded file\n",
    "    audio_file = list(uploaded.keys())[0]\n",
    "    print(f\"\\nüìÅ Processing: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Load and process the audio\n",
    "        wav, sr = torchaudio.load(audio_file)\n",
    "        \n",
    "        # Convert to mono if needed\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        \n",
    "        # Show audio info\n",
    "        duration = wav.shape[1] / sr\n",
    "        print(f\"üìä Audio Info:\")\n",
    "        print(f\"  - Duration: {duration:.1f} seconds\")\n",
    "        print(f\"  - Sample rate: {sr} Hz\")\n",
    "        print(f\"  - Channels: {wav.shape[0]}\")\n",
    "        \n",
    "        # Quality recommendations\n",
    "        if duration < 5:\n",
    "            print(\"\\n‚ö†Ô∏è Audio is quite short (< 5s). Consider using 10-20 seconds for better results.\")\n",
    "        elif duration > 30:\n",
    "            print(\"\\nüí° Audio is long (> 30s). The system will use the best portion automatically.\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Audio duration is optimal for voice cloning!\")\n",
    "        \n",
    "        # Play the audio\n",
    "        print(\"\\nüîä Preview of your audio:\")\n",
    "        ipd.display(ipd.Audio(wav.numpy(), rate=sr))\n",
    "        \n",
    "        # Create speaker embedding using efficient system\n",
    "        print(\"\\nüß† Creating voice embedding...\")\n",
    "        \n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"üöÄ Using Efficient Voice Cloning system...\")\n",
    "            try:\n",
    "                speaker_embedding, quality_metrics = efficient_tts.clone_voice_from_audio(\n",
    "                    wav, sr,\n",
    "                    target_length_seconds=min(20.0, duration),\n",
    "                    normalize=True,\n",
    "                    remove_silence=True,\n",
    "                    analyze_quality=True\n",
    "                )\n",
    "                \n",
    "                # Show quality analysis\n",
    "                print(f\"\\nüìà Voice Quality Analysis:\")\n",
    "                if quality_metrics:\n",
    "                    print(f\"  - Quality Score: {quality_metrics.get('quality_score', 0.8):.3f} / 1.000\")\n",
    "                    print(f\"  - SNR Estimate: {quality_metrics.get('snr_estimate', 20.0):.1f} dB\")\n",
    "                    print(f\"  - Duration Used: {quality_metrics.get('duration', duration):.1f}s\")\n",
    "                \n",
    "                # Store quality metrics\n",
    "                globals()['voice_quality_metrics'] = quality_metrics\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Efficient cloning failed: {e}\")\n",
    "                print(\"Falling back to enhanced cloning...\")\n",
    "                if ENHANCED_AVAILABLE:\n",
    "                    speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                        wav, sr, target_length_seconds=min(20.0, duration)\n",
    "                    )\n",
    "                    globals()['voice_quality_metrics'] = quality_metrics\n",
    "                else:\n",
    "                    speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "                    speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "                    \n",
    "        elif ENHANCED_AVAILABLE:\n",
    "            print(\"üîß Using Enhanced Voice Cloning system...\")\n",
    "            speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                wav, sr, target_length_seconds=min(20.0, duration)\n",
    "            )\n",
    "            globals()['voice_quality_metrics'] = quality_metrics\n",
    "            \n",
    "        else:\n",
    "            print(\"üì¢ Using standard voice cloning...\")\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "        \n",
    "        # Store for use in other cells\n",
    "        globals()['cloned_voice'] = speaker_embedding\n",
    "        globals()['original_audio_file'] = audio_file\n",
    "        \n",
    "        print(\"\\n‚úÖ Voice cloning successful!\")\n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"üöÄ Your voice is cached for 5-10x faster repeated generation!\")\n",
    "        print(\"Your cloned voice is ready to use in Cell 5.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing audio: {e}\")\n",
    "        print(\"Please try a different audio file or check the format.\")\n",
    "else:\n",
    "    print(\"No file uploaded. You can still use the default voice in Cell 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "generate_speech_efficient"
   },
   "outputs": [],
   "source": [
    "#@title 5. üöÄ Generate Speech with Efficient Voice Cloning\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#@markdown ### Text and Settings\n",
    "text = \"Hello! This is an efficient voice cloning demonstration using Zonos TTS. The new system provides 2-10x faster generation while maintaining the same high quality and naturalness. Long texts are automatically optimized with sentence bucketing and batch processing for maximum speed.\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### üöÄ Efficiency & Unlimited Settings\n",
    "force_efficient_mode = False #@param {type:\"boolean\"}\n",
    "unlimited_mode = True #@param {type:\"boolean\"}\n",
    "max_bucket_size = 4 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "target_chunk_chars = 1000 #@param {type:\"slider\", min:500, max:2000, step:100}\n",
    "use_fp16 = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown **üöÄ NEW: UNLIMITED MODE - NO LENGTH RESTRICTIONS!**\n",
    "#@markdown - **üî• Unlimited Mode**: Generate audio of ANY length (hours if needed!)\n",
    "#@markdown - **Force Efficient Mode**: Use efficient processing even for short texts\n",
    "#@markdown - **Max Bucket Size**: Number of sentences processed together\n",
    "#@markdown - **Target Chunk Chars**: Characters per chunk for very long texts\n",
    "#@markdown - **Use FP16**: Half precision for 2x speed improvement\n",
    "\n",
    "print(\"üöÄ Efficient Voice Cloning Generation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Check if we have a cloned voice\n",
    "speaker_embedding = None\n",
    "if 'cloned_voice' in globals():\n",
    "    speaker_embedding = cloned_voice\n",
    "    print(\"üé≠ Using your cloned voice!\")\n",
    "    if 'original_audio_file' in globals():\n",
    "        print(f\"üìÅ Voice source: {original_audio_file}\")\n",
    "else:\n",
    "    print(\"üé§ Using default voice (upload audio in Cell 4 to use your own voice)\")\n",
    "\n",
    "# Determine which system to use\n",
    "use_unlimited = unlimited_mode and EFFICIENT_AVAILABLE\n",
    "use_efficient = force_efficient_mode or (len(text) > 200 and EFFICIENT_AVAILABLE and not use_unlimited)\n",
    "\n",
    "print(f\"\\nüìù Text length: {len(text)} characters\")\n",
    "print(f\"üåç Language: {language}\")\n",
    "print(f\"üé≤ Seed: {seed}\")\n",
    "\n",
    "if use_unlimited:\n",
    "    print(f\"üî• Using UNLIMITED mode - NO LENGTH RESTRICTIONS!\")\n",
    "    print(f\"üìä Chunk size: {target_chunk_chars} characters\")\n",
    "    print(f\"‚ö° FP16 precision: {use_fp16}\")\n",
    "    print(f\"üöÄ Can generate HOURS of audio!\")\n",
    "elif use_efficient:\n",
    "    print(f\"üöÄ Using EFFICIENT mode (2-10x faster!)\")\n",
    "    print(f\"üìä Bucket size: {max_bucket_size} sentences\")\n",
    "    print(f\"‚ö° FP16 precision: {use_fp16}\")\n",
    "elif ENHANCED_AVAILABLE:\n",
    "    print(f\"üîß Using ENHANCED mode\")\n",
    "else:\n",
    "    print(f\"üì¢ Using STANDARD mode\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    if use_unlimited and EFFICIENT_AVAILABLE:\n",
    "        print(f\"\\nüî• Generating with UNLIMITED Voice Cloning - NO CAPS!\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"‚è≥ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with UNLIMITED system\n",
    "        audio = efficient_tts.generate_unlimited_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            target_chunk_chars=target_chunk_chars,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show unlimited stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nüìä UNLIMITED Generation Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        print(f\"  - NO LENGTH RESTRICTIONS APPLIED!\")\n",
    "        \n",
    "    elif use_efficient and EFFICIENT_AVAILABLE:"\n",
    "        print(f\"\\nüöÄ Generating with Efficient Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"‚è≥ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with efficient system\n",
    "        audio = efficient_tts.generate_speech_fast(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            max_bucket_size=max_bucket_size,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show efficiency stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nüìä Efficiency Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        \n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"\\nüîß Generating with Enhanced Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Generate with enhanced system\n",
    "        audio = enhanced_cloner.generate_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüì¢ Generating with Standard Voice Cloning...\")\n",
    "        \n",
    "        # Standard generation\n",
    "        from zonos.conditioning import make_cond_dict\n",
    "        \n",
    "        cond_dict = make_cond_dict(\n",
    "            text=text,\n",
    "            language=language,\n",
    "            speaker=speaker_embedding,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        conditioning = model.prepare_conditioning(cond_dict)\n",
    "        \n",
    "        # UNLIMITED token calculation - NO CAPS!\n",
    "        tokens_per_char = 25\n",
    "        estimated_tokens = len(text) * tokens_per_char\n",
    "        min_tokens = 1000\n",
    "        # NO MAXIMUM CAP! Generate as long as needed\n",
    "        max_tokens = max(min_tokens, estimated_tokens)\n",
    "        print(f\"üöÄ UNLIMITED tokens: {max_tokens} (NO CAP!)\")\n",
    "        \n",
    "        codes = model.generate(\n",
    "            prefix_conditioning=conditioning,\n",
    "            max_new_tokens=max_tokens,\n",
    "            cfg_scale=2.0,\n",
    "            batch_size=1,\n",
    "            progress_bar=True,\n",
    "            sampling_params={\"min_p\": 0.1, \"top_k\": 0, \"top_p\": 0.0}\n",
    "        )\n",
    "        \n",
    "        audio = model.autoencoder.decode(codes).cpu().detach()\n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    generation_time = time.time() - start_time\n",
    "    audio_duration = audio.shape[-1] / sample_rate\n",
    "    rtf = generation_time / audio_duration\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generation completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è Generation time: {generation_time:.2f}s\")\n",
    "    print(f\"üéµ Audio duration: {audio_duration:.2f}s\")\n",
    "    print(f\"üìä RTF (Real-Time Factor): {rtf:.4f}\")\n",
    "    print(f\"üöÄ Speed: {1/rtf:.1f}x faster than real-time\")\n",
    "    \n",
    "    if use_unlimited:\n",
    "        print(f\"üî• UNLIMITED MODE: Generated {audio_duration/60:.1f} minutes of audio!\")\n",
    "        print(f\"‚ö° NO LENGTH RESTRICTIONS were applied!\")\n",
    "        if audio_duration > 300:  # 5 minutes\n",
    "            print(f\"üéâ Successfully generated LONG FORM audio!\")\n",
    "    elif use_efficient:\n",
    "        expected_standard_time = generation_time * (3 if len(text) > 500 else 2)\n",
    "        speedup = expected_standard_time / generation_time\n",
    "        print(f\"‚ö° Estimated speedup vs standard: {speedup:.1f}x\")\n",
    "    \n",
    "    # Play the generated audio\n",
    "    print(f\"\\nüîä Generated Audio:\")\n",
    "    ipd.display(ipd.Audio(audio.numpy(), rate=sample_rate))\n",
    "    \n",
    "    # Save audio file\n",
    "    output_filename = f\"generated_audio_{int(time.time())}.wav\"\n",
    "    import torchaudio\n",
    "    torchaudio.save(output_filename, audio.cpu(), sample_rate)\n",
    "    print(f\"üíæ Audio saved as: {output_filename}\")\n",
    "    \n",
    "    # Download link\n",
    "    from google.colab import files\n",
    "    print(f\"\\nüì• Download your audio:\")\n",
    "    files.download(output_filename)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during generation: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check if model loaded correctly in Cell 3\")\n",
    "    print(\"2. Try shorter text if memory issues\")\n",
    "    print(\"3. Restart runtime if persistent errors\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
