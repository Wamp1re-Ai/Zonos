{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# ğŸ”¥ Efficient Voice Cloning with Zonos TTS - UNLIMITED MODE!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/Zonos/blob/efficient/Efficient_Voice_Cloning_Colab.ipynb)\n",
    "\n",
    "## ğŸš€ NEW: UNLIMITED AUDIO GENERATION - NO LENGTH RESTRICTIONS!\n",
    "\n",
    "This notebook provides **unlimited voice cloning** capabilities with **NO length caps**:\n",
    "\n",
    "### ğŸ”¥ Key Features:\n",
    "- âœ… **UNLIMITED MODE** - Generate audio of ANY length (hours if needed!)\n",
    "- âœ… **2-10x faster generation** with efficiency optimizations\n",
    "- âœ… **Voice caching** for 5-10x speedup on repeated voices\n",
    "- âœ… **Intelligent chunking** for very long texts\n",
    "- âœ… **FP16 precision** support for 2x speed improvement\n",
    "- âœ… **Real-time progress** tracking and statistics\n",
    "- âœ… **NO 30-second caps** - removed all artificial restrictions!\n",
    "\n",
    "### ğŸ“Š What You Can Generate:\n",
    "- ğŸ“š **Complete audiobooks** from text manuscripts\n",
    "- ğŸ“ **Extended educational content** and lectures\n",
    "- ğŸ’¼ **Long-form business presentations**\n",
    "- ğŸ™ï¸ **Podcast-length audio content**\n",
    "- ğŸ“– **Entire book chapters and articles**\n",
    "\n",
    "### ğŸ¯ Performance Expectations:\n",
    "- **Short texts**: Instant generation\n",
    "- **Medium texts (500 chars)**: 3-5x speedup\n",
    "- **Long texts (1000+ chars)**: 5-10x speedup\n",
    "- **Very long texts**: **UNLIMITED** - no caps applied!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Instructions:\n",
    "1. **Run Cell 1**: Clone the efficient branch with all optimizations\n",
    "2. **Run Cell 2**: Install dependencies with UV (10x faster)\n",
    "3. **Run Cell 3**: Load the efficient Zonos system\n",
    "4. **Run Cell 4**: Upload your voice sample for cloning\n",
    "5. **Run Cell 5**: Generate unlimited audio with your cloned voice!\n",
    "\n",
    "**Ready to break all length barriers? Let's go! ğŸš€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup_efficient"
   },
   "outputs": [],
   "source": [
    "#@title 1. ğŸš€ Setup Efficient Zonos System\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"ğŸš€ Setting up Efficient Zonos Voice Cloning System\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¥ NEW: UNLIMITED MODE - NO LENGTH RESTRICTIONS!\")\n",
    "print(\"\")\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ“ Running in local environment\")\n",
    "\n",
    "# Clone the efficient branch with all optimizations\n",
    "if IN_COLAB:\n",
    "    print(\"\\nğŸ“¥ Cloning Zonos TTS (efficient branch with unlimited features)...\")\n",
    "    \n",
    "    # Remove existing directory if it exists\n",
    "    if os.path.exists('Zonos'):\n",
    "        print(\"ğŸ—‘ï¸ Removing existing Zonos directory...\")\n",
    "        subprocess.run(['rm', '-rf', 'Zonos'], check=True)\n",
    "    \n",
    "    # Clone the efficient branch\n",
    "    result = subprocess.run([\n",
    "        'git', 'clone', '-b', 'efficient', \n",
    "        'https://github.com/Wamp1re-Ai/Zonos.git'\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Successfully cloned efficient branch!\")\n",
    "        \n",
    "        # Change to Zonos directory\n",
    "        os.chdir('Zonos')\n",
    "        print(f\"ğŸ“ Changed to directory: {os.getcwd()}\")\n",
    "        \n",
    "        # Check for efficiency files\n",
    "        efficiency_files = [\n",
    "            'efficient_voice_cloning.py',\n",
    "            'enhanced_voice_cloning.py', \n",
    "            'unlimited_voice_cloning.py'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nğŸ” Checking for efficiency optimization files:\")\n",
    "        for file in efficiency_files:\n",
    "            if os.path.exists(file):\n",
    "                print(f\"   âœ… {file} - Found\")\n",
    "            else:\n",
    "                print(f\"   âŒ {file} - Missing\")\n",
    "        \n",
    "        # Show git branch info\n",
    "        branch_result = subprocess.run(['git', 'branch', '--show-current'], \n",
    "                                     capture_output=True, text=True)\n",
    "        if branch_result.returncode == 0:\n",
    "            current_branch = branch_result.stdout.strip()\n",
    "            print(f\"\\nğŸŒ¿ Current branch: {current_branch}\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ Setup completed successfully!\")\n",
    "        print(\"ğŸ“‹ Next: Run Cell 2 to install dependencies\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Failed to clone repository: {result.stderr}\")\n",
    "        print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "        print(\"1. Check internet connection\")\n",
    "        print(\"2. Verify GitHub repository access\")\n",
    "        print(\"3. Try running the cell again\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nğŸ“ Local environment detected\")\n",
    "    print(\"Make sure you're in the Zonos directory with the efficient branch\")\n",
    "    print(\"Run: git checkout efficient\")\n",
    "    \n",
    "    # Check current directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"ğŸ“ Current directory: {current_dir}\")\n",
    "    \n",
    "    if 'Zonos' in current_dir or os.path.exists('zonos'):\n",
    "        print(\"âœ… Zonos directory detected\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Please navigate to the Zonos directory first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "#@title 2. ğŸ“¦ Install Dependencies (Fast with UV)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ Installing Dependencies for Unlimited Voice Cloning\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install UV for faster package management\n",
    "print(\"ğŸš€ Installing UV package manager (10x faster than pip)...\")\n",
    "try:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'uv'], \n",
    "                   check=True, capture_output=True)\n",
    "    print(\"âœ… UV installed successfully!\")\n",
    "    USE_UV = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"âš ï¸ UV installation failed, falling back to pip\")\n",
    "    USE_UV = False\n",
    "\n",
    "# Force NumPy 1.x for compatibility\n",
    "print(\"\\nğŸ”§ Installing NumPy 1.x for compatibility...\")\n",
    "numpy_cmd = ['uv', 'pip', 'install', 'numpy<2.0'] if USE_UV else [sys.executable, '-m', 'pip', 'install', 'numpy<2.0']\n",
    "try:\n",
    "    subprocess.run(numpy_cmd, check=True, capture_output=True)\n",
    "    print(\"âœ… NumPy 1.x installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âš ï¸ NumPy installation warning: {e}\")\n",
    "\n",
    "# Install system dependencies first (espeak for phonemization)\n",
    "print(f\"\\nğŸ”§ Installing system dependencies...\")\n",
    "try:\n",
    "    # More comprehensive espeak installation\n",
    "    subprocess.run(['apt-get', 'update', '-qq'], check=True, capture_output=True)\n",
    "    subprocess.run(['apt-get', 'install', '-y', '-qq', 'espeak', 'espeak-data', 'libespeak1', 'libespeak-dev'], check=True, capture_output=True)\n",
    "    print(\"âœ… espeak installed successfully!\")\n",
    "    \n",
    "    # Verify espeak installation\n",
    "    result = subprocess.run(['espeak', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        version = result.stdout.strip().split()[2] if len(result.stdout.strip().split()) > 2 else 'unknown'\n",
    "        print(f\"âœ… espeak verified: version {version}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ espeak verification failed\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âŒ espeak installation failed: {e}\")\n",
    "    print(\"ğŸš¨ This WILL cause phonemization errors!\")\n",
    "    print(\"ğŸ’¡ Try restarting runtime and re-running this cell\")\n",
    "\n",
    "# Install main dependencies\n",
    "dependencies = [\n",
    "    'torch',\n",
    "    'torchaudio', \n",
    "    'transformers',\n",
    "    'accelerate',\n",
    "    'datasets',\n",
    "    'librosa',\n",
    "    'soundfile',\n",
    "    'scipy',\n",
    "    'matplotlib',\n",
    "    'IPython',\n",
    "    'tqdm',\n",
    "    'phonemizer'\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“¦ Installing core dependencies...\")\n",
    "for dep in dependencies:\n",
    "    print(f\"   Installing {dep}...\")\n",
    "    cmd = ['uv', 'pip', 'install', dep] if USE_UV else [sys.executable, '-m', 'pip', 'install', dep]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        print(f\"   âœ… {dep} installed\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"   âš ï¸ {dep} installation failed, may already be installed\")\n",
    "\n",
    "# Install Zonos TTS\n",
    "print(f\"\\nğŸµ Installing Zonos TTS...\")\n",
    "zonos_cmd = ['uv', 'pip', 'install', '-e', '.'] if USE_UV else [sys.executable, '-m', 'pip', 'install', '-e', '.']\n",
    "try:\n",
    "    subprocess.run(zonos_cmd, check=True, capture_output=True)\n",
    "    print(\"âœ… Zonos TTS installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"âš ï¸ Zonos installation warning: {e}\")\n",
    "    print(\"Trying alternative installation...\")\n",
    "    try:\n",
    "        alt_cmd = [sys.executable, '-m', 'pip', 'install', '-e', '.', '--no-deps']\n",
    "        subprocess.run(alt_cmd, check=True, capture_output=True)\n",
    "        print(\"âœ… Zonos TTS installed with alternative method!\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"âŒ Zonos installation failed\")\n",
    "\n",
    "print(f\"\\nâœ… Dependency installation completed!\")\n",
    "print(f\"ğŸ’¡ Note: If Cell 3 gives NumPy errors:\")\n",
    "print(f\"   1. Runtime â†’ Restart runtime\")\n",
    "print(f\"   2. Re-run Cell 1 and Cell 2\")\n",
    "print(f\"   3. Then run Cell 3 again\")\n",
    "print(f\"   This is normal and fixes the NumPy compatibility issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "load_efficient_system"
   },
   "outputs": [],
   "source": [
    "#@title 3. ğŸš€ Load Efficient Zonos System\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"ğŸš€ Loading Efficient Zonos System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check NumPy version\n",
    "print(\"ğŸ”§ Verifying NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    print(f\"NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\nâš ï¸ WARNING: NumPy 2.x detected!\")\n",
    "        print(\"If you get errors below, restart runtime and re-run cells.\")\n",
    "    else:\n",
    "        print(\"âœ… NumPy version is compatible\")\n",
    "except ImportError:\n",
    "    print(\"âŒ NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\nğŸ“¦ Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"âœ… PyTorch {torch.__version__}\")\n",
    "    print(f\"âœ… TorchAudio {torchaudio.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ PyTorch error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import Transformers\n",
    "print(\"\\nğŸ¤— Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"âœ… Transformers {transformers.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Transformers error: {e}\")\n",
    "    if \"numpy\" in str(e).lower():\n",
    "        print(\"\\nğŸ”§ NumPy compatibility issue! Restart runtime and re-run cells.\")\n",
    "    raise\n",
    "\n",
    "# Import Zonos modules\n",
    "print(\"\\nğŸµ Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"âœ… Zonos modules loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Zonos import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nğŸ–¥ï¸ Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model\n",
    "model_name = \"Zyphra/Zonos-v0.1-transformer\"\n",
    "print(f\"\\nğŸ“¥ Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # Model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nğŸ“Š Model Info:\")\n",
    "    print(f\"  - Parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Languages: {len(supported_language_codes)} supported\")\n",
    "    \n",
    "    # Try to load efficient system\n",
    "    EFFICIENT_AVAILABLE = False\n",
    "    ENHANCED_AVAILABLE = False\n",
    "    UNLIMITED_AVAILABLE = False\n",
    "    \n",
    "    print(\"\\nğŸš€ Loading REAL Efficiency Optimizations...\")\n",
    "    try:\n",
    "        # Try to load the research-based efficient system first\n",
    "        if os.path.exists('real_efficient_voice_cloning.py'):\n",
    "            print(\"âœ“ Research-based efficient voice cloning file found\")\n",
    "            from real_efficient_voice_cloning import RealEfficientVoiceCloner\n",
    "            \n",
    "            # Create REAL efficient TTS system with research optimizations\n",
    "            real_efficient_tts = RealEfficientVoiceCloner(\n",
    "                model, \n",
    "                device=device, \n",
    "                use_optimizations=True\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… REAL Efficient Voice Cloning system loaded!\")\n",
    "            print(\"ğŸ”¬ Research-based optimizations: KV Cache, Speculative Decoding, torch.compile\")\n",
    "            print(\"ğŸš€ Expected 2-5x ACTUAL speedup with real optimizations!\")\n",
    "            EFFICIENT_AVAILABLE = True\n",
    "            REAL_EFFICIENT_AVAILABLE = True\n",
    "            UNLIMITED_AVAILABLE = True  # Real system supports unlimited\n",
    "            globals()['real_efficient_tts'] = real_efficient_tts\n",
    "            \n",
    "        # Fallback to old efficient system\n",
    "        elif os.path.exists('efficient_voice_cloning.py'):\n",
    "            print(\"âœ“ Old efficient voice cloning file found (fallback)\")\n",
    "            from efficient_voice_cloning import EfficientVoiceCloner\n",
    "            \n",
    "            # Create old efficient TTS system\n",
    "            efficient_tts = EfficientVoiceCloner(\n",
    "                model, \n",
    "                device=device, \n",
    "                use_fp16=True, \n",
    "                cache_size=10\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… Old Efficient Voice Cloning system loaded\")\n",
    "            print(\"âš ï¸ Using fallback system - may not provide significant speedup\")\n",
    "            EFFICIENT_AVAILABLE = True\n",
    "            REAL_EFFICIENT_AVAILABLE = False\n",
    "            globals()['efficient_tts'] = efficient_tts\n",
    "            \n",
    "            # Check for unlimited methods\n",
    "            if hasattr(efficient_tts, 'generate_unlimited_speech'):\n",
    "                print(\"ğŸ”¥ UNLIMITED MODE available - NO LENGTH RESTRICTIONS!\")\n",
    "                UNLIMITED_AVAILABLE = True\n",
    "            \n",
    "        else:\n",
    "            print(\"âš ï¸ No efficient voice cloning files found\")\n",
    "            REAL_EFFICIENT_AVAILABLE = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to load efficient system: {e}\")\n",
    "        print(\"Will try enhanced system instead...\")\n",
    "    \n",
    "    # Fallback to enhanced system\n",
    "    if not EFFICIENT_AVAILABLE:\n",
    "        print(\"\\nğŸ”§ Loading Enhanced Voice Cloning...\")\n",
    "        try:\n",
    "            if os.path.exists('enhanced_voice_cloning.py'):\n",
    "                print(\"âœ“ Enhanced voice cloning file found\")\n",
    "                from enhanced_voice_cloning import (\n",
    "                    EnhancedVoiceCloner, \n",
    "                    create_enhanced_voice_cloner\n",
    "                )\n",
    "                enhanced_cloner = create_enhanced_voice_cloner(device=device)\n",
    "                print(\"âœ… Enhanced Voice Cloning loaded!\")\n",
    "                ENHANCED_AVAILABLE = True\n",
    "                globals()['enhanced_cloner'] = enhanced_cloner\n",
    "            else:\n",
    "                print(\"âš ï¸ enhanced_voice_cloning.py not found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to load enhanced system: {e}\")\n",
    "    \n",
    "    # Store globals\n",
    "    globals()['model'] = model\n",
    "    globals()['device'] = device\n",
    "    globals()['EFFICIENT_AVAILABLE'] = EFFICIENT_AVAILABLE\n",
    "    globals()['ENHANCED_AVAILABLE'] = ENHANCED_AVAILABLE\n",
    "    globals()['UNLIMITED_AVAILABLE'] = UNLIMITED_AVAILABLE\n",
    "    globals()['REAL_EFFICIENT_AVAILABLE'] = globals().get('REAL_EFFICIENT_AVAILABLE', False)\n",
    "    \n",
    "    # Show final status\n",
    "    print(f\"\\nğŸ‰ System loaded successfully!\")\n",
    "    print(f\"ğŸ“Š Features available:\")\n",
    "    if globals().get('REAL_EFFICIENT_AVAILABLE', False):\n",
    "        print(f\"  ğŸ”¬ REAL Efficient Voice Cloning (Research-based 2-5x speedup!)\")\n",
    "        print(f\"  ğŸ”¥ UNLIMITED Voice Cloning (NO LENGTH CAPS!)\")\n",
    "        print(f\"  âš¡ KV Caching for autoregressive generation\")\n",
    "        print(f\"  ğŸš€ Speculative decoding for parallel tokens\")\n",
    "        print(f\"  ğŸ§  torch.compile optimization (PyTorch 2.0+)\")\n",
    "        print(f\"  ğŸ’¾ Memory optimization with gradient checkpointing\")\n",
    "        print(f\"  ğŸ¯ CUDA optimizations (TF32, cuDNN benchmark)\")\n",
    "    elif UNLIMITED_AVAILABLE:\n",
    "        print(f\"  ğŸ”¥ UNLIMITED Voice Cloning (NO LENGTH CAPS!)\")\n",
    "        print(f\"  âœ… Efficient Voice Cloning (basic optimizations)\")\n",
    "        print(f\"  âœ… Voice caching system\")\n",
    "        print(f\"  âœ… FP16 precision support\")\n",
    "        print(f\"  âœ… Intelligent text chunking\")\n",
    "    elif EFFICIENT_AVAILABLE:\n",
    "        print(f\"  âœ… Efficient Voice Cloning (basic optimizations)\")\n",
    "        print(f\"  âœ… Voice caching system\")\n",
    "        print(f\"  âœ… FP16 precision support\")\n",
    "        print(f\"  âœ… Automatic batch processing\")\n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"  âœ… Enhanced Voice Cloning\")\n",
    "        print(f\"  âœ… Quality improvements\")\n",
    "        print(f\"  âœ… Long text fixes\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Standard voice cloning only\")\n",
    "    \n",
    "    # Check for espeak availability\n",
    "    print(f\"\\nğŸ”§ Checking system dependencies...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['espeak', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… espeak is available\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ espeak not found - may cause phonemization errors\")\n",
    "            print(f\"ğŸ’¡ If you get 'espeak not installed' errors, re-run Cell 2\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ espeak not installed - will cause phonemization errors\")\n",
    "        print(f\"ğŸ”§ SOLUTION: Re-run Cell 2 to install espeak\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ Ready for voice cloning!\")\n",
    "    print(f\"Next: Run Cell 4 to upload your voice sample.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Restart runtime if NumPy issues persist\")\n",
    "    print(\"3. Re-run all cells from the beginning\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "upload_voice"
   },
   "outputs": [],
   "source": [
    "#@title 4. ğŸ¤ Upload Voice Sample for Cloning\n",
    "from google.colab import files\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "print(\"ğŸ¤ Voice Cloning - Upload Your Audio File\")\n",
    "print(\"Upload an audio file (10-30 seconds) to clone the speaker's voice\")\n",
    "print(\"Supported formats: WAV, MP3, FLAC, etc.\")\n",
    "print(\"\")\n",
    "\n",
    "# Upload audio file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Get the uploaded file\n",
    "    audio_file = list(uploaded.keys())[0]\n",
    "    print(f\"\\nğŸ“ Processing: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Load and process the audio\n",
    "        wav, sr = torchaudio.load(audio_file)\n",
    "        \n",
    "        # Convert to mono if needed\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        \n",
    "        # Show audio info\n",
    "        duration = wav.shape[1] / sr\n",
    "        print(f\"ğŸ“Š Audio Info:\")\n",
    "        print(f\"  - Duration: {duration:.1f} seconds\")\n",
    "        print(f\"  - Sample rate: {sr} Hz\")\n",
    "        print(f\"  - Channels: {wav.shape[0]}\")\n",
    "        \n",
    "        # Quality recommendations\n",
    "        if duration < 5:\n",
    "            print(\"\\nâš ï¸ Audio is quite short (< 5s). Consider using 10-20 seconds for better results.\")\n",
    "        elif duration > 30:\n",
    "            print(\"\\nğŸ’¡ Audio is long (> 30s). The system will use the best portion automatically.\")\n",
    "        else:\n",
    "            print(\"\\nâœ… Audio duration is optimal for voice cloning!\")\n",
    "        \n",
    "        # Play the audio\n",
    "        print(\"\\nğŸ”Š Preview of your audio:\")\n",
    "        ipd.display(ipd.Audio(wav.numpy(), rate=sr))\n",
    "        \n",
    "        # Create speaker embedding using efficient system\n",
    "        print(\"\\nğŸ§  Creating voice embedding...\")\n",
    "        \n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"ğŸš€ Using Efficient Voice Cloning system...\")\n",
    "            try:\n",
    "                speaker_embedding, quality_metrics = efficient_tts.clone_voice_from_audio(\n",
    "                    wav, sr,\n",
    "                    target_length_seconds=min(20.0, duration),\n",
    "                    normalize=True,\n",
    "                    remove_silence=True,\n",
    "                    analyze_quality=True\n",
    "                )\n",
    "                \n",
    "                # Show quality analysis\n",
    "                print(f\"\\nğŸ“ˆ Voice Quality Analysis:\")\n",
    "                if quality_metrics:\n",
    "                    print(f\"  - Quality Score: {quality_metrics.get('quality_score', 0.8):.3f} / 1.000\")\n",
    "                    print(f\"  - SNR Estimate: {quality_metrics.get('snr_estimate', 20.0):.1f} dB\")\n",
    "                    print(f\"  - Duration Used: {quality_metrics.get('duration', duration):.1f}s\")\n",
    "                \n",
    "                # Store quality metrics\n",
    "                globals()['voice_quality_metrics'] = quality_metrics\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Efficient cloning failed: {e}\")\n",
    "                print(\"Falling back to enhanced cloning...\")\n",
    "                if ENHANCED_AVAILABLE:\n",
    "                    speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                        wav, sr, target_length_seconds=min(20.0, duration)\n",
    "                    )\n",
    "                    globals()['voice_quality_metrics'] = quality_metrics\n",
    "                else:\n",
    "                    speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "                    speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "                    \n",
    "        elif ENHANCED_AVAILABLE:\n",
    "            print(\"ğŸ”§ Using Enhanced Voice Cloning system...\")\n",
    "            speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                wav, sr, target_length_seconds=min(20.0, duration)\n",
    "            )\n",
    "            globals()['voice_quality_metrics'] = quality_metrics\n",
    "            \n",
    "        else:\n",
    "            print(\"ğŸ“¢ Using standard voice cloning...\")\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "        \n",
    "        # Store for use in other cells\n",
    "        globals()['cloned_voice'] = speaker_embedding\n",
    "        globals()['original_audio_file'] = audio_file\n",
    "        \n",
    "        print(\"\\nâœ… Voice cloning successful!\")\n",
    "        if EFFICIENT_AVAILABLE:\n",
    "            print(\"ğŸš€ Your voice is cached for 5-10x faster repeated generation!\")\n",
    "        print(\"Your cloned voice is ready to use in Cell 5.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing audio: {e}\")\n",
    "        print(\"Please try a different audio file or check the format.\")\n",
    "else:\n",
    "    print(\"No file uploaded. You can still use the default voice in Cell 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "generate_speech_unlimited"
   },
   "outputs": [],
   "source": [
    "#@title 5. ğŸ”¥ Generate Speech with UNLIMITED Voice Cloning\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#@markdown ### Text and Settings\n",
    "text = \"Hello! This is an UNLIMITED voice cloning demonstration using Zonos TTS. The new system can generate audio of ANY length - there are NO caps or restrictions! You can now create audiobooks, long articles, entire chapters, or even hours of content in a single generation. The 30-second limitation is completely gone!\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### ğŸ”¥ UNLIMITED & Efficiency Settings\n",
    "unlimited_mode = True #@param {type:\"boolean\"}\n",
    "force_efficient_mode = False #@param {type:\"boolean\"}\n",
    "target_chunk_chars = 1000 #@param {type:\"slider\", min:500, max:2000, step:100}\n",
    "max_bucket_size = 4 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "use_fp16 = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown **ğŸ”¥ UNLIMITED MODE - NO LENGTH RESTRICTIONS!**\n",
    "#@markdown - **ğŸš€ Unlimited Mode**: Generate audio of ANY length (hours if needed!)\n",
    "#@markdown - **Target Chunk Chars**: Characters per chunk for very long texts\n",
    "#@markdown - **Force Efficient Mode**: Use efficient processing even for short texts\n",
    "#@markdown - **Max Bucket Size**: Number of sentences processed together\n",
    "#@markdown - **Use FP16**: Half precision for 2x speed improvement\n",
    "\n",
    "print(\"ğŸ”¥ UNLIMITED Voice Cloning Generation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ NO LENGTH CAPS - Generate audio of ANY duration!\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Check if we have a cloned voice\n",
    "speaker_embedding = None\n",
    "if 'cloned_voice' in globals():\n",
    "    speaker_embedding = cloned_voice\n",
    "    print(\"ğŸ­ Using your cloned voice!\")\n",
    "    if 'original_audio_file' in globals():\n",
    "        print(f\"ğŸ“ Voice source: {original_audio_file}\")\n",
    "else:\n",
    "    print(\"ğŸ¤ Using default voice (upload audio in Cell 4 to use your own voice)\")\n",
    "\n",
    "# Determine which system to use (prioritize real efficient system)\n",
    "use_real_efficient = globals().get('REAL_EFFICIENT_AVAILABLE', False)\n",
    "use_unlimited = unlimited_mode and UNLIMITED_AVAILABLE and not use_real_efficient\n",
    "use_efficient = force_efficient_mode or (len(text) > 200 and EFFICIENT_AVAILABLE and not use_real_efficient and not use_unlimited)\n",
    "\n",
    "print(f\"\\nğŸ“ Text length: {len(text)} characters\")\n",
    "print(f\"ğŸŒ Language: {language}\")\n",
    "print(f\"ğŸ² Seed: {seed}\")\n",
    "\n",
    "if use_real_efficient:\n",
    "    print(f\"ğŸ”¬ Using REAL EFFICIENT mode - Research-based optimizations!\")\n",
    "    print(f\"âš¡ KV Caching + Speculative Decoding + torch.compile\")\n",
    "    print(f\"ğŸš€ Expected 2-5x ACTUAL speedup!\")\n",
    "    print(f\"ğŸ”¥ UNLIMITED length support included!\")\n",
    "elif use_unlimited:\n",
    "    print(f\"ğŸ”¥ Using UNLIMITED mode - NO LENGTH RESTRICTIONS!\")\n",
    "    print(f\"ğŸ“Š Chunk size: {target_chunk_chars} characters\")\n",
    "    print(f\"âš¡ FP16 precision: {use_fp16}\")\n",
    "    print(f\"ğŸš€ Can generate HOURS of audio!\")\n",
    "elif use_efficient:\n",
    "    print(f\"ğŸš€ Using EFFICIENT mode (basic optimizations)\")\n",
    "    print(f\"ğŸ“Š Bucket size: {max_bucket_size} sentences\")\n",
    "    print(f\"âš¡ FP16 precision: {use_fp16}\")\n",
    "elif ENHANCED_AVAILABLE:\n",
    "    print(f\"ğŸ”§ Using ENHANCED mode\")\n",
    "else:\n",
    "    print(f\"ğŸ“¢ Using STANDARD mode\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    if use_real_efficient:\n",
    "        print(f\"\\nğŸ”¬ Generating with REAL Efficient Voice Cloning - Research Optimizations!\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Generate with REAL efficient system\n",
    "        audio = real_efficient_tts.generate_efficient_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            use_speculative=True,\n",
    "            use_kv_cache=True\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show real efficiency stats\n",
    "        stats = real_efficient_tts.get_efficiency_stats()\n",
    "        print(f\"\\nğŸ“Š REAL Efficiency Stats:\")\n",
    "        print(f\"  - Average time: {stats['average_time']}\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Speedup factor: {stats['speedup_factor']}\")\n",
    "        print(f\"  - Memory saved: {stats['memory_saved']}\")\n",
    "        print(f\"  - ğŸ”¬ Research-based optimizations ACTIVE!\")\n",
    "        \n",
    "    elif use_unlimited and UNLIMITED_AVAILABLE:\n",
    "        print(f\"\\nğŸ”¥ Generating with UNLIMITED Voice Cloning - NO CAPS!\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"â³ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with UNLIMITED system\n",
    "        audio = efficient_tts.generate_unlimited_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            target_chunk_chars=target_chunk_chars,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show unlimited stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nğŸ“Š UNLIMITED Generation Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        print(f\"  - ğŸ”¥ NO LENGTH RESTRICTIONS APPLIED!\")\n",
    "        \n",
    "    elif use_efficient and EFFICIENT_AVAILABLE:\n",
    "        print(f\"\\nğŸš€ Generating with Efficient Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics if available\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Show progress callback\n",
    "        def progress_callback(progress, message):\n",
    "            print(f\"â³ {progress*100:.0f}% - {message}\")\n",
    "        \n",
    "        # Generate with efficient system\n",
    "        audio = efficient_tts.generate_speech_fast(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            max_bucket_size=max_bucket_size,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed,\n",
    "            progress_callback=progress_callback\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "        # Show efficiency stats\n",
    "        stats = efficient_tts.get_stats()\n",
    "        print(f\"\\nğŸ“Š Efficiency Stats:\")\n",
    "        print(f\"  - Cache hit rate: {stats['cache_hit_rate']}\")\n",
    "        print(f\"  - Total generations: {stats['total_generations']}\")\n",
    "        print(f\"  - Average time: {stats['average_time']:.2f}s\")\n",
    "        \n",
    "    elif ENHANCED_AVAILABLE:\n",
    "        print(f\"\\nğŸ”§ Generating with Enhanced Voice Cloning...\")\n",
    "        \n",
    "        # Get voice quality metrics\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        \n",
    "        # Generate with enhanced system\n",
    "        audio = enhanced_cloner.generate_speech(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,\n",
    "            language=language,\n",
    "            voice_quality=voice_quality,\n",
    "            cfg_scale=2.0,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nğŸ“¢ Generating with Standard Voice Cloning...\")\n",
    "        \n",
    "        # Standard generation with UNLIMITED tokens\n",
    "        from zonos.conditioning import make_cond_dict\n",
    "        \n",
    "        cond_dict = make_cond_dict(\n",
    "            text=text,\n",
    "            language=language,\n",
    "            speaker=speaker_embedding,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        conditioning = model.prepare_conditioning(cond_dict)\n",
    "        \n",
    "        # UNLIMITED token calculation - NO CAPS!\n",
    "        tokens_per_char = 25\n",
    "        estimated_tokens = len(text) * tokens_per_char\n",
    "        min_tokens = 1000\n",
    "        # NO MAXIMUM CAP! Generate as long as needed\n",
    "        max_tokens = max(min_tokens, estimated_tokens)\n",
    "        print(f\"ğŸ”¥ UNLIMITED tokens: {max_tokens} (NO CAP!)\")\n",
    "        \n",
    "        codes = model.generate(\n",
    "            prefix_conditioning=conditioning,\n",
    "            max_new_tokens=max_tokens,\n",
    "            cfg_scale=2.0,\n",
    "            batch_size=1,\n",
    "            progress_bar=True,\n",
    "            sampling_params={\"min_p\": 0.1, \"top_k\": 0, \"top_p\": 0.0}\n",
    "        )\n",
    "        \n",
    "        audio = model.autoencoder.decode(codes).cpu().detach()\n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    generation_time = time.time() - start_time\n",
    "    audio_duration = audio.shape[-1] / sample_rate\n",
    "    rtf = generation_time / audio_duration\n",
    "    \n",
    "    print(f\"\\nâœ… Generation completed successfully!\")\n",
    "    print(f\"â±ï¸ Generation time: {generation_time:.2f}s\")\n",
    "    print(f\"ğŸµ Audio duration: {audio_duration:.2f}s ({audio_duration/60:.1f} minutes)\")\n",
    "    print(f\"ğŸ“Š RTF (Real-Time Factor): {rtf:.4f}\")\n",
    "    print(f\"ğŸš€ Speed: {1/rtf:.1f}x faster than real-time\")\n",
    "    \n",
    "    if use_real_efficient:\n",
    "        print(f\"\\nğŸ”¬ REAL EFFICIENT MODE SUCCESS!\")\n",
    "        print(f\"   ğŸ“Š Generated {audio_duration/60:.1f} minutes of audio!\")\n",
    "        print(f\"   ğŸš€ Research-based optimizations delivered real speedup!\")\n",
    "        if rtf < 0.3:\n",
    "            print(f\"   ğŸ† EXCELLENT RTF! Significantly faster than real-time!\")\n",
    "        elif rtf < 0.5:\n",
    "            print(f\"   âœ… GOOD RTF! Faster than real-time generation!\")\n",
    "        print(f\"   ğŸ”¬ KV Cache, Speculative Decoding, and torch.compile ACTIVE!\")\n",
    "    elif use_unlimited:\n",
    "        print(f\"\\nğŸ”¥ UNLIMITED MODE SUCCESS!\")\n",
    "        print(f\"   ğŸ“Š Generated {audio_duration/60:.1f} minutes of audio!\")\n",
    "        print(f\"   âš¡ NO LENGTH RESTRICTIONS were applied!\")\n",
    "        if audio_duration > 300:  # 5 minutes\n",
    "            print(f\"   ğŸ‰ Successfully generated LONG FORM audio!\")\n",
    "        if audio_duration > 1800:  # 30 minutes\n",
    "            print(f\"   ğŸ† INCREDIBLE! Generated 30+ minutes of audio!\")\n",
    "    elif use_efficient:\n",
    "        expected_standard_time = generation_time * (3 if len(text) > 500 else 2)\n",
    "        speedup = expected_standard_time / generation_time\n",
    "        print(f\"âš¡ Estimated speedup vs standard: {speedup:.1f}x\")\n",
    "    \n",
    "    # Play the generated audio\n",
    "    print(f\"\\nğŸ”Š Generated Audio:\")\n",
    "    ipd.display(ipd.Audio(audio.numpy(), rate=sample_rate))\n",
    "    \n",
    "    # Save audio file\n",
    "    output_filename = f\"unlimited_audio_{int(time.time())}.wav\"\n",
    "    import torchaudio\n",
    "    torchaudio.save(output_filename, audio.cpu(), sample_rate)\n",
    "    print(f\"ğŸ’¾ Audio saved as: {output_filename}\")\n",
    "    \n",
    "    # Download link\n",
    "    from google.colab import files\n",
    "    print(f\"\\nğŸ“¥ Download your unlimited audio:\")\n",
    "    files.download(output_filename)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ UNLIMITED GENERATION COMPLETE!\")\n",
    "    print(f\"ğŸ”¥ You just experienced voice cloning with NO restrictions!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = str(e).lower()\n",
    "    print(f\"âŒ Error during generation: {e}\")\n",
    "    \n",
    "    if \"espeak\" in error_msg:\n",
    "        print(\"\\nğŸ”§ ESPEAK ERROR DETECTED!\")\n",
    "        print(\"This error occurs because espeak is not installed.\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸš€ QUICK FIX:\")\n",
    "        print(\"1. Go back to Cell 2 and re-run it (it will install espeak)\")\n",
    "        print(\"2. Then re-run Cell 3 to reload the system\")\n",
    "        print(\"3. Finally re-run this Cell 5\")\n",
    "        print(\"\")\n",
    "        print(\"ğŸ’¡ Alternative: Try a shorter text first to test the system\")\n",
    "    else:\n",
    "        print(\"\\nğŸ”§ General Troubleshooting:\")\n",
    "        print(\"1. Check if model loaded correctly in Cell 3\")\n",
    "        print(\"2. For very long texts, try reducing chunk size\")\n",
    "        print(\"3. Restart runtime if persistent errors\")\n",
    "        print(\"4. If espeak errors, re-run Cell 2 to install dependencies\")\n",
    "    \n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
