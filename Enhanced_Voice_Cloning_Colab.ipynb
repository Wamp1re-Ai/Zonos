{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé§ Enhanced Voice Cloning with Zonos TTS - Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/Zonos/blob/main/Enhanced_Voice_Cloning_Colab.ipynb)\n",
    "\n",
    "This Google Colab notebook provides an **enhanced voice cloning system** using Zonos TTS. It's designed for ease of use within the Colab environment and offers several improvements over standard voice cloning approaches, focusing on naturalness, consistency, and control.\n",
    "\n",
    "**Key improvements include:**\n",
    "- ‚úÖ Smooth, natural speech flow (reduced unnatural pauses and timing issues).\n",
    "- ‚úÖ Consistent speaking rate.\n",
    "- ‚úÖ Clear, intelligible speech (reduced gibberish generation).\n",
    "- ‚úÖ Stable voice reproduction.\n",
    "\n",
    "## üöÄ Features:\n",
    "- üîß **Advanced Audio Preprocessing**: Automatic silence removal and normalization for uploaded voice samples.\n",
    "- üìä **Voice Quality Analysis**: SNR estimation and quality scoring for your voice samples.\n",
    "- ‚öôÔ∏è **Optimized & Customizable Parameters**: Choose from Quality Presets for balanced results or fine-tune for specific needs. Includes options for faster generation (lower CFG Scales) and emotional expressiveness.\n",
    "- üéØ **Adaptive Settings**: Parameters automatically adjust based on the quality of your voice sample and chosen preset.\n",
    "- üîÑ **Reproducible Results**: Seed support for consistent audio generation.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Instructions:\n",
    "1. **Run Cell 1 (Setup)**: Clones the Zonos repository and sets up the Colab environment.\n",
    "2. **Run Cell 2 (Install Dependencies)**: Installs necessary Python packages using UV for speed.\n",
    "3. **Run Cell 3 (Load Model)**: Loads the Zonos TTS model. **IMPORTANT:** If you modify underlying model code (e.g., `zonos/model.py`), you MUST re-run this cell for changes to take effect.\n",
    "4. **Run Cell 4 (Upload Voice Sample)**: Upload a 10-30 second audio file of the voice you want to clone.\n",
    "5. **Run Cell 5 (Generate Speech)**: Generate speech using your cloned voice and selected Quality Preset.\n",
    "6. **Run Cell 6 (Run Benchmarks - Optional)**: Test generation speed and quality with different CFG Scales.\n",
    "\n",
    "**Troubleshooting Note**: If you encounter NumPy-related errors, especially after installing dependencies, try restarting the Colab Runtime (`Runtime` > `Restart runtime` or `Factory reset runtime`) and then re-run cells from Cell 1. This usually resolves such issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup_and_clone"
   },
   "outputs": [],
   "source": [
    "#@title 1. üì• Setup and Clone Repository\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üöÄ Enhanced Voice Cloning Setup\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è Not running in Google Colab\")\n",
    "\n",
    "# Clone the repository if it doesn't exist\n",
    "if not os.path.exists('Zonos'):\n",
    "    print(\"\\nüì• Cloning Zonos repository...\")\n",
    "    !git clone https://github.com/Wamp1re-Ai/Zonos.git\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change to the Zonos directory\n",
    "%cd Zonos\n",
    "\n",
    "# Install system dependencies\n",
    "print(\"\\nüîß Installing system dependencies...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install -y espeak-ng git-lfs -qq\n",
    "!git lfs install\n",
    "print(\"‚úÖ System dependencies installed!\")\n",
    "\n",
    "# Check for enhanced files\n",
    "if os.path.exists('enhanced_voice_cloning.py'):\n",
    "    print(\"\\nüöÄ Enhanced voice cloning files detected!\")\n",
    "    print(\"You have access to all the latest improvements.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Enhanced files not found. Using standard voice cloning.\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete! Continue to Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "#@title 2. ‚ö° Install Dependencies with UV (Ultra-Fast Installation)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"‚ö° Ultra-Fast Dependency Installation with UV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Install UV for ultra-fast package management\n",
    "print(\"\\nüöÄ Step 1: Installing UV (Rust-based package manager)...\")\n",
    "try:\n",
    "    # Check if uv is already installed\n",
    "    result = subprocess.run(['uv', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ UV already installed: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "    print(\"üì¶ Installing UV...\")\n",
    "    !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "    # Add uv to PATH for current session\n",
    "    os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ.get('PATH', '')}\"\n",
    "    print(\"‚úÖ UV installed successfully!\")\n",
    "\n",
    "# Step 2: Fix NumPy compatibility FIRST\n",
    "print(\"\\nüîß Step 2: Fixing NumPy compatibility (ultra-fast)...\")\n",
    "!uv pip install \"numpy==1.26.4\" --force-reinstall --system\n",
    "\n",
    "# Verify NumPy installation\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"‚úÖ NumPy {np.__version__} installed successfully\")\n",
    "    \n",
    "    # Double-check version\n",
    "    numpy_major = int(np.__version__.split('.')[0])\n",
    "    if numpy_major >= 2:\n",
    "        print(\"‚ö†Ô∏è NumPy 2.x still detected. This may require a runtime restart.\")\n",
    "        print(\"If you get errors in Cell 3, restart runtime and try again.\")\n",
    "    else:\n",
    "        print(\"‚úÖ NumPy version is now compatible with transformers\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è NumPy verification failed: {e}\")\n",
    "    print(\"Continuing with installation...\")\n",
    "\n",
    "# Step 3: Install core dependencies with UV (much faster)\n",
    "print(\"\\n‚ö° Step 3: Installing core dependencies with UV...\")\n",
    "\n",
    "# Check PyTorch (usually pre-installed in Colab)\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} already available\")\n",
    "    print(f\"‚úÖ TorchAudio {torchaudio.__version__} already available\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing PyTorch with UV...\")\n",
    "    !uv pip install torch torchaudio --system\n",
    "\n",
    "# Install all other packages in one UV command (much faster than pip)\n",
    "print(\"‚ö° Installing all dependencies with UV (10x faster than pip)...\")\n",
    "!uv pip install \"transformers>=4.45.0,<4.50.0\" \"huggingface-hub>=0.20.0\" \"soundfile>=0.12.1\" \"phonemizer>=3.2.0\" \"inflect>=7.0.0\" \"scipy\" \"ipywidgets>=8.0.0\" --system\n",
    "\n",
    "print(\"\\n‚ö° Step 4: Installing Zonos package with UV...\")\n",
    "try:\n",
    "    !uv pip install -e . --system\n",
    "    print(\"‚úÖ Zonos package installed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Package installation failed, adding to Python path...\")\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.insert(0, current_dir)\n",
    "    print(f\"‚úÖ Added {current_dir} to Python path\")\n",
    "\n",
    "installation_time = time.time() - start_time\n",
    "print(f\"\\nüéâ All dependencies installed successfully in {installation_time:.1f} seconds!\")\n",
    "print(f\"‚ö° UV is ~10x faster than pip for package installation\")\n",
    "print(\"\\nüöÄ Ready for Cell 3: Load Model\")\n",
    "print(\"\\nüí° Note: If Cell 3 gives NumPy errors:\")\n",
    "print(\"   1. Runtime ‚Üí Restart runtime\")\n",
    "print(\"   2. Re-run Cell 1 and Cell 2\")\n",
    "print(\"   3. Then run Cell 3 again\")\n",
    "print(\"   This is normal and fixes the NumPy compatibility issue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "#@title 3. ü§ñ Load Enhanced Zonos Model\n",
    "# IMPORTANT: If you have modified the underlying Zonos Python files (e.g., zonos/model.py),\n",
    "# you MUST re-run this cell for those changes to take effect in the model.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ü§ñ Loading Enhanced Zonos Model\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Make sure we can import zonos modules\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Check NumPy version (should be fixed by Cell 2)\n",
    "print(\"üîß Verifying NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    print(f\"NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\n‚ö†Ô∏è WARNING: NumPy 2.x detected!\")\n",
    "        print(\"This may cause issues. If you get errors below:\")\n",
    "        print(\"1. Runtime ‚Üí Restart runtime\")\n",
    "        print(\"2. Re-run Cell 1 and Cell 2\")\n",
    "        print(\"3. Try Cell 3 again\")\n",
    "        print(\"\\nContinuing anyway...\")\n",
    "    else:\n",
    "        print(\"‚úÖ NumPy version is compatible\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\nüì¶ Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
    "    print(f\"‚úÖ TorchAudio {torchaudio.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PyTorch error: {e}\")\n",
    "    print(\"Please run Cell 2 to install dependencies.\")\n",
    "    raise\n",
    "\n",
    "# Import transformers with better error handling\n",
    "print(\"\\nü§ó Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"‚úÖ Transformers {transformers.__version__}\")\n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    print(f\"‚ùå Transformers error: {e}\")\n",
    "    \n",
    "    if \"numpy\" in error_msg.lower() or \"_center\" in error_msg:\n",
    "        print(\"\\nüîß This is the NumPy 2.x compatibility issue!\")\n",
    "        print(\"\\nüìã SOLUTION:\")\n",
    "        print(\"1. Runtime ‚Üí Restart runtime\")\n",
    "        print(\"2. Run Cell 1 (Setup)\")\n",
    "        print(\"3. Run Cell 2 (Dependencies)\")\n",
    "        print(\"4. Run Cell 3 (this cell) again\")\n",
    "        print(\"\\nThis will fix the NumPy compatibility issue.\")\n",
    "    else:\n",
    "        print(\"Please check your dependencies in Cell 2.\")\n",
    "    raise\n",
    "\n",
    "# Try to import enhanced voice cloning modules\n",
    "print(\"\\nüöÄ Loading Enhanced Voice Cloning...\")\n",
    "ENHANCED_AVAILABLE = False\n",
    "try:\n",
    "    # First check if the file exists\n",
    "    import os\n",
    "    if os.path.exists('enhanced_voice_cloning.py'):\n",
    "        print(\"‚úì Enhanced voice cloning file found\")\n",
    "        \n",
    "        # Try importing the enhanced modules\n",
    "        from enhanced_voice_cloning import (\n",
    "            EnhancedVoiceCloner, \n",
    "            create_enhanced_voice_cloner, \n",
    "            quick_voice_clone\n",
    "        )\n",
    "        print(\"‚úÖ Enhanced Voice Cloning modules loaded successfully!\")\n",
    "        ENHANCED_AVAILABLE = True\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è enhanced_voice_cloning.py not found in current directory\")\n",
    "        ENHANCED_AVAILABLE = False\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Enhanced modules import failed: {e}\")\n",
    "    print(\"This might be due to missing dependencies in the enhanced module.\")\n",
    "    print(\"Using standard voice cloning instead.\")\n",
    "    ENHANCED_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Unexpected error loading enhanced modules: {e}\")\n",
    "    print(\"Using standard voice cloning instead.\")\n",
    "    ENHANCED_AVAILABLE = False\n",
    "\n",
    "# Import standard Zonos modules\n",
    "print(\"\\nüéµ Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"‚úÖ Zonos modules loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Zonos import error: {e}\")\n",
    "    print(\"Make sure Cell 2 completed successfully.\")\n",
    "    raise\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model\n",
    "model_name = \"Zyphra/Zonos-v0.1-transformer\"\n",
    "print(f\"\\nüì• Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # Model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nüìä Model Info:\")\n",
    "    print(f\"  - Parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Enhanced features: {'‚úÖ Available' if ENHANCED_AVAILABLE else '‚ùå Standard only'}\")\n",
    "    print(f\"  - Languages: {len(supported_language_codes)} supported\")\n",
    "    \n",
    "    # Create enhanced cloner if available\n",
    "    if ENHANCED_AVAILABLE:\n",
    "        print(\"\\nüöÄ Creating Enhanced Voice Cloner...\")\n",
    "        try:\n",
    "            # Attempt to pass the model to the enhanced cloner if it accepts it\n",
    "            try:\n",
    "                enhanced_cloner = create_enhanced_voice_cloner(model=model, device=device)\n",
    "            except TypeError:\n",
    "                 print(\"  (Enhanced cloner does not accept model directly, creating with device only)\")\n",
    "                 enhanced_cloner = create_enhanced_voice_cloner(device=device)\n",
    "            print(\"‚úÖ Enhanced Voice Cloner ready!\")\n",
    "            globals()['enhanced_cloner'] = enhanced_cloner\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to create enhanced cloner: {e}\")\n",
    "            print(\"Will create fallback enhanced functions...\")\n",
    "            ENHANCED_AVAILABLE = False # Fallback to simple if cloner fails\n",
    "    \n",
    "    # Create fallback enhanced functions using zonos.speaker_cloning\n",
    "    if not ENHANCED_AVAILABLE:\n",
    "        print(\"\\nüîß Creating fallback enhanced voice cloning functions...\")\n",
    "        try:\n",
    "            from zonos.speaker_cloning import (\n",
    "                preprocess_audio_for_cloning,\n",
    "                analyze_voice_quality,\n",
    "                get_voice_cloning_conditioning_params,\n",
    "                get_voice_cloning_sampling_params\n",
    "            )\n",
    "            \n",
    "            def simple_enhanced_clone_voice(wav, sr, **kwargs):\n",
    "                processed_wav = preprocess_audio_for_cloning(\n",
    "                    wav, sr,\n",
    "                    target_length_seconds=kwargs.get('target_length_seconds', 20.0),\n",
    "                    normalize=kwargs.get('normalize', True),\n",
    "                    remove_silence=kwargs.get('remove_silence', True)\n",
    "                )\n",
    "                quality_metrics = analyze_voice_quality(processed_wav, sr)\n",
    "                speaker_embedding = model.make_speaker_embedding(processed_wav, sr)\n",
    "                speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "                return speaker_embedding, quality_metrics\n",
    "            \n",
    "            # Modified simple_enhanced_generate_speech to accept emotion_vector\n",
    "            def simple_enhanced_generate_speech(text, speaker_embedding=None, language='en-us', \n",
    "                                               voice_quality=None, seed=None, cfg_scale=2.0, \n",
    "                                               custom_conditioning_params=None, custom_sampling_params=None, \n",
    "                                               emotion_vector=None, **kwargs):\n",
    "                if seed is not None:\n",
    "                    torch.manual_seed(seed)\n",
    "                conditioning_params = get_voice_cloning_conditioning_params(voice_quality)\n",
    "                sampling_params = get_voice_cloning_sampling_params(voice_quality)\n",
    "                if custom_conditioning_params:\n",
    "                    conditioning_params.update(custom_conditioning_params)\n",
    "                if custom_sampling_params:\n",
    "                    sampling_params.update(custom_sampling_params)\n",
    "                \n",
    "                cond_dict_extra_args = {}\n",
    "                if emotion_vector is not None:\n",
    "                    cond_dict_extra_args['emotion'] = emotion_vector\n",
    "                    \n",
    "                cond_dict = make_cond_dict(\n",
    "                    text=text, language=language, speaker=speaker_embedding,\n",
    "                    device=device, **conditioning_params, **cond_dict_extra_args\n",
    "                )\n",
    "                conditioning = model.prepare_conditioning(cond_dict, cfg_scale=cfg_scale)\n",
    "                sampling_dict = {k: v for k, v in sampling_params.items() if k in ['min_p', 'top_k', 'top_p', 'temperature', 'repetition_penalty']}\n",
    "                \n",
    "                tokens_per_char = 20\n",
    "                estimated_tokens = len(text) * tokens_per_char\n",
    "                min_tokens = 1000\n",
    "                max_tokens = max(min_tokens, min(estimated_tokens, 86 * 120))\n",
    "                \n",
    "                codes = model.generate(\n",
    "                    prefix_conditioning=conditioning,\n",
    "                    max_new_tokens=max_tokens,\n",
    "                    cfg_scale=cfg_scale, \n",
    "                    batch_size=1, \n",
    "                    progress_bar=True,\n",
    "                    sampling_params=sampling_dict\n",
    "                )\n",
    "                audio = model.autoencoder.decode(codes).cpu().detach()\n",
    "                return audio\n",
    "            \n",
    "            globals()['enhanced_clone_voice_from_audio'] = simple_enhanced_clone_voice\n",
    "            globals()['enhanced_generate_speech'] = simple_enhanced_generate_speech\n",
    "            print(\"‚úÖ Fallback enhanced functions created (now emotion-aware)!\")\n",
    "            ENHANCED_AVAILABLE = True # Mark as available because we have the fallback\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to create fallback functions: {e}\")\n",
    "            print(\"Using standard voice cloning only.\")\n",
    "            ENHANCED_AVAILABLE = False # Ensure it's false if creation fails\n",
    "    \n",
    "    globals()['model'] = model\n",
    "    globals()['device'] = device\n",
    "    globals()['ENHANCED_AVAILABLE'] = ENHANCED_AVAILABLE \n",
    "    \n",
    "    print(\"\\nüéâ Setup complete! Ready for voice cloning.\")\n",
    "    print(\"\\nüöÄ Next: Run Cell 4 to upload your voice sample.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check internet connection\")\n",
    "    print(\"2. Restart runtime if NumPy issues persist\")\n",
    "    print(\"3. Re-run all cells from the beginning\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "upload_voice"
   },
   "outputs": [],
   "source": [
    "#@title 4. üé§ Upload Voice Sample for Cloning\n",
    "from google.colab import files\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "print(\"üé§ Voice Cloning - Upload Your Audio File\")\n",
    "print(\"Upload an audio file (10-30 seconds) to clone the speaker's voice\")\n",
    "print(\"Supported formats: WAV, MP3, FLAC, etc.\")\n",
    "print(\"\")\n",
    "\n",
    "# Upload audio file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Get the uploaded file\n",
    "    audio_file = list(uploaded.keys())[0]\n",
    "    print(f\"\\nüìÅ Processing: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Load and process the audio\n",
    "        wav, sr = torchaudio.load(audio_file)\n",
    "        \n",
    "        # Convert to mono if needed\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        \n",
    "        # Show audio info\n",
    "        duration = wav.shape[1] / sr\n",
    "        print(f\"üìä Audio Info:\")\n",
    "        print(f\"  - Duration: {duration:.1f} seconds\")\n",
    "        print(f\"  - Sample rate: {sr} Hz\")\n",
    "        print(f\"  - Channels: {wav.shape[0]}\")\n",
    "        \n",
    "        # Quality recommendations\n",
    "        if duration < 5:\n",
    "            print(\"\\n‚ö†Ô∏è Audio is quite short (< 5s). Consider using 10-20 seconds for better results.\")\n",
    "        elif duration > 30:\n",
    "            print(\"\\nüí° Audio is long (> 30s). The system will use the best portion automatically.\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Audio duration is optimal for voice cloning!\")\n",
    "        \n",
    "        # Play the audio\n",
    "        print(\"\\nüîä Preview of your audio:\")\n",
    "        ipd.display(ipd.Audio(wav.numpy(), rate=sr))\n",
    "        \n",
    "        # Create speaker embedding\n",
    "        print(\"\\nüß† Creating voice embedding...\")\n",
    "        \n",
    "        if ENHANCED_AVAILABLE and 'enhanced_cloner' in globals():\n",
    "            print(\"üöÄ Using Enhanced Voice Cloner class...\")\n",
    "            speaker_embedding, quality_metrics = enhanced_cloner.clone_voice_from_audio(\n",
    "                wav, sr,\n",
    "                target_length_seconds=min(20.0, duration),\n",
    "                normalize=True,\n",
    "                remove_silence=True,\n",
    "                analyze_quality=True\n",
    "            )\n",
    "            print(f\"\\nüìà Voice Quality Analysis:\")\n",
    "            print(f\"  - Quality Score: {quality_metrics['quality_score']:.3f} / 1.000\")\n",
    "            print(f\"  - SNR Estimate: {quality_metrics['snr_estimate']:.1f} dB\")\n",
    "            globals()['voice_quality_metrics'] = quality_metrics\n",
    "        elif ENHANCED_AVAILABLE and 'enhanced_clone_voice_from_audio' in globals():\n",
    "            print(\"üöÄ Using fallback enhanced_clone_voice_from_audio function...\")\n",
    "            speaker_embedding, quality_metrics = enhanced_clone_voice_from_audio(\n",
    "                wav, sr,\n",
    "                target_length_seconds=min(20.0, duration),\n",
    "                normalize=True,\n",
    "                remove_silence=True\n",
    "            )\n",
    "            print(f\"\\nüìà Voice Quality Analysis (from fallback):\")\n",
    "            print(f\"  - Quality Score: {quality_metrics['quality_score']:.3f} / 1.000\")\n",
    "            print(f\"  - SNR Estimate: {quality_metrics['snr_estimate']:.1f} dB\")\n",
    "            globals()['voice_quality_metrics'] = quality_metrics\n",
    "        else:\n",
    "            print(\"üì¢ Using standard Zonos model.make_speaker_embedding...\")\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "            globals()['voice_quality_metrics'] = {} # No specific quality metrics for standard\n",
    "        \n",
    "        globals()['cloned_voice'] = speaker_embedding\n",
    "        globals()['original_audio_file'] = audio_file\n",
    "        \n",
    "        print(\"\\n‚úÖ Voice cloning successful!\")\n",
    "        print(\"Your cloned voice is ready to use in Cell 5.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing audio: {e}\")\n",
    "        print(\"Please try a different audio file or check the format.\")\n",
    "else:\n",
    "    print(\"No file uploaded. You can still use the default voice in Cell 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "generate_speech"
   },
   "outputs": [],
   "source": [
    "#@title 5. üé§ Generate Speech with Enhanced Voice Cloning\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#@markdown ### Text and Settings\n",
    "text = \"Hello! This is an enhanced voice cloning demonstration using Zonos TTS. The new system provides much better consistency and naturalness.\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### Voice Quality Preset\n",
    "#@markdown Select a preset to balance speed, quality, and expressiveness. Advanced settings are optimized based on your choice.\n",
    "quality_preset = \"Balanced\" #@param [\"Conservative\", \"Balanced\", \"Fast (Less Expressive)\", \"Expressive\", \"Creative\"]\n",
    "\n",
    "#@markdown **Quality Preset Descriptions:**\n",
    "#@markdown - **Conservative**: Safe, stable output with minimal artifacts. Good for challenging audio or when maximum clarity is needed.\n",
    "#@markdown - **Balanced**: Good balance of quality, naturalness, and speed (recommended starting point).\n",
    "#@markdown - **Fast (Less Expressive)**: Prioritizes generation speed by using a lower CFG Scale (1.5). Output may be flatter or less expressive but is significantly faster.\n",
    "#@markdown - **Expressive**: More dynamic and expressive speech, with an adjusted emotional profile for liveliness (e.g., slightly happier/more surprised).\n",
    "#@markdown - **Creative**: Experimental, most expressive but may have artifacts, with a unique, diverse emotional profile.\n",
    "#@markdown \n",
    "#@markdown *Underlying parameters like CFG Scale, pitch variation, speaking rate, and sampling settings (min_p, temperature) are automatically adjusted based on your voice sample's quality and the chosen preset. The 'Expressive' and 'Creative' presets also apply specific emotion vectors.*\n",
    "\n",
    "print(\"üé§ Enhanced Voice Cloning Generation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "speaker_embedding = globals().get('cloned_voice', None)\n",
    "if speaker_embedding is not None:\n",
    "    print(\"üé≠ Using your cloned voice!\")\n",
    "    if 'original_audio_file' in globals(): print(f\"üìÅ Voice source: {original_audio_file}\")\n",
    "else:\n",
    "    print(\"üé§ Using default voice (upload audio in Cell 4 to use your own voice)\")\n",
    "\n",
    "print(f\"\\nüéµ Generating speech...\")\n",
    "print(f\"üìù Text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "print(f\"üåç Language: {language}\")\n",
    "print(f\"üé≤ Seed: {seed}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    use_enhanced_cloner_class = ENHANCED_AVAILABLE and 'enhanced_cloner' in globals()\n",
    "    use_fallback_enhanced_func = ENHANCED_AVAILABLE and not use_enhanced_cloner_class and 'enhanced_generate_speech' in globals()\n",
    "\n",
    "    if use_enhanced_cloner_class or use_fallback_enhanced_func:\n",
    "        print(f\"üöÄ Using Enhanced Voice Cloning system...\")\n",
    "        voice_quality = globals().get('voice_quality_metrics', None)\n",
    "        print(f\"üéØ Using {quality_preset} preset with automatic optimization...\")\n",
    "        quality_score = voice_quality.get('quality_score', 0.7) if voice_quality else 0.7\n",
    "        snr_estimate = voice_quality.get('snr_estimate', 20.0) if voice_quality else 20.0\n",
    "        \n",
    "        emotion_vector_override = None \n",
    "\n",
    "        if quality_preset == \"Conservative\":\n",
    "            base_pitch = 8.0; base_rate = 10.0; base_min_p = 0.02; base_temp = 0.6; cfg_scale_notebook = 2.5\n",
    "        elif quality_preset == \"Fast (Less Expressive)\":\n",
    "            base_pitch = 8.0; base_rate = 10.0; base_min_p = 0.03; base_temp = 0.7; cfg_scale_notebook = 1.5\n",
    "        elif quality_preset == \"Expressive\":\n",
    "            base_pitch = 18.0; base_rate = 14.0; base_min_p = 0.06; base_temp = 0.85; cfg_scale_notebook = 2.0\n",
    "            emotion_vector_override = [0.6, 0.05, 0.05, 0.05, 0.1, 0.05, 0.05, 0.05] \n",
    "        elif quality_preset == \"Creative\":\n",
    "            base_pitch = 22.0; base_rate = 16.0; base_min_p = 0.08; base_temp = 0.95; cfg_scale_notebook = 1.8\n",
    "            emotion_vector_override = [0.2, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1] \n",
    "        else:  # Balanced (default)\n",
    "            base_pitch = 12.0; base_rate = 12.0; base_min_p = 0.04; base_temp = 0.75; cfg_scale_notebook = 2.2\n",
    "        \n",
    "        quality_factor = min(1.2, max(0.8, quality_score * 1.2))\n",
    "        snr_factor = min(1.1, max(0.9, (snr_estimate - 15.0) / 20.0 + 1.0))\n",
    "        pitch_std = max(5.0, min(25.0, base_pitch * quality_factor))\n",
    "        speaking_rate = max(8.0, min(18.0, base_rate * snr_factor))\n",
    "        min_p = max(0.01, min(0.15, base_min_p * quality_factor))\n",
    "        temperature = max(0.5, min(1.0, base_temp * quality_factor))\n",
    "        cfg_scale_notebook = max(1.0, min(3.0, cfg_scale_notebook)) \n",
    "        \n",
    "        custom_conditioning = {'pitch_std': pitch_std, 'speaking_rate': speaking_rate}\n",
    "        custom_sampling = {'min_p': min_p, 'temperature': temperature}\n",
    "        \n",
    "        print(f\"üìä Automatically optimized parameters (for this cell's run):\")\n",
    "        if voice_quality: print(f\"  - Voice quality score: {quality_score:.3f}\")\n",
    "        if voice_quality: print(f\"  - SNR estimate: {snr_estimate:.1f} dB\")\n",
    "        print(f\"  - Pitch variation: {pitch_std:.1f}\")\n",
    "        print(f\"  - Speaking rate: {speaking_rate:.1f}\")\n",
    "        print(f\"  - Sampling min_p: {min_p:.3f}\")\n",
    "        print(f\"  - Temperature: {temperature:.2f}\")\n",
    "        print(f\"  - CFG Scale (from preset): {cfg_scale_notebook:.1f}\")\n",
    "        if emotion_vector_override: print(f\"  - Emotion Vector Override: {emotion_vector_override}\")\n",
    "\n",
    "        if use_fallback_enhanced_func:\n",
    "            print(\"üöÄ Using fallback enhanced_generate_speech function (now emotion-aware)...\")\n",
    "            audio = enhanced_generate_speech(\n",
    "                text=text, speaker_embedding=speaker_embedding, language=language,\n",
    "                voice_quality=voice_quality, custom_conditioning_params=custom_conditioning,\n",
    "                custom_sampling_params=custom_sampling, cfg_scale=cfg_scale_notebook, seed=seed,\n",
    "                emotion_vector=emotion_vector_override \n",
    "            )\n",
    "            sample_rate = model.autoencoder.sampling_rate\n",
    "        elif use_enhanced_cloner_class:\n",
    "            print(\"üöÄ Using EnhancedVoiceCloner class...\")\n",
    "            audio = enhanced_cloner.generate_speech(\n",
    "                text=text, speaker_embedding=speaker_embedding, language=language,\n",
    "                voice_quality=voice_quality, custom_conditioning_params=custom_conditioning,\n",
    "                custom_sampling_params=custom_sampling, cfg_scale=cfg_scale_notebook, seed=seed,\n",
    "                emotion_vector=emotion_vector_override \n",
    "            )\n",
    "            sample_rate = enhanced_cloner.model.autoencoder.sampling_rate \n",
    "        else:\n",
    "             raise Exception(\"Logic error: No valid enhanced generation function determined.\")\n",
    "        print(f\"‚úÖ Enhanced generation completed!\")\n",
    "        \n",
    "    else: \n",
    "        print(\"üì¢ Using standard Zonos model.generate (no enhanced features or emotion override)...\")\n",
    "        cfg_scale_notebook = 2.2\n",
    "        cond_dict = make_cond_dict(text=text, language=language, speaker=speaker_embedding, device=device)\n",
    "        conditioning = model.prepare_conditioning(cond_dict, cfg_scale=cfg_scale_notebook)\n",
    "        tokens_per_char = 20\n",
    "        estimated_tokens = len(text) * tokens_per_char\n",
    "        min_tokens = 1000\n",
    "        max_tokens = max(min_tokens, min(estimated_tokens, 86 * 120))\n",
    "        codes = model.generate(\n",
    "            prefix_conditioning=conditioning, max_new_tokens=max_tokens,\n",
    "            cfg_scale=cfg_scale_notebook, batch_size=1, progress_bar=True\n",
    "        )\n",
    "        audio = model.autoencoder.decode(codes).cpu().detach()\n",
    "        sample_rate = model.autoencoder.sampling_rate\n",
    "        print(f\"‚úÖ Standard generation completed!\")\n",
    "    \n",
    "    if audio.dim() == 2 and audio.size(0) > 1: audio = audio[0:1, :]\n",
    "    generation_time = time.time() - start_time\n",
    "    duration = audio.shape[-1] / sample_rate\n",
    "    \n",
    "    print(f\"\\nüìä Generation Stats:\")\n",
    "    print(f\"  - Generation time: {generation_time:.2f} seconds\")\n",
    "    print(f\"  - Audio duration: {duration:.2f} seconds\")\n",
    "    print(f\"  - Sample rate: {sample_rate} Hz\")\n",
    "    \n",
    "    print(f\"\\nüîä Generated Audio:\")\n",
    "    wav_numpy = audio.squeeze().numpy()\n",
    "    ipd.display(ipd.Audio(wav_numpy, rate=sample_rate))\n",
    "    globals()['last_generated_audio'] = (wav_numpy, sample_rate)\n",
    "    \n",
    "    if use_enhanced_cloner_class or use_fallback_enhanced_func:\n",
    "        print(\"\\nüéâ Enhanced voice cloning features used.\")\n",
    "    print(f\"\\n‚úÖ Success! Your voice clone is ready.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during audio generation: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"- Try shorter text (under 200 characters)\")\n",
    "    print(\"- Check GPU memory usage\")\n",
    "    print(\"- Restart runtime if NumPy issues persist\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark_cell_new",
    "title": "6. üìä Run CFG Scale Benchmarks"
   },
   "outputs": [],
   "source": [
    "#@title 6. üìä Run CFG Scale Benchmarks\n",
    "#@markdown This cell runs benchmarks with different CFG scales (1.0, 1.5, 2.2). Other generation parameters (pitch, rate, sampling) are based on the 'Balanced' preset to isolate the impact of CFG Scale.\n",
    "#@markdown - **CFG Scale 1.0**: Typically offers the fastest generation but may result in the least expressive or most robotic audio. \n",
    "#@markdown - **CFG Scale 1.5**: Used by the \"Fast (Less Expressive)\" preset in Cell 5. Aims for a balance between speed and quality, though still less expressive than higher CFG scales.\n",
    "#@markdown - **CFG Scale 2.2**: Default for the \"Balanced\" preset in Cell 5, offering a good blend of quality and naturalness.\n",
    "#@markdown Results will show Real-Time Factor (RTF), audio duration, generation time, and allow you to listen to each sample.\n",
    "#@markdown \n",
    "#@markdown **IMPORTANT:** If `zonos/model.py` (or other underlying model code) has been changed due to updates or local modifications, you **MUST re-run Cell 3 (Load Model)** to load the new model code *before* running these benchmarks or generating audio in Cell 5.\n",
    "\n",
    "import time\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "benchmark_audio_dir = \"/content/Zonos/benchmark_audio\"\n",
    "if not os.path.exists(benchmark_audio_dir):\n",
    "    os.makedirs(benchmark_audio_dir)\n",
    "\n",
    "def run_benchmark_trial(text_input, language_code, seed_value, cfg_scale_to_test, quality_preset_value, \n",
    "                        speaker_embedding_tensor, voice_quality_data, \n",
    "                        zonos_model, torch_device, \n",
    "                        run_warmup=False):\n",
    "    print(f\"\\n--- Benchmarking Trial ---\")\n",
    "    print(f\"Text: '{text_input[:50]}...' ({len(text_input)} chars)\")\n",
    "    print(f\"CFG Scale: {cfg_scale_to_test}, Preset (base for other params): {quality_preset_value}\")\n",
    "\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    quality_score = voice_quality_data.get('quality_score', 0.7) if voice_quality_data else 0.7\n",
    "    snr_estimate = voice_quality_data.get('snr_estimate', 20.0) if voice_quality_data else 20.0\n",
    "\n",
    "    # Use base parameters from the 'Balanced' preset for consistency in benchmark, CFG is overridden\n",
    "    base_pitch, base_rate, base_min_p, base_temp = 12.0, 12.0, 0.04, 0.75\n",
    "\n",
    "    quality_factor = min(1.2, max(0.8, quality_score * 1.2))\n",
    "    snr_factor = min(1.1, max(0.9, (snr_estimate - 15.0) / 20.0 + 1.0))\n",
    "    \n",
    "    pitch_std = max(5.0, min(25.0, base_pitch * quality_factor))\n",
    "    speaking_rate = max(8.0, min(18.0, base_rate * snr_factor))\n",
    "    min_p_val = max(0.01, min(0.15, base_min_p * quality_factor))\n",
    "    temperature_val = max(0.5, min(1.0, base_temp * quality_factor))\n",
    "\n",
    "    current_custom_conditioning = {'pitch_std': pitch_std, 'speaking_rate': speaking_rate}\n",
    "    current_custom_sampling = {'min_p': min_p_val, 'temperature': temperature_val}\n",
    "\n",
    "    if run_warmup:\n",
    "        print(\"Running warmup...\")\n",
    "        warmup_text = \"Warmup.\"\n",
    "        warmup_cond_dict = make_cond_dict(\n",
    "            text=warmup_text, language=language_code, speaker=speaker_embedding_tensor,\n",
    "            device=torch_device, **current_custom_conditioning\n",
    "        )\n",
    "        warmup_conditioning = zonos_model.prepare_conditioning(warmup_cond_dict, cfg_scale=cfg_scale_to_test)\n",
    "        _ = zonos_model.generate(\n",
    "            prefix_conditioning=warmup_conditioning, max_new_tokens=30, cfg_scale=cfg_scale_to_test,\n",
    "            batch_size=1, sampling_params=current_custom_sampling, progress_bar=False\n",
    "        )\n",
    "        print(\"Warmup complete.\")\n",
    "\n",
    "    generation_start_time = time.time()\n",
    "    cond_dict = make_cond_dict(\n",
    "        text=text_input, language=language_code, speaker=speaker_embedding_tensor,\n",
    "        device=torch_device, **current_custom_conditioning \n",
    "    )\n",
    "    prepared_conditioning = zonos_model.prepare_conditioning(cond_dict, cfg_scale=cfg_scale_to_test)\n",
    "    \n",
    "    tokens_per_char = 15 \n",
    "    estimated_tokens = len(text_input) * tokens_per_char\n",
    "    min_gen_tokens = 200\n",
    "    max_gen_tokens = max(min_gen_tokens, min(estimated_tokens, 86 * 100))\n",
    "\n",
    "    codes = zonos_model.generate(\n",
    "        prefix_conditioning=prepared_conditioning, max_new_tokens=max_gen_tokens,\n",
    "        cfg_scale=cfg_scale_to_test, batch_size=1, \n",
    "        sampling_params=current_custom_sampling, progress_bar=True\n",
    "    )\n",
    "    audio_output = zonos_model.autoencoder.decode(codes).cpu().detach()\n",
    "    generation_time = time.time() - generation_start_time\n",
    "    sample_rate = zonos_model.autoencoder.sampling_rate\n",
    "    \n",
    "    if audio_output.dim() == 2 and audio_output.size(0) > 1: audio_output = audio_output[0:1, :]\n",
    "    audio_duration = audio_output.shape[-1] / sample_rate\n",
    "    rtf = generation_time / audio_duration if audio_duration > 0 else float('inf')\n",
    "    \n",
    "    print(f\"  Generated {audio_duration:.2f}s audio in {generation_time:.2f}s. RTF: {rtf:.2f}\")\n",
    "\n",
    "    clean_text_for_filename = text_input[:20].replace(' ', '_').replace('.', '').replace('!', '').replace('?', '')\n",
    "    audio_filename = f\"benchmark_cfg_{cfg_scale_to_test}_seed_{seed_value}_text_{clean_text_for_filename}.wav\"\n",
    "    audio_filepath = os.path.join(benchmark_audio_dir, audio_filename)\n",
    "    torchaudio.save(audio_filepath, audio_output.squeeze(0), sample_rate)\n",
    "    print(f\"  Saved audio to: {audio_filepath}\")\n",
    "    return rtf, audio_duration, generation_time, audio_filepath\n",
    "\n",
    "texts_to_benchmark = [\n",
    "    \"Hello world.\",\n",
    "    \"This is a test of the emergency broadcast system.\",\n",
    "    \"The quick brown fox jumps over the lazy dog, and other fables are often used for typing practice.\"\n",
    "]\n",
    "cfg_scales_to_benchmark = [1.0, 1.5, 2.2]\n",
    "benchmark_language = \"en-us\"\n",
    "benchmark_seed = 42 \n",
    "benchmark_quality_preset_for_other_params = \"Balanced\" \n",
    "benchmark_results_list = [] \n",
    "\n",
    "if 'model' not in globals() or 'device' not in globals():\n",
    "    print(\"‚ö†Ô∏è Model or device not found. Please run previous cells (1-3) to load the model.\")\n",
    "elif 'make_cond_dict' not in globals():\n",
    "    print(\"‚ö†Ô∏è make_cond_dict not found. Please ensure Cell 3 (model loading) has run successfully.\")\n",
    "else:\n",
    "    current_speaker_embedding = globals().get('cloned_voice', None)\n",
    "    if current_speaker_embedding is None: print(\"üé§ No cloned voice found. Using default speaker if model supports.\")\n",
    "    current_voice_quality_metrics = globals().get('voice_quality_metrics', {})\n",
    "    \n",
    "    print(\"\\nüî• Running a single warm-up generation before benchmark loop (using CFG 2.2 from preset)...\")\n",
    "    run_benchmark_trial(\n",
    "        \"Warmup text.\", benchmark_language, benchmark_seed, 2.2, \n",
    "        benchmark_quality_preset_for_other_params, current_speaker_embedding, current_voice_quality_metrics,\n",
    "        model, device, run_warmup=False \n",
    "    )\n",
    "    print(\"üî• Warm-up finished.\\n\")\n",
    "\n",
    "    for cfg_val in cfg_scales_to_benchmark:\n",
    "        for text_sample in texts_to_benchmark:\n",
    "            rtf, audio_dur, gen_time, audio_file = run_benchmark_trial(\n",
    "                text_sample, benchmark_language, benchmark_seed, cfg_val,\n",
    "                benchmark_quality_preset_for_other_params, current_speaker_embedding, current_voice_quality_metrics,\n",
    "                model, device\n",
    "            )\n",
    "            benchmark_results_list.append({\n",
    "                \"text\": text_sample,\n",
    "                \"cfg_scale\": cfg_val,\n",
    "                \"rtf\": rtf,\n",
    "                \"audio_duration\": audio_dur,\n",
    "                \"generation_time\": gen_time,\n",
    "                \"audio_file\": audio_file\n",
    "            })\n",
    "\n",
    "    print(\"\\n\\n--- Benchmark Summary ---\")\n",
    "    table_header = f\"{'CFG':<5} | {'Text Len':<8} | {'RTF':<5} | {'Audio (s)':<10} | {'Gen Time (s)':<12} | {'File':<70}\"\n",
    "    print(table_header)\n",
    "    print(\"-\" * len(table_header))\n",
    "    for res in benchmark_results_list:\n",
    "        text_len_desc = \"Short\" if len(res['text']) < 20 else \"Medium\" if len(res['text']) < 70 else \"Long\"\n",
    "        print(f\"{res['cfg_scale']:<5.1f} | {text_len_desc:<8} | {res['rtf']:<5.2f} | {res['audio_duration']:<10.2f} | {res['generation_time']:<12.2f} | {os.path.basename(res['audio_file']):<70}\")\n",
    "        ipd.display(ipd.HTML(f\"<b>Text:</b> {res['text']}<br><b>CFG:</b> {res['cfg_scale']}, <b>File:</b> {res['audio_file']}\"))\n",
    "        ipd.display(ipd.Audio(res['audio_file']))\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "    globals()['benchmark_run_results_list'] = benchmark_results_list\n",
    "\n",
    "print(\"\\n‚úÖ Benchmarking cell execution complete.\")\n",
    "print(\"Reminder: If you've updated zonos/model.py or other core files, ensure you've re-run Cell 3 to load changes before running Cell 5 or this benchmark cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary_header"
   },
   "source": [
    "---\n",
    "## üéâ Enhanced Voice Cloning Complete!\n",
    "\n",
    "You've successfully used the enhanced voice cloning system with Zonos TTS. This notebook provides a comprehensive suite for voice cloning, generation, and performance benchmarking.\n",
    "\n",
    "### üöÄ What's Enhanced & Key Features:\n",
    "- **Improved Speech Quality**: Significant reductions in gibberish, better timing consistency, and more natural speech flow.\n",
    "- **Advanced Audio Preprocessing**: Automatic silence removal and normalization for uploaded voice samples.\n",
    "- **Voice Quality Analysis**: SNR estimation and quality scoring for your voice samples to guide parameter choices.\n",
    "- **Flexible Quality Presets**: \n",
    "    - Choose from presets like \"Conservative\", \"Balanced\", \"Fast (Less Expressive)\", \"Expressive\", and \"Creative\".\n",
    "    - \"Fast\" preset uses a lower CFG Scale (1.5) for quicker generation with a trade-off in expressiveness.\n",
    "    - \"Expressive\" and \"Creative\" presets now incorporate specific emotion vectors for more vivid speech.\n",
    "- **Adaptive Settings**: Parameters automatically adjust based on your voice sample's quality and chosen preset.\n",
    "- **CFG Scale Control**: Support for `cfg_scale=1.0` (and other values) in `zonos.model.py` allows for fine-tuning the balance between speed and expressiveness. This is benchmarked in Cell 6.\n",
    "- **Reproducible Results**: Seed support for consistent audio generation.\n",
    "- **Google Colab Compatibility**: Streamlined setup and dependency management within the Colab environment.\n",
    "- **Benchmarking Tools**: Cell 6 allows for systematic testing of different CFG Scales to understand performance and quality trade-offs.\n",
    "\n",
    "### üí° Tips for Best Results:\n",
    "- Use clean, high-quality audio (16kHz+ sample rate, minimal background noise/music) for voice cloning.\n",
    "- Provide 10-20 seconds of clear speech for optimal cloning.\n",
    "- Experiment with different Quality Presets in Cell 5 to find the best match for your needs.\n",
    "- If modifying underlying code (like `zonos/model.py`), always re-run Cell 3 (Load Model) to apply changes.\n",
    "\n",
    "### üîß If You Encountered Issues:\n",
    "- **NumPy or other dependency errors**: Try `Runtime` > `Restart runtime` (or `Factory reset runtime`) then re-run cells from the beginning (Cell 1 onwards).\n",
    "- **Model loading errors after code changes**: Ensure you've re-run Cell 3.\n",
    "- **Memory errors**: Try shorter text for generation or restart the runtime.\n",
    "- **Audio quality issues**: Use cleaner source audio for cloning. Experiment with different presets in Cell 5.\n",
    "\n",
    "---\n",
    "\n",
    "**üé§ Thank you for using Enhanced Voice Cloning with Zonos TTS!**\n",
    "\n",
    "For more information, visit: [Zonos GitHub Repository](https://github.com/Wamp1re-Ai/Zonos)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
