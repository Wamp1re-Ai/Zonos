{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🔧 Quick NumPy Check (Optional)\n",
    "# Run this cell first if you want to check for NumPy compatibility issues\n",
    "# This is optional - you can skip to Cell 1 if you prefer\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    \n",
    "    print(f\"Current NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"⚠️ WARNING: NumPy 2.x detected!\")\n",
    "        print(\"This may cause compatibility issues with transformers.\")\n",
    "        print(\"If you get errors in Cell 3, restart runtime and try again.\")\n",
    "    else:\n",
    "        print(\"✅ NumPy version looks compatible\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"NumPy not installed yet - this is normal\")\n",
    "    \n",
    "print(\"\\n🚀 Ready to proceed! Continue with Cell 1 below.\")\n",
    "print(\"(Remember: if you get errors, just restart runtime and try again)\")\n",
    "\n",
    "# Also check if we're in Colab\n",
    "if 'google.colab' in str(type(get_ipython())):\n",
    "    print(\"\\n✅ Running in Google Colab\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Not running in Google Colab - some features may not work\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54137773",
   "metadata": {},
   "source": [
    "# Zonos Model: Google Colab Notebook\n",
    "\n",
    "This notebook will help you set up and run the Zonos model in Google Colab. The model will be automatically downloaded from [Hugging Face](https://huggingface.co/Wamp1re-Ai/Zonos-v0.1-transformer).\n",
    "\n",
    "## Steps:\n",
    "1. Clone or upload the Zonos repository and download the model from HuggingFace.\n",
    "2. Install dependencies.\n",
    "3. Run the model with example code.\n",
    "4. (Optional) Upload your own audio files for inference.\n",
    "5. Use Cloudflare subdomain for sharing your Gradio interface.\n",
    "\n",
    "## ⚠️ Important: NumPy Compatibility Issue\n",
    "\n",
    "**If you get a NumPy/Transformers error in Cell 3**, this is a known compatibility issue:\n",
    "- **Problem**: Google Colab sometimes loads NumPy 2.x which is incompatible with transformers\n",
    "- **Symptom**: Error mentioning `_center` or NumPy in transformers import\n",
    "- **Solution**: **Restart runtime** (Runtime → Restart runtime) and re-run cells 1-3\n",
    "\n",
    "This is **normal** and **easy to fix** - just restart the runtime when prompted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade15647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Clone the repository and download the model\n",
    "import os\n",
    "\n",
    "# Clone the Zonos repository (use the correct URL)\n",
    "if not os.path.exists('Zonos'):\n",
    "    !git clone https://github.com/Wamp1re-Ai/Zonos.git  # Change this to your actual GitHub username\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"Repository already exists!\")\n",
    "\n",
    "%cd Zonos\n",
    "\n",
    "# Install system dependencies first (eSpeak is required for phonemization)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y espeak-ng git-lfs\n",
    "\n",
    "# Initialize git LFS\n",
    "!git lfs install\n",
    "\n",
    "print(\"System dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b350a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Install dependencies\n",
    "# Install required packages efficiently and avoid dependency conflicts\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_package(package, use_uv=False):\n",
    "    \"\"\"Install a package with better error handling\"\"\"\n",
    "    try:\n",
    "        if use_uv:\n",
    "            subprocess.check_call([\"uv\", \"pip\", \"install\", package, \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "        else:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Install UV for faster package management\n",
    "print(\"Installing UV for faster package management...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"uv\", \"--quiet\"])\n",
    "    print(\"✓ UV installed successfully!\")\n",
    "    use_uv = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Failed to install UV, falling back to pip\")\n",
    "    use_uv = False\n",
    "\n",
    "# Don't upgrade pip/setuptools in Colab - it causes conflicts\n",
    "print(\"Skipping pip upgrade to avoid dependency conflicts in Colab...\")\n",
    "\n",
    "# Check if we're in Colab and use pre-installed torch if available\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Use Colab's pre-installed PyTorch to save time\n",
    "    print(\"Using Colab's pre-installed PyTorch...\")\n",
    "    try:\n",
    "        import torch\n",
    "        import torchaudio\n",
    "        print(f\"✓ PyTorch {torch.__version__} already available\")\n",
    "        print(f\"✓ TorchAudio {torchaudio.__version__} already available\")\n",
    "        torch_installed = True\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not found, will install...\")\n",
    "        torch_installed = False\n",
    "else:\n",
    "    torch_installed = False\n",
    "\n",
    "# Check current numpy version BEFORE any installations\n",
    "print(\"\\n🔍 Checking current NumPy version...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    current_numpy = np.__version__\n",
    "    numpy_major, numpy_minor = map(int, current_numpy.split('.')[:2])\n",
    "    print(f\"Current NumPy: {current_numpy}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"⚠️ NumPy 2.x detected - this will cause transformers compatibility issues!\")\n",
    "        numpy_needs_fix = True\n",
    "    else:\n",
    "        print(\"✓ NumPy version is compatible\")\n",
    "        numpy_needs_fix = False\n",
    "except ImportError:\n",
    "    print(\"NumPy not installed yet\")\n",
    "    numpy_needs_fix = False\n",
    "\n",
    "# Force install compatible numpy version if needed\n",
    "if numpy_needs_fix or not IN_COLAB:\n",
    "    print(\"\\n🔧 Installing compatible NumPy version...\")\n",
    "    if use_uv:\n",
    "        subprocess.check_call([\"uv\", \"pip\", \"install\", \"numpy==1.26.4\", \"--force-reinstall\", \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "    else:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--force-reinstall\", \"--quiet\"])\n",
    "    print(\"✓ NumPy 1.26.4 installed\")\n",
    "    \n",
    "    if numpy_needs_fix:\n",
    "        print(\"\\n⚠️ IMPORTANT: NumPy was downgraded from 2.x to 1.26.4\")\n",
    "        print(\"This may not take effect until you restart the runtime.\")\n",
    "        print(\"If you get import errors in the next cell, please:\")\n",
    "        print(\"  1. Runtime → Restart runtime\")\n",
    "        print(\"  2. Re-run cells 1, 2, and 3\")\n",
    "\n",
    "# Install core dependencies with compatible versions\n",
    "packages = [\n",
    "    \"transformers>=4.45.0,<4.50.0\",  # Pin to avoid compatibility issues\n",
    "    \"gradio>=4.0.0,<5.0.0\", \n",
    "    \"huggingface-hub>=0.20.0\",\n",
    "    \"soundfile>=0.12.1\",\n",
    "    \"phonemizer>=3.2.0\",\n",
    "    \"inflect>=7.0.0\",\n",
    "    \"scipy\"\n",
    "]\n",
    "\n",
    "# Add torch packages if not already installed\n",
    "if not torch_installed:\n",
    "    packages = [\"torch>=2.0.0\", \"torchaudio>=2.0.0\"] + packages\n",
    "\n",
    "print(f\"\\nInstalling {len(packages)} core dependencies...\")\n",
    "failed_packages = []\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    if not install_package(package, use_uv):\n",
    "        failed_packages.append(package)\n",
    "\n",
    "if failed_packages:\n",
    "    print(f\"\\n⚠️ Failed to install: {failed_packages}\")\n",
    "    print(\"Continuing anyway - some packages might work...\")\n",
    "\n",
    "# Install optional dependencies with better error handling\n",
    "print(\"\\nInstalling optional dependencies (these may fail - it's normal)...\")\n",
    "optional_packages = [\n",
    "    (\"flash-attn>=2.0.0\", \"Flash Attention for faster inference\"),\n",
    "    (\"mamba-ssm>=1.0.0\", \"Mamba State Space Models\"), \n",
    "    (\"causal-conv1d>=1.0.0\", \"Causal Conv1D for Mamba\")\n",
    "]\n",
    "\n",
    "optional_success = 0\n",
    "for package, description in optional_packages:\n",
    "    print(f\"Attempting to install {package} ({description})...\")\n",
    "    if install_package(package, use_uv):\n",
    "        print(f\"  ✓ {package} installed successfully\")\n",
    "        optional_success += 1\n",
    "    else:\n",
    "        print(f\"  ✗ {package} installation failed (optional - continuing)\")\n",
    "\n",
    "# Install the project itself\n",
    "print(\"\\nInstalling Zonos package...\")\n",
    "try:\n",
    "    if use_uv:\n",
    "        subprocess.check_call([\"uv\", \"pip\", \"install\", \"-e\", \".\", \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "    else:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\", \"--quiet\"])\n",
    "    print(\"✓ Zonos package installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ Failed to install Zonos package: {e}\")\n",
    "    print(\"Trying alternative installation...\")\n",
    "    # Alternative: add current directory to Python path\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.insert(0, current_dir)\n",
    "    print(f\"Added {current_dir} to Python path\")\n",
    "\n",
    "# Verify critical imports work\n",
    "print(\"\\n🔍 Verifying critical imports...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"✓ NumPy {np.__version__} working\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ NumPy import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"✓ Transformers {transformers.__version__} working\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Transformers import failed: {e}\")\n",
    "    if \"_center\" in str(e) or \"numpy\" in str(e).lower():\n",
    "        print(\"\\n🔧 This looks like the NumPy 2.x compatibility issue!\")\n",
    "        print(\"Please restart the runtime and try again.\")\n",
    "\n",
    "print(\"\\n✅ Dependency installation complete!\")\n",
    "print(\"\\n📝 Installation Summary:\")\n",
    "print(f\"  - Package manager: {'UV' if use_uv else 'pip'}\")\n",
    "print(f\"  - Core packages: {len(packages) - len(failed_packages)}/{len(packages)} successful\")\n",
    "print(f\"  - Optional packages: {optional_success}/{len(optional_packages)} successful\")\n",
    "if failed_packages:\n",
    "    print(f\"  - Failed packages: {failed_packages}\")\n",
    "print(f\"  - Zonos package: Installed\")\n",
    "print(f\"  - NumPy compatibility: {'Fixed' if numpy_needs_fix else 'OK'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Load and run the Zonos model\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Make sure we can import zonos modules\n",
    "if '/content/Zonos' not in sys.path:\n",
    "    sys.path.insert(0, '/content/Zonos')\n",
    "\n",
    "# CRITICAL: Check numpy compatibility first - this must be done before importing transformers\n",
    "print(\"🔧 Checking NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major, numpy_minor = map(int, numpy_version.split('.')[:2])\n",
    "    print(f\"Current NumPy: {numpy_version}\")\n",
    "    \n",
    "    # Check if numpy version is compatible - NumPy 2.x causes issues\n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\n❌ CRITICAL ERROR: NumPy 2.x detected!\")\n",
    "        print(\"NumPy 2.x is incompatible with transformers library.\")\n",
    "        print(\"\\n🔄 SOLUTION REQUIRED:\")\n",
    "        print(\"1. Click 'Runtime' in the top menu\")\n",
    "        print(\"2. Click 'Restart runtime'\")\n",
    "        print(\"3. Run Cell 1 (Clone repository)\")\n",
    "        print(\"4. Run Cell 2 (Install dependencies)\")\n",
    "        print(\"5. Run Cell 3 (this cell) again\")\n",
    "        print(\"\\n💡 Why this happens:\")\n",
    "        print(\"- Colab sometimes has NumPy 2.x pre-loaded in memory\")\n",
    "        print(\"- Restarting clears memory and uses our installed NumPy 1.26.4\")\n",
    "        print(\"- This is a known compatibility issue with transformers\")\n",
    "        raise RuntimeError(\"NumPy 2.x compatibility issue - runtime restart required\")\n",
    "    else:\n",
    "        print(f\"✓ NumPy {numpy_version} is compatible\")\n",
    "except ImportError:\n",
    "    print(\"❌ NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    if \"restart\" in str(e) or \"compatibility\" in str(e):\n",
    "        raise\n",
    "    print(f\"❌ NumPy error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\n📦 Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"✓ PyTorch {torch.__version__} loaded successfully\")\n",
    "    print(f\"✓ TorchAudio {torchaudio.__version__} loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PyTorch import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import transformers with enhanced error handling\n",
    "print(\"\\n🤗 Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"✓ Transformers {transformers.__version__} loaded successfully\")\n",
    "except ImportError as e:\n",
    "    error_msg = str(e)\n",
    "    if \"_center\" in error_msg or \"numpy\" in error_msg.lower():\n",
    "        print(f\"❌ NumPy/Transformers compatibility error: {e}\")\n",
    "        print(\"\\n🔧 DETECTED: NumPy 2.x compatibility issue\")\n",
    "        print(\"\\n📋 REQUIRED SOLUTION:\")\n",
    "        print(\"┌─────────────────────────────────────┐\")\n",
    "        print(\"│ 1. Runtime → Restart runtime        │\")\n",
    "        print(\"│ 2. Run Cell 1 (Clone)              │\")\n",
    "        print(\"│ 3. Run Cell 2 (Dependencies)       │\")\n",
    "        print(\"│ 4. Run Cell 3 (Model) again        │\")\n",
    "        print(\"└─────────────────────────────────────┘\")\n",
    "        print(\"\\n💡 This happens because:\")\n",
    "        print(\"- NumPy 2.x was loaded before we could replace it\")\n",
    "        print(\"- Restarting runtime will use our NumPy 1.26.4\")\n",
    "        print(\"- This is the only way to fix this compatibility issue\")\n",
    "        raise RuntimeError(\"NumPy/Transformers compatibility issue - restart required\")\n",
    "    else:\n",
    "        print(f\"❌ Transformers import error: {e}\")\n",
    "        print(\"\\nTry:\")\n",
    "        print(\"1. Restart runtime\")\n",
    "        print(\"2. Re-run all cells from the beginning\")\n",
    "        raise\n",
    "\n",
    "# Now try to import Zonos modules\n",
    "print(\"\\n🎵 Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"✓ Zonos modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Zonos import error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"- Make sure Cell 2 (dependency installation) completed successfully\")\n",
    "    print(\"- Check that you're in the Zonos directory\")\n",
    "    print(\"- Try restarting runtime and running from Cell 1\")\n",
    "    \n",
    "    # Try importing individual modules to diagnose the issue\n",
    "    print(\"\\n🔍 Diagnostic imports:\")\n",
    "    try:\n",
    "        from zonos import model\n",
    "        print(\"✓ zonos.model imported\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ zonos.model failed: {e2}\")\n",
    "    \n",
    "    try:\n",
    "        from zonos import conditioning\n",
    "        print(\"✓ zonos.conditioning imported\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ zonos.conditioning failed: {e2}\")\n",
    "    \n",
    "    raise\n",
    "\n",
    "# Set device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n🖥️ Using device: {device}\")\n",
    "\n",
    "# Check GPU memory if using CUDA\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✓ GPU cache cleared\")\n",
    "\n",
    "# Load the model from HuggingFace\n",
    "model_name = \"Wamp1re-Ai/Zonos-v0.1-transformer\"\n",
    "print(f\"\\n📥 Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "    \n",
    "    # Show available conditioning options\n",
    "    if hasattr(model, 'prefix_conditioner') and hasattr(model.prefix_conditioner, 'conditioners'):\n",
    "        print(\"\\n🎛️ Available conditioning options:\")\n",
    "        for c in model.prefix_conditioner.conditioners:\n",
    "            print(f\"  - {c.name}\")\n",
    "    \n",
    "    # Show supported languages\n",
    "    print(f\"\\n🌍 Supported languages: {supported_language_codes}\")\n",
    "    \n",
    "    # Show model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\n📊 Model info:\")\n",
    "    print(f\"  - Total parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Dtype: {next(model.parameters()).dtype}\")\n",
    "            \n",
    "    print(\"\\n🎉 Setup complete! You can now use the model in the cells below.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    print(\"\\n🔧 Troubleshooting tips:\")\n",
    "    print(\"1. Make sure you have a stable internet connection\")\n",
    "    print(\"2. Check if you have enough GPU/RAM memory\")\n",
    "    print(\"3. Try restarting the runtime and running from the beginning\")\n",
    "    print(\"4. Ensure you're using a GPU runtime for best performance\")\n",
    "    \n",
    "    # Show memory usage for debugging\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"\\n💾 GPU Memory Usage:\")\n",
    "        print(f\"  - Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "        print(f\"  - Reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b30930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Run text-to-speech example\n",
    "\n",
    "# Import necessary modules for conditional generation\n",
    "from google.colab import files\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "#@markdown ### Text and language settings\n",
    "text = \"Hello, this is Zonos text-to-speech model. How can I help you today?\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "\n",
    "#@markdown ### Optional: Upload your own audio for speaker cloning\n",
    "use_speaker_cloning = False #@param {type:\"boolean\"}\n",
    "\n",
    "speaker_embedding = None\n",
    "if use_speaker_cloning:\n",
    "    print(\"Upload a short audio file (5-30 seconds) of the speaker you want to clone:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        speaker_file = list(uploaded.keys())[0]\n",
    "        print(f\"Processing {speaker_file}...\")\n",
    "        try:\n",
    "            wav, sr = torchaudio.load(speaker_file)\n",
    "            # Convert to mono if stereo\n",
    "            if wav.shape[0] > 1:\n",
    "                wav = wav.mean(0, keepdim=True)\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "            print(f\"✓ Speaker embedding created from {speaker_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing speaker audio: {e}\")\n",
    "            use_speaker_cloning = False\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create conditioning dictionary\n",
    "print(\"Creating conditioning...\")\n",
    "try:\n",
    "    cond_dict = make_cond_dict(\n",
    "        text=text,\n",
    "        language=language,\n",
    "        speaker=speaker_embedding,\n",
    "        device=device,\n",
    "        # Use emotion as unconditional for more natural speech\n",
    "        unconditional_keys=[\"emotion\"] if not use_speaker_cloning else [\"emotion\"]\n",
    "    )\n",
    "\n",
    "    # Prepare conditioning\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "    # Generate audio\n",
    "    print(\"🎵 Generating audio...\")\n",
    "    print(\"This may take 30-60 seconds depending on text length...\")\n",
    "    \n",
    "    codes = model.generate(\n",
    "        prefix_conditioning=conditioning,\n",
    "        max_new_tokens=min(86 * 30, len(text) * 20),  # Adaptive based on text length\n",
    "        cfg_scale=2.0,\n",
    "        batch_size=1,\n",
    "        progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Decode the audio\n",
    "    print(\"🔊 Decoding audio...\")\n",
    "    wav_out = model.autoencoder.decode(codes).cpu().detach()\n",
    "    sr_out = model.autoencoder.sampling_rate\n",
    "    \n",
    "    if wav_out.dim() == 2 and wav_out.size(0) > 1:\n",
    "        wav_out = wav_out[0:1, :]\n",
    "\n",
    "    # Play the audio\n",
    "    wav_numpy = wav_out.squeeze().numpy()\n",
    "    print(f\"✓ Audio generated successfully!\")\n",
    "    print(f\"Sample rate: {sr_out} Hz, Duration: {len(wav_numpy)/sr_out:.2f} seconds\")\n",
    "    \n",
    "    # Display audio player\n",
    "    ipd.display(ipd.Audio(wav_numpy, rate=sr_out))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during audio generation: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"- Try shorter text (under 100 characters)\")\n",
    "    print(\"- Check GPU memory usage\")\n",
    "    print(\"- Restart runtime if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.1 Advanced Text-to-Speech Options\n",
    "\n",
    "#@markdown ### Adjust model parameters for generation\n",
    "\n",
    "#@markdown #### Text and language\n",
    "text = \"I can speak with different emotions and characteristics. This is an example of advanced text-to-speech synthesis.\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "\n",
    "#@markdown #### Emotion controls (0-1 scale)\n",
    "happiness = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "sadness = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "anger = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "fear = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "surprise = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "disgust = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "other = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "neutral = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "\n",
    "#@markdown #### Voice characteristics  \n",
    "speaking_rate = 15.0 #@param {type:\"slider\", min:5, max:30, step:0.5}\n",
    "pitch_std = 45.0 #@param {type:\"slider\", min:0, max:300, step:5}\n",
    "fmax = 24000 #@param {type:\"slider\", min:8000, max:24000, step:1000}\n",
    "vq_score = 0.78 #@param {type:\"slider\", min:0.5, max:0.8, step:0.01}\n",
    "dnsmos_ovrl = 4.0 #@param {type:\"slider\", min:1, max:5, step:0.1}\n",
    "\n",
    "#@markdown #### Generation settings\n",
    "cfg_scale = 2.0 #@param {type:\"slider\", min:1, max:5, step:0.1}\n",
    "randomize_seed = True #@param {type:\"boolean\"}\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "max_length_multiplier = 20 #@param {type:\"slider\", min:10, max:50, step:5}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "if not randomize_seed:\n",
    "    torch.manual_seed(seed)\n",
    "    used_seed = seed\n",
    "else:\n",
    "    used_seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "    torch.manual_seed(used_seed)\n",
    "\n",
    "print(f\"Using seed: {used_seed}\")\n",
    "\n",
    "# Validate emotion values sum (should be close to 1.0 for best results)\n",
    "emotion_sum = happiness + sadness + anger + fear + surprise + disgust + other + neutral\n",
    "if emotion_sum > 1.2 or emotion_sum < 0.8:\n",
    "    print(f\"⚠️ Warning: Emotion values sum to {emotion_sum:.2f}, consider adjusting for better results\")\n",
    "\n",
    "try:\n",
    "    # Create emotion tensor\n",
    "    emotion_tensor = torch.tensor([\n",
    "        float(happiness),  # Happiness\n",
    "        float(sadness),    # Sadness  \n",
    "        float(disgust),    # Disgust\n",
    "        float(fear),       # Fear\n",
    "        float(surprise),   # Surprise\n",
    "        float(anger),      # Anger\n",
    "        float(other),      # Other\n",
    "        float(neutral)     # Neutral\n",
    "    ], device=device)\n",
    "\n",
    "    # Create VQ score tensor (8 values for 8 codebooks)\n",
    "    vq_tensor = torch.tensor([float(vq_score)] * 8, device=device).unsqueeze(0)\n",
    "\n",
    "    # Create conditioning dictionary with more parameters\n",
    "    print(\"Creating advanced conditioning...\")\n",
    "    cond_dict = make_cond_dict(\n",
    "        text=text,\n",
    "        language=language,\n",
    "        speaker=speaker_embedding if 'speaker_embedding' in globals() else None,\n",
    "        emotion=emotion_tensor,\n",
    "        speaking_rate=speaking_rate,\n",
    "        pitch_std=pitch_std,\n",
    "        fmax=fmax,\n",
    "        vqscore_8=vq_tensor,\n",
    "        dnsmos_ovrl=dnsmos_ovrl,\n",
    "        device=device,\n",
    "        unconditional_keys=[\"emotion\"] if 'speaker_embedding' not in globals() or speaker_embedding is None else []\n",
    "    )\n",
    "\n",
    "    # Prepare conditioning\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "    # Calculate appropriate max_new_tokens based on text length\n",
    "    estimated_tokens = min(86 * 30, len(text) * max_length_multiplier)\n",
    "    \n",
    "    # Generate audio\n",
    "    print(f\"🎵 Generating audio with advanced settings...\")\n",
    "    print(f\"Text length: {len(text)} chars, Estimated tokens: {estimated_tokens}\")\n",
    "    \n",
    "    codes = model.generate(\n",
    "        prefix_conditioning=conditioning,\n",
    "        max_new_tokens=estimated_tokens,\n",
    "        cfg_scale=cfg_scale,\n",
    "        batch_size=1,\n",
    "        progress_bar=True,\n",
    "        sampling_params=dict(min_p=0.1, top_k=0, top_p=0.0)  # Use min_p sampling\n",
    "    )\n",
    "\n",
    "    # Decode the audio\n",
    "    print(\"🔊 Decoding audio...\")\n",
    "    wav_out = model.autoencoder.decode(codes).cpu().detach()\n",
    "    sr_out = model.autoencoder.sampling_rate\n",
    "    if wav_out.dim() == 2 and wav_out.size(0) > 1:\n",
    "        wav_out = wav_out[0:1, :]\n",
    "\n",
    "    # Play the audio\n",
    "    wav_numpy = wav_out.squeeze().numpy()\n",
    "    duration = len(wav_numpy) / sr_out\n",
    "    \n",
    "    print(f\"✓ Advanced audio generated successfully!\")\n",
    "    print(f\"Sample rate: {sr_out} Hz, Duration: {duration:.2f} seconds\")\n",
    "    print(f\"Settings used: CFG={cfg_scale}, Emotions=[H:{happiness}, S:{sadness}, A:{anger}, N:{neutral}]\")\n",
    "    ipd.display(ipd.Audio(wav_numpy, rate=sr_out))\n",
    "    \n",
    "    # Store for potential download\n",
    "    globals()['last_generated_audio'] = (wav_numpy, sr_out, used_seed)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during advanced audio generation: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"- Try simpler emotion settings (closer to default values)\")\n",
    "    print(\"- Reduce text length\")\n",
    "    print(\"- Lower CFG scale (try 1.5-2.0)\")\n",
    "    print(\"- Check GPU memory usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af95e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.2 Save Generated Audio\n",
    "\n",
    "#@markdown ### Save and download the generated audio\n",
    "import os\n",
    "import scipy.io.wavfile\n",
    "from datetime import datetime\n",
    "\n",
    "#@markdown Choose what to save\n",
    "save_last_generated = True #@param {type:\"boolean\"}\n",
    "filename_prefix = \"zonos_audio\" #@param {type:\"string\"}\n",
    "include_timestamp = True #@param {type:\"boolean\"}\n",
    "include_settings = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Check if we have generated audio from previous cells\n",
    "try:\n",
    "    if 'last_generated_audio' in globals():\n",
    "        wav_numpy, sr_out, used_seed = last_generated_audio\n",
    "        \n",
    "        # Create filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") if include_timestamp else \"\"\n",
    "        settings_suffix = f\"_seed{used_seed}\" if include_settings else \"\"\n",
    "        \n",
    "        if timestamp and settings_suffix:\n",
    "            filename = f\"{filename_prefix}_{timestamp}{settings_suffix}.wav\"\n",
    "        elif timestamp:\n",
    "            filename = f\"{filename_prefix}_{timestamp}.wav\"\n",
    "        elif settings_suffix:\n",
    "            filename = f\"{filename_prefix}{settings_suffix}.wav\"\n",
    "        else:\n",
    "            filename = f\"{filename_prefix}.wav\"\n",
    "        \n",
    "        # Save the audio file\n",
    "        print(f\"💾 Saving audio as: {filename}\")\n",
    "        scipy.io.wavfile.write(filename, sr_out, wav_numpy)\n",
    "        \n",
    "        # Show file info\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)  # MB\n",
    "        duration = len(wav_numpy) / sr_out\n",
    "        print(f\"✓ Audio saved successfully!\")\n",
    "        print(f\"  File: {filename}\")\n",
    "        print(f\"  Size: {file_size:.2f} MB\")\n",
    "        print(f\"  Duration: {duration:.2f} seconds\")\n",
    "        print(f\"  Sample rate: {sr_out} Hz\")\n",
    "        \n",
    "        # Provide download link\n",
    "        print(\"\\n📥 Starting download...\")\n",
    "        from google.colab import files\n",
    "        files.download(filename)\n",
    "        \n",
    "        print(\"🎉 Audio file ready for download!\")\n",
    "        \n",
    "    elif 'wav_numpy' in globals() and 'sr_out' in globals():\n",
    "        # Fallback to basic variables if available\n",
    "        filename = f\"{filename_prefix}_basic.wav\"\n",
    "        scipy.io.wavfile.write(filename, sr_out, wav_numpy)\n",
    "        print(f\"✓ Audio saved as {filename}\")\n",
    "        files.download(filename)\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No audio has been generated yet.\")\n",
    "        print(\"Run one of the audio generation cells above first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving audio: {e}\")\n",
    "    print(\"Make sure audio generation completed successfully in previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd2978",
   "metadata": {},
   "source": [
    "---\n",
    "**Note:**\n",
    "- Adjust the import paths and model usage according to your codebase.\n",
    "- If you encounter issues with dependencies, check the `pyproject.toml` or manually install missing packages.\n",
    "\n",
    "## Additional Notes and Troubleshooting\n",
    "\n",
    "### ✅ What This Notebook Does\n",
    "- Automatically installs all required dependencies including system packages\n",
    "- Downloads the Zonos transformer model from HuggingFace (2-3 GB)\n",
    "- Provides both simple and advanced text-to-speech generation\n",
    "- Supports speaker cloning with uploaded audio files\n",
    "- Includes a full Gradio web interface for interactive use\n",
    "- Handles error checking and provides helpful feedback\n",
    "\n",
    "### 🎯 Performance Tips\n",
    "- **GPU Runtime**: Use GPU runtime for best performance (Runtime → Change runtime type → Hardware accelerator → GPU)\n",
    "- **Text Length**: Shorter texts (under 200 characters) generate faster\n",
    "- **Memory**: The model uses ~2-4 GB of GPU memory when loaded\n",
    "- **First Run**: Initial model download may take 5-10 minutes depending on connection\n",
    "\n",
    "### 🔧 Common Issues and Solutions\n",
    "\n",
    "**Model Loading Fails:**\n",
    "- Check internet connection stability\n",
    "- Ensure sufficient GPU/RAM memory (restart runtime if needed)\n",
    "- Try the transformer model if hybrid fails\n",
    "\n",
    "**Audio Generation Errors:**\n",
    "- Reduce text length (try under 100 characters)\n",
    "- Lower CFG scale (try 1.5 instead of 2.0)\n",
    "- Simplify emotion settings (use defaults)\n",
    "- Check GPU memory usage\n",
    "\n",
    "**Import Errors:**\n",
    "- Restart runtime and run all cells from the beginning\n",
    "- Check that installation completed without errors\n",
    "- Ensure you're using a GPU runtime\n",
    "\n",
    "**Speaker Cloning Issues:**\n",
    "- Use audio files 5-30 seconds long\n",
    "- Ensure audio is clear and contains speech\n",
    "- Supported formats: WAV, MP3, FLAC\n",
    "- Try mono audio if stereo doesn't work\n",
    "\n",
    "### 📚 Model Information\n",
    "- **Model**: Wamp1re-Ai/Zonos-v0.1-transformer\n",
    "- **Languages**: English, Japanese, Chinese, French, German\n",
    "- **Sample Rate**: 44.1 kHz\n",
    "- **Architecture**: Transformer-based with DAC autoencoder\n",
    "- **Training Data**: 200k+ hours of multilingual speech\n",
    "\n",
    "### 🌐 Using Custom Subdomains\n",
    "When running the Gradio interface, you can optionally use a custom Cloudflare subdomain:\n",
    "1. Set `use_custom_subdomain = True` in the Gradio cell\n",
    "2. Choose a unique subdomain name\n",
    "3. Your interface will be available at `https://your-name.gradio.app`\n",
    "\n",
    "### 💡 Advanced Usage\n",
    "For production use or custom applications, consider:\n",
    "- Using the hybrid model for better quality (requires mamba-ssm)\n",
    "- Implementing custom conditioning parameters\n",
    "- Fine-tuning for specific voices or languages\n",
    "- Using the API programmatically\n",
    "\n",
    "### 🔗 Useful Links\n",
    "- [Zonos GitHub Repository](https://github.com/YourUsername/Zonos)\n",
    "- [Model on HuggingFace](https://huggingface.co/Wamp1re-Ai/Zonos-v0.1-transformer)\n",
    "- [Zyphra Blog Post](https://www.zyphra.com/post/beta-release-of-zonos-v0-1)\n",
    "- [Online Playground](https://playground.zyphra.com/audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494540d0",
   "metadata": {},
   "source": [
    "## Using Cloudflare Subdomain for Gradio Interface\n",
    "\n",
    "When running the Gradio interface, you can use a custom Cloudflare subdomain to make your interface accessible via a consistent URL. This is especially useful for sharing your model with others.\n",
    "\n",
    "**To use a custom subdomain:**\n",
    "\n",
    "1. Set the `GRADIO_SUBDOMAIN` environment variable to your desired subdomain name.\n",
    "2. Set `GRADIO_SHARE=True` to enable sharing.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Run Gradio Interface (Interactive Web UI)\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "#@markdown ### Gradio Interface Settings\n",
    "subdomain_name = \"my-zonos-app\" #@param {type:\"string\"}\n",
    "use_custom_subdomain = False #@param {type:\"boolean\"}\n",
    "share_publicly = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Set environment variables for Gradio\n",
    "if use_custom_subdomain and subdomain_name:\n",
    "    os.environ[\"GRADIO_SUBDOMAIN\"] = subdomain_name\n",
    "    print(f\"🌐 Will attempt to use subdomain: {subdomain_name}.gradio.app\")\n",
    "else:\n",
    "    # Remove subdomain if previously set\n",
    "    os.environ.pop(\"GRADIO_SUBDOMAIN\", None)\n",
    "\n",
    "os.environ[\"GRADIO_SHARE\"] = \"True\" if share_publicly else \"False\"\n",
    "\n",
    "print(\"🚀 Starting Gradio interface...\")\n",
    "print(\"This may take a moment to initialize...\")\n",
    "\n",
    "# Check if gradio_interface.py exists\n",
    "if not os.path.exists(\"gradio_interface.py\"):\n",
    "    print(\"❌ gradio_interface.py not found!\")\n",
    "    print(\"Make sure you're in the correct directory and the file exists.\")\n",
    "else:\n",
    "    try:\n",
    "        # Import and run the interface\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        # Run the gradio interface in a separate process\n",
    "        print(\"📱 Launching Gradio interface...\")\n",
    "        print(\"Click on the public URL below to access the web interface\")\n",
    "        print(\"⚠️ Note: The interface will run until you stop this cell\\n\")\n",
    "        \n",
    "        # Run the gradio interface\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"gradio_interface.py\"\n",
    "        ], capture_output=False, text=True)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Gradio interface stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error running Gradio interface: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"- Make sure all dependencies are installed correctly\")\n",
    "        print(\"- Check that the model loaded successfully in previous cells\")\n",
    "        print(\"- Try restarting the runtime if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🧪 Quick Test - Verify Everything Works\n",
    "#@markdown Run this cell to verify that Zonos is properly installed and working\n",
    "\n",
    "print(\"Running comprehensive test of Zonos installation...\")\n",
    "print(\"This will check dependencies and try to load the model.\")\n",
    "print()\n",
    "\n",
    "exec(open('colab_quick_test.py').read())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
