{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🔧 Quick NumPy Check (Optional)\n",
    "# Run this cell first if you want to check for NumPy compatibility issues\n",
    "# This is optional - you can skip to Cell 1 if you prefer\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major = int(numpy_version.split('.')[0])\n",
    "    \n",
    "    print(f\"Current NumPy version: {numpy_version}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"⚠️ WARNING: NumPy 2.x detected!\")\n",
    "        print(\"This may cause compatibility issues with transformers.\")\n",
    "        print(\"If you get errors in Cell 3, restart runtime and try again.\")\n",
    "    else:\n",
    "        print(\"✅ NumPy version looks compatible\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"NumPy not installed yet - this is normal\")\n",
    "    \n",
    "print(\"\\n🚀 Ready to proceed! Continue with Cell 1 below.\")\n",
    "print(\"(Remember: if you get errors, just restart runtime and try again)\")\n",
    "\n",
    "# Also check if we're in Colab\n",
    "if 'google.colab' in str(type(get_ipython())):\n",
    "    print(\"\\n✅ Running in Google Colab\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Not running in Google Colab - some features may not work\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54137773",
   "metadata": {},
   "source": [
    "# Zonos Model: Google Colab Notebook\n",
    "\n",
    "This notebook will help you set up and run the Zonos model in Google Colab. The model will be automatically downloaded from [Hugging Face](https://huggingface.co/Wamp1re-Ai/Zonos-v0.1-transformer).\n",
    "\n",
    "## Steps:\n",
    "1. Clone or upload the Zonos repository and download the model from HuggingFace.\n",
    "2. Install dependencies.\n",
    "3. Run the model with example code.\n",
    "4. (Optional) Upload your own audio files for inference.\n",
    "5. Use Cloudflare subdomain for sharing your Gradio interface.\n",
    "\n",
    "## ⚠️ Important: NumPy Compatibility Issue\n",
    "\n",
    "**If you get a NumPy/Transformers error in Cell 3**, this is a known compatibility issue:\n",
    "- **Problem**: Google Colab sometimes loads NumPy 2.x which is incompatible with transformers\n",
    "- **Symptom**: Error mentioning `_center` or NumPy in transformers import\n",
    "- **Solution**: **Restart runtime** (Runtime → Restart runtime) and re-run cells 1-3\n",
    "\n",
    "This is **normal** and **easy to fix** - just restart the runtime when prompted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade15647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Clone the repository and download the model\n",
    "import os\n",
    "\n",
    "# Clone the Zonos repository (use the correct URL)\n",
    "if not os.path.exists('Zonos'):\n",
    "    !git clone https://github.com/Wamp1re-Ai/Zonos.git  # Change this to your actual GitHub username\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"Repository already exists!\")\n",
    "\n",
    "%cd Zonos\n",
    "\n",
    "# Install system dependencies first (eSpeak is required for phonemization)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y espeak-ng git-lfs\n",
    "\n",
    "# Initialize git LFS\n",
    "!git lfs install\n",
    "\n",
    "print(\"System dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b350a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Install dependencies\n",
    "# Install required packages efficiently and avoid dependency conflicts\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_package(package, use_uv=False):\n",
    "    \"\"\"Install a package with better error handling\"\"\"\n",
    "    try:\n",
    "        if use_uv:\n",
    "            subprocess.check_call([\"uv\", \"pip\", \"install\", package, \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "        else:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Install UV for faster package management\n",
    "print(\"Installing UV for faster package management...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"uv\", \"--quiet\"])\n",
    "    print(\"✓ UV installed successfully!\")\n",
    "    use_uv = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Failed to install UV, falling back to pip\")\n",
    "    use_uv = False\n",
    "\n",
    "# Don't upgrade pip/setuptools in Colab - it causes conflicts\n",
    "print(\"Skipping pip upgrade to avoid dependency conflicts in Colab...\")\n",
    "\n",
    "# Check if we're in Colab and use pre-installed torch if available\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Use Colab's pre-installed PyTorch to save time\n",
    "    print(\"Using Colab's pre-installed PyTorch...\")\n",
    "    try:\n",
    "        import torch\n",
    "        import torchaudio\n",
    "        print(f\"✓ PyTorch {torch.__version__} already available\")\n",
    "        print(f\"✓ TorchAudio {torchaudio.__version__} already available\")\n",
    "        torch_installed = True\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not found, will install...\")\n",
    "        torch_installed = False\n",
    "else:\n",
    "    torch_installed = False\n",
    "\n",
    "# Check current numpy version BEFORE any installations\n",
    "print(\"\\n🔍 Checking current NumPy version...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    current_numpy = np.__version__\n",
    "    numpy_major, numpy_minor = map(int, current_numpy.split('.')[:2])\n",
    "    print(f\"Current NumPy: {current_numpy}\")\n",
    "    \n",
    "    if numpy_major >= 2:\n",
    "        print(\"⚠️ NumPy 2.x detected - this will cause transformers compatibility issues!\")\n",
    "        numpy_needs_fix = True\n",
    "    else:\n",
    "        print(\"✓ NumPy version is compatible\")\n",
    "        numpy_needs_fix = False\n",
    "except ImportError:\n",
    "    print(\"NumPy not installed yet\")\n",
    "    numpy_needs_fix = False\n",
    "\n",
    "# Force install compatible numpy version if needed\n",
    "if numpy_needs_fix or not IN_COLAB:\n",
    "    print(\"\\n🔧 Installing compatible NumPy version...\")\n",
    "    if use_uv:\n",
    "        subprocess.check_call([\"uv\", \"pip\", \"install\", \"numpy==1.26.4\", \"--force-reinstall\", \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "    else:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--force-reinstall\", \"--quiet\"])\n",
    "    print(\"✓ NumPy 1.26.4 installed\")\n",
    "    \n",
    "    if numpy_needs_fix:\n",
    "        print(\"\\n⚠️ IMPORTANT: NumPy was downgraded from 2.x to 1.26.4\")\n",
    "        print(\"This may not take effect until you restart the runtime.\")\n",
    "        print(\"If you get import errors in the next cell, please:\")\n",
    "        print(\"  1. Runtime → Restart runtime\")\n",
    "        print(\"  2. Re-run cells 1, 2, and 3\")\n",
    "\n",
    "# Install core dependencies with compatible versions\n",
    "packages = [\n",
    "    \"transformers>=4.45.0,<4.50.0\",  # Pin to avoid compatibility issues\n",
    "    \"gradio>=4.0.0,<5.0.0\", \n",
    "    \"huggingface-hub>=0.20.0\",\n",
    "    \"soundfile>=0.12.1\",\n",
    "    \"phonemizer>=3.2.0\",\n",
    "    \"inflect>=7.0.0\",\n",
    "    \"scipy\"\n",
    "]\n",
    "\n",
    "# Add torch packages if not already installed\n",
    "if not torch_installed:\n",
    "    packages = [\"torch>=2.0.0\", \"torchaudio>=2.0.0\"] + packages\n",
    "\n",
    "print(f\"\\nInstalling {len(packages)} core dependencies...\")\n",
    "failed_packages = []\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    if not install_package(package, use_uv):\n",
    "        failed_packages.append(package)\n",
    "\n",
    "if failed_packages:\n",
    "    print(f\"\\n⚠️ Failed to install: {failed_packages}\")\n",
    "    print(\"Continuing anyway - some packages might work...\")\n",
    "\n",
    "# Install optional dependencies with better error handling\n",
    "print(\"\\nInstalling optional dependencies (these may fail - it's normal)...\")\n",
    "optional_packages = [\n",
    "    (\"flash-attn>=2.0.0\", \"Flash Attention for faster inference\"),\n",
    "    (\"mamba-ssm>=1.0.0\", \"Mamba State Space Models\"), \n",
    "    (\"causal-conv1d>=1.0.0\", \"Causal Conv1D for Mamba\")\n",
    "]\n",
    "\n",
    "optional_success = 0\n",
    "for package, description in optional_packages:\n",
    "    print(f\"Attempting to install {package} ({description})...\")\n",
    "    if install_package(package, use_uv):\n",
    "        print(f\"  ✓ {package} installed successfully\")\n",
    "        optional_success += 1\n",
    "    else:\n",
    "        print(f\"  ✗ {package} installation failed (optional - continuing)\")\n",
    "\n",
    "# Install the project itself\n",
    "print(\"\\nInstalling Zonos package...\")\n",
    "try:\n",
    "    if use_uv:\n",
    "        subprocess.check_call([\"uv\", \"pip\", \"install\", \"-e\", \".\", \"--quiet\"], env={**os.environ, \"UV_SYSTEM_PYTHON\": \"1\"})\n",
    "    else:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\", \"--quiet\"])\n",
    "    print(\"✓ Zonos package installed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"❌ Failed to install Zonos package: {e}\")\n",
    "    print(\"Trying alternative installation...\")\n",
    "    # Alternative: add current directory to Python path\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.insert(0, current_dir)\n",
    "    print(f\"Added {current_dir} to Python path\")\n",
    "\n",
    "# Verify critical imports work\n",
    "print(\"\\n🔍 Verifying critical imports...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"✓ NumPy {np.__version__} working\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ NumPy import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"✓ Transformers {transformers.__version__} working\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Transformers import failed: {e}\")\n",
    "    if \"_center\" in str(e) or \"numpy\" in str(e).lower():\n",
    "        print(\"\\n🔧 This looks like the NumPy 2.x compatibility issue!\")\n",
    "        print(\"Please restart the runtime and try again.\")\n",
    "\n",
    "print(\"\\n✅ Dependency installation complete!\")\n",
    "print(\"\\n📝 Installation Summary:\")\n",
    "print(f\"  - Package manager: {'UV' if use_uv else 'pip'}\")\n",
    "print(f\"  - Core packages: {len(packages) - len(failed_packages)}/{len(packages)} successful\")\n",
    "print(f\"  - Optional packages: {optional_success}/{len(optional_packages)} successful\")\n",
    "if failed_packages:\n",
    "    print(f\"  - Failed packages: {failed_packages}\")\n",
    "print(f\"  - Zonos package: Installed\")\n",
    "print(f\"  - NumPy compatibility: {'Fixed' if numpy_needs_fix else 'OK'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Load and run the Zonos model\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Make sure we can import zonos modules\n",
    "if '/content/Zonos' not in sys.path:\n",
    "    sys.path.insert(0, '/content/Zonos')\n",
    "\n",
    "# CRITICAL: Check numpy compatibility first - this must be done before importing transformers\n",
    "print(\"🔧 Checking NumPy compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    numpy_major, numpy_minor = map(int, numpy_version.split('.')[:2])\n",
    "    print(f\"Current NumPy: {numpy_version}\")\n",
    "    \n",
    "    # Check if numpy version is compatible - NumPy 2.x causes issues\n",
    "    if numpy_major >= 2:\n",
    "        print(\"\\n⚠️ NumPy 2.x detected - attempting automatic fix...\")\n",
    "        print(\"Installing compatible NumPy version...\")\n",
    "        \n",
    "        try:\n",
    "            # Force reinstall compatible numpy\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.26.4\", \"--force-reinstall\", \"--quiet\"])\n",
    "            print(\"✓ NumPy 1.26.4 installed successfully\")\n",
    "            \n",
    "            # Clear the module cache and reimport\n",
    "            if 'numpy' in sys.modules:\n",
    "                del sys.modules['numpy']\n",
    "            if 'np' in globals():\n",
    "                del globals()['np']\n",
    "                \n",
    "            # Re-import numpy\n",
    "            import numpy as np\n",
    "            numpy_version = np.__version__\n",
    "            numpy_major = int(numpy_version.split('.')[0])\n",
    "            print(f\"Updated NumPy: {numpy_version}\")\n",
    "            \n",
    "            if numpy_major >= 2:\n",
    "                print(\"\\n❌ CRITICAL ERROR: NumPy 2.x still detected after reinstall!\")\n",
    "                print(\"NumPy 2.x is incompatible with transformers library.\")\n",
    "                print(\"\\n🔄 MANUAL SOLUTION REQUIRED:\")\n",
    "                print(\"1. Click 'Runtime' in the top menu\")\n",
    "                print(\"2. Click 'Restart runtime'\")\n",
    "                print(\"3. Run Cell 1 (Clone repository)\")\n",
    "                print(\"4. Run Cell 2 (Install dependencies)\")\n",
    "                print(\"5. Run Cell 3 (this cell) again\")\n",
    "                print(\"\\n💡 Why this happens:\")\n",
    "                print(\"- Colab sometimes has NumPy 2.x pre-loaded in memory\")\n",
    "                print(\"- Restarting clears memory and uses our installed NumPy 1.26.4\")\n",
    "                print(\"- This is a known compatibility issue with transformers\")\n",
    "                raise RuntimeError(\"NumPy 2.x compatibility issue - runtime restart required\")\n",
    "            else:\n",
    "                print(f\"✓ NumPy {numpy_version} is now compatible!\")\n",
    "                \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ Failed to automatically fix NumPy: {e}\")\n",
    "            print(\"\\n🔄 MANUAL SOLUTION REQUIRED:\")\n",
    "            print(\"1. Click 'Runtime' in the top menu\")\n",
    "            print(\"2. Click 'Restart runtime'\")\n",
    "            print(\"3. Run Cell 1 (Clone repository)\")\n",
    "            print(\"4. Run Cell 2 (Install dependencies)\")\n",
    "            print(\"5. Run Cell 3 (this cell) again\")\n",
    "            raise RuntimeError(\"NumPy 2.x compatibility issue - runtime restart required\")\n",
    "    else:\n",
    "        print(f\"✓ NumPy {numpy_version} is compatible\")\n",
    "except ImportError:\n",
    "    print(\"❌ NumPy not found! Please run Cell 2 first.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    if \"restart\" in str(e) or \"compatibility\" in str(e):\n",
    "        raise\n",
    "    print(f\"❌ NumPy error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import PyTorch\n",
    "print(\"\\n📦 Loading PyTorch...\")\n",
    "try:\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    print(f\"✓ PyTorch {torch.__version__} loaded successfully\")\n",
    "    print(f\"✓ TorchAudio {torchaudio.__version__} loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PyTorch import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Import transformers with enhanced error handling\n",
    "print(\"\\n🤗 Loading Transformers...\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"✓ Transformers {transformers.__version__} loaded successfully\")\n",
    "except ImportError as e:\n",
    "    error_msg = str(e)\n",
    "    if \"_center\" in error_msg or \"numpy\" in error_msg.lower():\n",
    "        print(f\"❌ NumPy/Transformers compatibility error: {e}\")\n",
    "        print(\"\\n🔧 DETECTED: NumPy 2.x compatibility issue\")\n",
    "        print(\"\\n📋 REQUIRED SOLUTION:\")\n",
    "        print(\"┌─────────────────────────────────────┐\")\n",
    "        print(\"│ 1. Runtime → Restart runtime        │\")\n",
    "        print(\"│ 2. Run Cell 1 (Clone)              │\")\n",
    "        print(\"│ 3. Run Cell 2 (Dependencies)       │\")\n",
    "        print(\"│ 4. Run Cell 3 (Model) again        │\")\n",
    "        print(\"└─────────────────────────────────────┘\")\n",
    "        print(\"\\n💡 This happens because:\")\n",
    "        print(\"- NumPy 2.x was loaded before we could replace it\")\n",
    "        print(\"- Restarting runtime will use our NumPy 1.26.4\")\n",
    "        print(\"- This is the only way to fix this compatibility issue\")\n",
    "        raise RuntimeError(\"NumPy/Transformers compatibility issue - restart required\")\n",
    "    else:\n",
    "        print(f\"❌ Transformers import error: {e}\")\n",
    "        print(\"\\nTry:\")\n",
    "        print(\"1. Restart runtime\")\n",
    "        print(\"2. Re-run all cells from the beginning\")\n",
    "        raise\n",
    "\n",
    "# Now try to import Zonos modules\n",
    "print(\"\\n🎵 Loading Zonos modules...\")\n",
    "try:\n",
    "    from zonos.model import Zonos\n",
    "    from zonos.conditioning import make_cond_dict, supported_language_codes\n",
    "    from zonos.utils import DEFAULT_DEVICE\n",
    "    print(\"✓ Zonos modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Zonos import error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"- Make sure Cell 2 (dependency installation) completed successfully\")\n",
    "    print(\"- Check that you're in the Zonos directory\")\n",
    "    print(\"- Try restarting runtime and running from Cell 1\")\n",
    "    \n",
    "    # Try importing individual modules to diagnose the issue\n",
    "    print(\"\\n🔍 Diagnostic imports:\")\n",
    "    try:\n",
    "        from zonos import model\n",
    "        print(\"✓ zonos.model imported\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ zonos.model failed: {e2}\")\n",
    "    \n",
    "    try:\n",
    "        from zonos import conditioning\n",
    "        print(\"✓ zonos.conditioning imported\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ zonos.conditioning failed: {e2}\")\n",
    "    \n",
    "    raise\n",
    "\n",
    "# Set device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n🖥️ Using device: {device}\")\n",
    "\n",
    "# Check GPU memory if using CUDA\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✓ GPU cache cleared\")\n",
    "\n",
    "# Load the model from HuggingFace\n",
    "model_name = \"Zyphra/Zonos-v0.1-transformer\"\n",
    "print(f\"\\n📥 Loading model: {model_name}\")\n",
    "print(\"This may take 2-5 minutes for the first time...\")\n",
    "\n",
    "try:\n",
    "    model = Zonos.from_pretrained(model_name, device=device)\n",
    "    model.requires_grad_(False).eval()\n",
    "    print(\"✅ Model loaded successfully!\")\n",
    "    \n",
    "    # Show available conditioning options\n",
    "    if hasattr(model, 'prefix_conditioner') and hasattr(model.prefix_conditioner, 'conditioners'):\n",
    "        print(\"\\n🎛️ Available conditioning options:\")\n",
    "        for c in model.prefix_conditioner.conditioners:\n",
    "            print(f\"  - {c.name}\")\n",
    "    \n",
    "    # Show supported languages\n",
    "    print(f\"\\n🌍 Supported languages: {supported_language_codes}\")\n",
    "    \n",
    "    # Show model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\n📊 Model info:\")\n",
    "    print(f\"  - Total parameters: {total_params:,}\")\n",
    "    print(f\"  - Device: {next(model.parameters()).device}\")\n",
    "    print(f\"  - Dtype: {next(model.parameters()).dtype}\")\n",
    "            \n",
    "    print(\"\\n🎉 Setup complete! You can now use the model in the cells below.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    print(\"\\n🔧 Troubleshooting tips:\")\n",
    "    print(\"1. Make sure you have a stable internet connection\")\n",
    "    print(\"2. Check if you have enough GPU/RAM memory\")\n",
    "    print(\"3. Try restarting the runtime and running from the beginning\")\n",
    "    print(\"4. Ensure you're using a GPU runtime for best performance\")\n",
    "    \n",
    "    # Show memory usage for debugging\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"\\n💾 GPU Memory Usage:\")\n",
    "        print(f\"  - Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "        print(f\"  - Reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b30930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Generate Speech with Text-to-Speech (Uses Cloned Voice if Available)\n",
    "\n",
    "# Import necessary modules for conditional generation\n",
    "from google.colab import files\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "#@markdown ### Text and language settings\n",
    "text = \"Hello, this is Zonos text-to-speech model. How can I help you today?\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "\n",
    "#@markdown ### Voice Settings\n",
    "#@markdown The system will automatically use your cloned voice if you uploaded audio in the previous cell\n",
    "use_cloned_voice = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Check if we have a cloned voice available\n",
    "speaker_embedding = None\n",
    "voice_info = \"\"\n",
    "\n",
    "if use_cloned_voice and 'custom_speaker_embedding' in globals():\n",
    "    speaker_embedding = custom_speaker_embedding\n",
    "    if 'speaker_audio_info' in globals():\n",
    "        info = speaker_audio_info\n",
    "        voice_info = f\"🎭 Using CLONED VOICE from '{info['filename']}' ({info['duration']:.1f}s)\"\n",
    "    else:\n",
    "        voice_info = \"🎭 Using CLONED VOICE from uploaded audio\"\n",
    "    print(voice_info)\n",
    "else:\n",
    "    if 'custom_speaker_embedding' in globals():\n",
    "        print(\"🔘 Cloned voice available but disabled. Enable 'use_cloned_voice' to use it.\")\n",
    "    else:\n",
    "        print(\"🎤 Using DEFAULT VOICE (no cloned voice uploaded)\")\n",
    "        print(\"💡 Tip: Run the 'Voice Cloning' cell above to upload your own voice!\")\n",
    "    voice_info = \"🎤 Using default voice\"\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create conditioning dictionary\n",
    "print(\"\\n🔧 Creating conditioning...\")\n",
    "try:\n",
    "    cond_dict = make_cond_dict(\n",
    "        text=text,\n",
    "        language=language,\n",
    "        speaker=speaker_embedding,\n",
    "        device=device,\n",
    "        # Use emotion as unconditional for more natural speech\n",
    "        unconditional_keys=[\"emotion\"] if speaker_embedding is None else [\"emotion\"]\n",
    "    )\n",
    "\n",
    "    # Prepare conditioning\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "    # Generate audio\n",
    "    print(f\"🎵 Generating audio...\")\n",
    "    print(f\"📝 Text: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "    print(f\"🌍 Language: {language}\")\n",
    "    print(f\"🎭 Voice: {voice_info}\")\n",
    "    print(\"⏳ This may take 30-60 seconds depending on text length...\")\n",
    "    \n",
    "    codes = model.generate(\n",
    "        prefix_conditioning=conditioning,\n",
    "        max_new_tokens=min(86 * 30, len(text) * 20),  # Adaptive based on text length\n",
    "        cfg_scale=2.0,\n",
    "        batch_size=1,\n",
    "        progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Decode the audio\n",
    "    print(\"🔊 Decoding audio...\")\n",
    "    wav_out = model.autoencoder.decode(codes).cpu().detach()\n",
    "    sr_out = model.autoencoder.sampling_rate\n",
    "    \n",
    "    if wav_out.dim() == 2 and wav_out.size(0) > 1:\n",
    "        wav_out = wav_out[0:1, :]\n",
    "\n",
    "    # Play the audio\n",
    "    wav_numpy = wav_out.squeeze().numpy()\n",
    "    duration = len(wav_numpy) / sr_out\n",
    "    \n",
    "    print(f\"\\n✅ Audio generated successfully!\")\n",
    "    print(f\"📊 Sample rate: {sr_out} Hz\")\n",
    "    print(f\"⏱️ Duration: {duration:.2f} seconds\")\n",
    "    \n",
    "    if speaker_embedding is not None:\n",
    "        print(f\"🎭 Successfully used cloned voice!\")\n",
    "    \n",
    "    # Display audio player\n",
    "    print(f\"\\n🎧 Click the play button below to listen:\")\n",
    "    ipd.display(ipd.Audio(wav_numpy, rate=sr_out))\n",
    "    \n",
    "    # Store for potential download\n",
    "    globals()['last_generated_audio'] = (wav_numpy, sr_out, 42)  # seed\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during audio generation: {e}\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"   • Try shorter text (under 100 characters)\")\n",
    "    print(\"   • Check GPU memory usage\")\n",
    "    print(\"   • Make sure the model loaded successfully (Cell 3)\")\n",
    "    print(\"   • Restart runtime if needed\")\n",
    "    if speaker_embedding is not None:\n",
    "        print(\"   • If using cloned voice, try disabling it or re-uploading audio\")\n",
    "\n",
    "print(f\"\\n💡 Tips:\")\n",
    "print(f\"   • Try different text and languages\")\n",
    "print(f\"   • Upload different audio files for voice cloning\")\n",
    "print(f\"   • Use the 'Advanced Options' cell below for more control\")\n",
    "print(f\"   • Save your audio using the 'Save Generated Audio' cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b1dae",
   "metadata": {},
   "source": [
    "# 🎭 Voice Cloning (Optional)\n",
    "\n",
    "**Upload your own audio to clone any voice!** \n",
    "\n",
    "This section allows you to upload a short audio sample (5-30 seconds) of any speaker and use their voice for text-to-speech generation. The voice cloning works with any language and speaking style.\n",
    "\n",
    "### Requirements for best results:\n",
    "- **Audio length**: 5-30 seconds (longer is better up to 30 seconds)\n",
    "- **Audio quality**: Clear speech with minimal background noise\n",
    "- **Content**: Natural speech (not singing or whispering)\n",
    "- **Format**: WAV, MP3, or FLAC files\n",
    "- **Language**: Any language supported by the model\n",
    "\n",
    "### How it works:\n",
    "1. Upload your audio file below\n",
    "2. The model will analyze the speaker's voice characteristics\n",
    "3. Use the created voice in the text-to-speech cells below\n",
    "\n",
    "**Privacy Note**: Your uploaded audio is only processed locally in this session and is not stored or shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.1 Advanced Text-to-Speech Options (Uses Cloned Voice if Available)\n",
    "\n",
    "#@markdown ### Adjust model parameters for generation\n",
    "\n",
    "#@markdown #### Text and language\n",
    "text = \"I can speak with different emotions and characteristics. This is an example of advanced text-to-speech synthesis.\" #@param {type:\"string\"}\n",
    "language = \"en-us\" #@param [\"en-us\", \"en-gb\", \"fr-fr\", \"es-es\", \"de-de\", \"it-it\", \"ja-jp\", \"zh-cn\"]\n",
    "\n",
    "#@markdown #### Voice Settings  \n",
    "#@markdown The system will automatically use your cloned voice if available\n",
    "use_cloned_voice = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown #### Emotion controls (0-1 scale)\n",
    "happiness = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "sadness = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "anger = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "fear = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "surprise = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "disgust = 0.05 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "other = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "neutral = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "\n",
    "#@markdown #### Voice characteristics  \n",
    "speaking_rate = 15.0 #@param {type:\"slider\", min:5, max:30, step:0.5}\n",
    "pitch_std = 45.0 #@param {type:\"slider\", min:0, max:300, step:5}\n",
    "fmax = 24000 #@param {type:\"slider\", min:8000, max:24000, step:1000}\n",
    "vq_score = 0.78 #@param {type:\"slider\", min:0.5, max:0.8, step:0.01}\n",
    "dnsmos_ovrl = 4.0 #@param {type:\"slider\", min:1, max:5, step:0.1}\n",
    "\n",
    "#@markdown #### Generation settings\n",
    "cfg_scale = 2.0 #@param {type:\"slider\", min:1, max:5, step:0.1}\n",
    "randomize_seed = True #@param {type:\"boolean\"}\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "max_length_multiplier = 20 #@param {type:\"slider\", min:10, max:50, step:5}\n",
    "\n",
    "# Check for cloned voice\n",
    "speaker_embedding = None\n",
    "voice_info = \"\"\n",
    "\n",
    "if use_cloned_voice and 'custom_speaker_embedding' in globals():\n",
    "    speaker_embedding = custom_speaker_embedding\n",
    "    if 'speaker_audio_info' in globals():\n",
    "        info = speaker_audio_info\n",
    "        voice_info = f\"🎭 CLONED VOICE: {info['filename']} ({info['duration']:.1f}s)\"\n",
    "    else:\n",
    "        voice_info = \"🎭 CLONED VOICE from uploaded audio\"\n",
    "    print(voice_info)\n",
    "else:\n",
    "    if 'custom_speaker_embedding' in globals():\n",
    "        print(\"🔘 Cloned voice available but disabled. Enable 'use_cloned_voice' to use it.\")\n",
    "    else:\n",
    "        print(\"🎤 No cloned voice uploaded - using default voice\")\n",
    "    voice_info = \"🎤 Default voice\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "if not randomize_seed:\n",
    "    torch.manual_seed(seed)\n",
    "    used_seed = seed\n",
    "else:\n",
    "    used_seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "    torch.manual_seed(used_seed)\n",
    "\n",
    "print(f\"\\n🎲 Using seed: {used_seed}\")\n",
    "\n",
    "# Validate emotion values sum (should be close to 1.0 for best results)\n",
    "emotion_sum = happiness + sadness + anger + fear + surprise + disgust + other + neutral\n",
    "if emotion_sum > 1.2 or emotion_sum < 0.8:\n",
    "    print(f\"⚠️ Warning: Emotion values sum to {emotion_sum:.2f}, consider adjusting for better results\")\n",
    "\n",
    "try:\n",
    "    # Create emotion tensor\n",
    "    emotion_tensor = torch.tensor([\n",
    "        float(happiness),  # Happiness\n",
    "        float(sadness),    # Sadness  \n",
    "        float(disgust),    # Disgust\n",
    "        float(fear),       # Fear\n",
    "        float(surprise),   # Surprise\n",
    "        float(anger),      # Anger\n",
    "        float(other),      # Other\n",
    "        float(neutral)     # Neutral\n",
    "    ], device=device)\n",
    "\n",
    "    # Create VQ score tensor (8 values for 8 codebooks)\n",
    "    vq_tensor = torch.tensor([float(vq_score)] * 8, device=device).unsqueeze(0)\n",
    "\n",
    "    # Create conditioning dictionary with more parameters\n",
    "    print(f\"\\n🔧 Creating advanced conditioning...\")\n",
    "    print(f\"📝 Text: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "    print(f\"🌍 Language: {language}\")\n",
    "    print(f\"🎭 Voice: {voice_info}\")\n",
    "    print(f\"🎨 Emotions: Happy={happiness:.1f}, Sad={sadness:.1f}, Angry={anger:.1f}, Neutral={neutral:.1f}\")\n",
    "    \n",
    "    cond_dict = make_cond_dict(\n",
    "        text=text,\n",
    "        language=language,\n",
    "        speaker=speaker_embedding,\n",
    "        emotion=emotion_tensor,\n",
    "        speaking_rate=speaking_rate,\n",
    "        pitch_std=pitch_std,\n",
    "        fmax=fmax,\n",
    "        vqscore_8=vq_tensor,\n",
    "        dnsmos_ovrl=dnsmos_ovrl,\n",
    "        device=device,\n",
    "        unconditional_keys=[\"emotion\"] if speaker_embedding is None else []\n",
    "    )\n",
    "\n",
    "    # Prepare conditioning\n",
    "    conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "    # Calculate appropriate max_new_tokens based on text length\n",
    "    estimated_tokens = min(86 * 30, len(text) * max_length_multiplier)\n",
    "    \n",
    "    # Generate audio\n",
    "    print(f\"\\n🎵 Generating advanced audio...\")\n",
    "    print(f\"📊 Text length: {len(text)} chars\")\n",
    "    print(f\"📊 Estimated tokens: {estimated_tokens}\")\n",
    "    print(f\"📊 CFG scale: {cfg_scale}\")\n",
    "    print(\"⏳ This may take 30-90 seconds...\")\n",
    "    \n",
    "    codes = model.generate(\n",
    "        prefix_conditioning=conditioning,\n",
    "        max_new_tokens=estimated_tokens,\n",
    "        cfg_scale=cfg_scale,\n",
    "        batch_size=1,\n",
    "        progress_bar=True,\n",
    "        sampling_params=dict(min_p=0.1, top_k=0, top_p=0.0)  # Use min_p sampling\n",
    "    )\n",
    "\n",
    "    # Decode the audio\n",
    "    print(\"🔊 Decoding audio...\")\n",
    "    wav_out = model.autoencoder.decode(codes).cpu().detach()\n",
    "    sr_out = model.autoencoder.sampling_rate\n",
    "    if wav_out.dim() == 2 and wav_out.size(0) > 1:\n",
    "        wav_out = wav_out[0:1, :]\n",
    "\n",
    "    # Play the audio\n",
    "    wav_numpy = wav_out.squeeze().numpy()\n",
    "    duration = len(wav_numpy) / sr_out\n",
    "    \n",
    "    print(f\"\\n✅ Advanced audio generated successfully!\")\n",
    "    print(f\"📊 Sample rate: {sr_out} Hz\")\n",
    "    print(f\"⏱️ Duration: {duration:.2f} seconds\")\n",
    "    print(f\"🎭 Voice: {voice_info}\")\n",
    "    print(f\"🎛️ Settings: CFG={cfg_scale}, Emotions=[H:{happiness}, S:{sadness}, A:{anger}, N:{neutral}]\")\n",
    "    \n",
    "    print(f\"\\n🎧 Click the play button below to listen:\")\n",
    "    ipd.display(ipd.Audio(wav_numpy, rate=sr_out))\n",
    "    \n",
    "    # Store for potential download\n",
    "    globals()['last_generated_audio'] = (wav_numpy, sr_out, used_seed)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during advanced audio generation: {e}\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"   • Try simpler emotion settings (closer to default values)\")\n",
    "    print(\"   • Reduce text length\")\n",
    "    print(\"   • Lower CFG scale (try 1.5-2.0)\")\n",
    "    print(\"   • Check GPU memory usage\")\n",
    "    if speaker_embedding is not None:\n",
    "        print(\"   • If using cloned voice, try disabling it temporarily\")\n",
    "\n",
    "print(f\"\\n💡 Advanced Tips:\")\n",
    "print(f\"   • Experiment with different emotion combinations\")\n",
    "print(f\"   • Adjust speaking rate for faster/slower speech\")\n",
    "print(f\"   • Try different CFG scales for varied results\")\n",
    "print(f\"   • Use your cloned voice with different emotions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af95e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4.2 Save Generated Audio\n",
    "\n",
    "#@markdown ### Save and download the generated audio\n",
    "import os\n",
    "import scipy.io.wavfile\n",
    "from datetime import datetime\n",
    "\n",
    "#@markdown Choose what to save\n",
    "save_last_generated = True #@param {type:\"boolean\"}\n",
    "filename_prefix = \"zonos_audio\" #@param {type:\"string\"}\n",
    "include_timestamp = True #@param {type:\"boolean\"}\n",
    "include_settings = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Check if we have generated audio from previous cells\n",
    "try:\n",
    "    if 'last_generated_audio' in globals():\n",
    "        wav_numpy, sr_out, used_seed = last_generated_audio\n",
    "        \n",
    "        # Create filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") if include_timestamp else \"\"\n",
    "        settings_suffix = f\"_seed{used_seed}\" if include_settings else \"\"\n",
    "        \n",
    "        if timestamp and settings_suffix:\n",
    "            filename = f\"{filename_prefix}_{timestamp}{settings_suffix}.wav\"\n",
    "        elif timestamp:\n",
    "            filename = f\"{filename_prefix}_{timestamp}.wav\"\n",
    "        elif settings_suffix:\n",
    "            filename = f\"{filename_prefix}{settings_suffix}.wav\"\n",
    "        else:\n",
    "            filename = f\"{filename_prefix}.wav\"\n",
    "        \n",
    "        # Save the audio file\n",
    "        print(f\"💾 Saving audio as: {filename}\")\n",
    "        scipy.io.wavfile.write(filename, sr_out, wav_numpy)\n",
    "        \n",
    "        # Show file info\n",
    "        file_size = os.path.getsize(filename) / (1024 * 1024)  # MB\n",
    "        duration = len(wav_numpy) / sr_out\n",
    "        print(f\"✓ Audio saved successfully!\")\n",
    "        print(f\"  File: {filename}\")\n",
    "        print(f\"  Size: {file_size:.2f} MB\")\n",
    "        print(f\"  Duration: {duration:.2f} seconds\")\n",
    "        print(f\"  Sample rate: {sr_out} Hz\")\n",
    "        \n",
    "        # Provide download link\n",
    "        print(\"\\n📥 Starting download...\")\n",
    "        from google.colab import files\n",
    "        files.download(filename)\n",
    "        \n",
    "        print(\"🎉 Audio file ready for download!\")\n",
    "        \n",
    "    elif 'wav_numpy' in globals() and 'sr_out' in globals():\n",
    "        # Fallback to basic variables if available\n",
    "        filename = f\"{filename_prefix}_basic.wav\"\n",
    "        scipy.io.wavfile.write(filename, sr_out, wav_numpy)\n",
    "        print(f\"✓ Audio saved as {filename}\")\n",
    "        files.download(filename)\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No audio has been generated yet.\")\n",
    "        print(\"Run one of the audio generation cells above first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving audio: {e}\")\n",
    "    print(\"Make sure audio generation completed successfully in previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd2978",
   "metadata": {},
   "source": [
    "---\n",
    "**Note:**\n",
    "- Adjust the import paths and model usage according to your codebase.\n",
    "- If you encounter issues with dependencies, check the `pyproject.toml` or manually install missing packages.\n",
    "\n",
    "## Additional Notes and Troubleshooting\n",
    "\n",
    "### ✅ What This Notebook Does\n",
    "- Automatically installs all required dependencies including system packages\n",
    "- Downloads the Zonos transformer model from HuggingFace (2-3 GB)\n",
    "- Provides both simple and advanced text-to-speech generation\n",
    "- Supports speaker cloning with uploaded audio files\n",
    "- Includes a full Gradio web interface for interactive use\n",
    "- Handles error checking and provides helpful feedback\n",
    "\n",
    "### 🎯 Performance Tips\n",
    "- **GPU Runtime**: Use GPU runtime for best performance (Runtime → Change runtime type → Hardware accelerator → GPU)\n",
    "- **Text Length**: Shorter texts (under 200 characters) generate faster\n",
    "- **Memory**: The model uses ~2-4 GB of GPU memory when loaded\n",
    "- **First Run**: Initial model download may take 5-10 minutes depending on connection\n",
    "\n",
    "### 🔧 Common Issues and Solutions\n",
    "\n",
    "**Model Loading Fails:**\n",
    "- Check internet connection stability\n",
    "- Ensure sufficient GPU/RAM memory (restart runtime if needed)\n",
    "- Try the transformer model if hybrid fails\n",
    "\n",
    "**Audio Generation Errors:**\n",
    "- Reduce text length (try under 100 characters)\n",
    "- Lower CFG scale (try 1.5 instead of 2.0)\n",
    "- Simplify emotion settings (use defaults)\n",
    "- Check GPU memory usage\n",
    "\n",
    "**Import Errors:**\n",
    "- Restart runtime and run all cells from the beginning\n",
    "- Check that installation completed without errors\n",
    "- Ensure you're using a GPU runtime\n",
    "\n",
    "**Speaker Cloning Issues:**\n",
    "- Use audio files 5-30 seconds long\n",
    "- Ensure audio is clear and contains speech\n",
    "- Supported formats: WAV, MP3, FLAC\n",
    "- Try mono audio if stereo doesn't work\n",
    "\n",
    "### 📚 Model Information\n",
    "- **Model**: Wamp1re-Ai/Zonos-v0.1-transformer\n",
    "- **Languages**: English, Japanese, Chinese, French, German\n",
    "- **Sample Rate**: 44.1 kHz\n",
    "- **Architecture**: Transformer-based with DAC autoencoder\n",
    "- **Training Data**: 200k+ hours of multilingual speech\n",
    "\n",
    "### 🌐 Using Custom Subdomains\n",
    "When running the Gradio interface, you can optionally use a custom Cloudflare subdomain:\n",
    "1. Set `use_custom_subdomain = True` in the Gradio cell\n",
    "2. Choose a unique subdomain name\n",
    "3. Your interface will be available at `https://your-name.gradio.app`\n",
    "\n",
    "### 💡 Advanced Usage\n",
    "For production use or custom applications, consider:\n",
    "- Using the hybrid model for better quality (requires mamba-ssm)\n",
    "- Implementing custom conditioning parameters\n",
    "- Fine-tuning for specific voices or languages\n",
    "- Using the API programmatically\n",
    "\n",
    "### 🔗 Useful Links\n",
    "- [Zonos GitHub Repository](https://github.com/YourUsername/Zonos)\n",
    "- [Model on HuggingFace](https://huggingface.co/Wamp1re-Ai/Zonos-v0.1-transformer)\n",
    "- [Zyphra Blog Post](https://www.zyphra.com/post/beta-release-of-zonos-v0-1)\n",
    "- [Online Playground](https://playground.zyphra.com/audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494540d0",
   "metadata": {},
   "source": [
    "## Using Cloudflare Subdomain for Gradio Interface\n",
    "\n",
    "When running the Gradio interface, you can use a custom Cloudflare subdomain to make your interface accessible via a consistent URL. This is especially useful for sharing your model with others.\n",
    "\n",
    "**To use a custom subdomain:**\n",
    "\n",
    "1. Set the `GRADIO_SUBDOMAIN` environment variable to your desired subdomain name.\n",
    "2. Set `GRADIO_SHARE=True` to enable sharing.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Run Gradio Interface (Interactive Web UI)\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "#@markdown ### Gradio Interface Settings\n",
    "subdomain_name = \"my-zonos-app\" #@param {type:\"string\"}\n",
    "use_custom_subdomain = False #@param {type:\"boolean\"}\n",
    "share_publicly = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Set environment variables for Gradio\n",
    "if use_custom_subdomain and subdomain_name:\n",
    "    os.environ[\"GRADIO_SUBDOMAIN\"] = subdomain_name\n",
    "    print(f\"🌐 Will attempt to use subdomain: {subdomain_name}.gradio.app\")\n",
    "else:\n",
    "    # Remove subdomain if previously set\n",
    "    os.environ.pop(\"GRADIO_SUBDOMAIN\", None)\n",
    "\n",
    "os.environ[\"GRADIO_SHARE\"] = \"True\" if share_publicly else \"False\"\n",
    "\n",
    "print(\"🚀 Starting Gradio interface...\")\n",
    "print(\"This may take a moment to initialize...\")\n",
    "\n",
    "# Check if gradio_interface.py exists\n",
    "if not os.path.exists(\"gradio_interface.py\"):\n",
    "    print(\"❌ gradio_interface.py not found!\")\n",
    "    print(\"Make sure you're in the correct directory and the file exists.\")\n",
    "else:\n",
    "    try:\n",
    "        # Import and run the interface\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        # Run the gradio interface in a separate process\n",
    "        print(\"📱 Launching Gradio interface...\")\n",
    "        print(\"Click on the public URL below to access the web interface\")\n",
    "        print(\"⚠️ Note: The interface will run until you stop this cell\\n\")\n",
    "        \n",
    "        # Run the gradio interface\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"gradio_interface.py\"\n",
    "        ], capture_output=False, text=True)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 Gradio interface stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error running Gradio interface: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"- Make sure all dependencies are installed correctly\")\n",
    "        print(\"- Check that the model loaded successfully in previous cells\")\n",
    "        print(\"- Try restarting the runtime if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda40922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🧪 Quick Test - Verify Everything Works\n",
    "#@markdown Run this cell to verify that Zonos is properly installed and working\n",
    "\n",
    "print(\"Running comprehensive test of Zonos installation...\")\n",
    "print(\"This will check dependencies and try to load the model.\")\n",
    "print()\n",
    "\n",
    "exec(open('colab_quick_test.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 🎭 Voice Cloning - Upload Audio to Clone a Voice\n",
    "\n",
    "from google.colab import files\n",
    "import torchaudio\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#@markdown ### Upload Audio File for Voice Cloning\n",
    "#@markdown Click the \"Choose Files\" button below to upload an audio file\n",
    "\n",
    "print(\"🎤 Voice Cloning Setup\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Upload a short audio file (5-30 seconds) of the speaker you want to clone.\")\n",
    "print(\"\")\n",
    "print(\"✅ Supported formats: WAV, MP3, FLAC, M4A\")\n",
    "print(\"✅ Recommended length: 10-30 seconds\")\n",
    "print(\"✅ Audio should contain clear speech\")\n",
    "print(\"✅ Minimal background noise preferred\")\n",
    "print(\"\")\n",
    "print(\"📁 Click 'Choose Files' to upload your audio:\")\n",
    "print(\"\")\n",
    "\n",
    "# Upload audio file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Process the uploaded file\n",
    "    speaker_file = list(uploaded.keys())[0]\n",
    "    file_size = len(uploaded[speaker_file]) / (1024 * 1024)  # MB\n",
    "    \n",
    "    print(f\"\")\n",
    "    print(f\"📁 Processing uploaded file: {speaker_file}\")\n",
    "    print(f\"📏 File size: {file_size:.2f} MB\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    try:\n",
    "        # Load audio file\n",
    "        print(\"🔄 Loading audio file...\")\n",
    "        wav, sr = torchaudio.load(speaker_file)\n",
    "        \n",
    "        # Get audio info\n",
    "        duration = wav.shape[1] / sr\n",
    "        channels = wav.shape[0]\n",
    "        \n",
    "        print(f\"✅ Audio loaded successfully!\")\n",
    "        print(f\"   📊 Duration: {duration:.2f} seconds\")\n",
    "        print(f\"   📊 Sample rate: {sr} Hz\")\n",
    "        print(f\"   📊 Channels: {channels} ({'Stereo' if channels > 1 else 'Mono'})\")\n",
    "        \n",
    "        # Check duration\n",
    "        if duration < 3:\n",
    "            print(f\"⚠️ WARNING: Audio is quite short ({duration:.1f}s). Consider using 5-30 seconds for better results.\")\n",
    "        elif duration > 60:\n",
    "            print(f\"⚠️ WARNING: Audio is long ({duration:.1f}s). Using first 30 seconds for processing.\")\n",
    "            # Trim to first 30 seconds\n",
    "            max_samples = int(30 * sr)\n",
    "            wav = wav[:, :max_samples]\n",
    "            duration = 30.0\n",
    "            \n",
    "        # Convert to mono if stereo\n",
    "        if wav.shape[0] > 1:\n",
    "            print(\"🔄 Converting stereo to mono...\")\n",
    "            wav = wav.mean(0, keepdim=True)\n",
    "        \n",
    "        # Resample if necessary (model expects certain sample rates)\n",
    "        target_sr = 44100  # Common target sample rate\n",
    "        if sr != target_sr:\n",
    "            print(f\"🔄 Resampling from {sr} Hz to {target_sr} Hz...\")\n",
    "            resampler = torchaudio.transforms.Resample(sr, target_sr)\n",
    "            wav = resampler(wav)\n",
    "            sr = target_sr\n",
    "        \n",
    "        # Play the processed audio for verification\n",
    "        print(f\"\")\n",
    "        print(f\"🔊 Preview of processed audio:\")\n",
    "        wav_numpy = wav.squeeze().numpy()\n",
    "        ipd.display(ipd.Audio(wav_numpy, rate=sr))\n",
    "        \n",
    "        # Create speaker embedding\n",
    "        print(f\"\")\n",
    "        print(f\"🧠 Creating speaker embedding...\")\n",
    "        print(f\"   This analyzes the voice characteristics for cloning\")\n",
    "        \n",
    "        # Make sure model is loaded\n",
    "        if 'model' not in globals():\n",
    "            print(f\"❌ Error: Model not loaded yet!\")\n",
    "            print(f\"   Please run Cell 3 (Load and run the Zonos model) first.\")\n",
    "        else:\n",
    "            # Create the speaker embedding\n",
    "            speaker_embedding = model.make_speaker_embedding(wav, sr)\n",
    "            speaker_embedding = speaker_embedding.to(device, dtype=torch.bfloat16)\n",
    "            \n",
    "            print(f\"✅ Speaker embedding created successfully!\")\n",
    "            print(f\"   📊 Embedding shape: {speaker_embedding.shape}\")\n",
    "            print(f\"   📊 Device: {speaker_embedding.device}\")\n",
    "            \n",
    "            # Store globally for use in other cells\n",
    "            globals()['custom_speaker_embedding'] = speaker_embedding\n",
    "            globals()['speaker_audio_info'] = {\n",
    "                'filename': speaker_file,\n",
    "                'duration': duration,\n",
    "                'sample_rate': sr,\n",
    "                'channels': channels\n",
    "            }\n",
    "            \n",
    "            print(f\"\")\n",
    "            print(f\"🎉 Voice cloning setup complete!\")\n",
    "            print(f\"\")\n",
    "            print(f\"✅ The voice from '{speaker_file}' is now ready for cloning\")\n",
    "            print(f\"✅ You can now use this voice in the text-to-speech cells below\")\n",
    "            print(f\"✅ The speaker embedding is stored as 'custom_speaker_embedding'\")\n",
    "            print(f\"\")\n",
    "            print(f\"➡️ Go to the next cell to generate speech with this cloned voice!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing audio file: {e}\")\n",
    "        print(f\"\")\n",
    "        print(f\"💡 Troubleshooting tips:\")\n",
    "        print(f\"   • Make sure the file is a valid audio format (WAV, MP3, FLAC)\")\n",
    "        print(f\"   • Try a different audio file\")\n",
    "        print(f\"   • Ensure the audio contains speech (not music or silence)\")\n",
    "        print(f\"   • Check that the model is loaded (run Cell 3 first)\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\")\n",
    "    print(f\"ℹ️ No file uploaded. Voice cloning is optional.\")\n",
    "    print(f\"\")\n",
    "    print(f\"You can:\")\n",
    "    print(f\"✅ Skip this step and use the default voice in the next cells\")\n",
    "    print(f\"✅ Come back here later to upload audio for voice cloning\")\n",
    "    print(f\"✅ Re-run this cell to upload a different audio file\")\n",
    "    \n",
    "    # Clear any existing speaker embedding\n",
    "    if 'custom_speaker_embedding' in globals():\n",
    "        del globals()['custom_speaker_embedding']\n",
    "        print(f\"🗑️ Cleared previous speaker embedding\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"📝 Next steps:\")\n",
    "print(f\"   1. Continue to the next cell for text-to-speech generation\")\n",
    "print(f\"   2. The system will automatically use your cloned voice if uploaded\")\n",
    "print(f\"   3. You can always come back here to try different voices\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
